{"version":3,"file":"index.cjs.js","sources":["../src/logging/formats.ts","../src/util/escapeRegExp.ts","../src/logging/rootLogger.ts","../src/logging/voidLogger.ts","../src/cache/CacheClient.ts","../src/cache/NoStore.ts","../src/cache/CacheManager.ts","../src/urls.ts","../src/config.ts","../src/context/AbortContext.ts","../src/context/RootContext.ts","../src/context/ValueContext.ts","../src/context/Contexts.ts","../src/database/config.ts","../src/database/connectors/defaultNameOverride.ts","../src/database/connectors/mysql.ts","../src/database/connectors/defaultSchemaOverride.ts","../src/database/connectors/postgres.ts","../src/database/connectors/sqlite3.ts","../src/database/connection.ts","../src/database/DatabaseManager.ts","../src/database/util.ts","../src/service/lib/config.ts","../src/hot.ts","../src/middleware/errorHandler.ts","../src/middleware/notFoundHandler.ts","../src/middleware/requestLoggingHandler.ts","../src/middleware/statusCheckHandler.ts","../src/service/lib/hostFactory.ts","../src/service/lib/ServiceBuilderImpl.ts","../src/discovery/SingleHostDiscovery.ts","../src/paths.ts","../src/reading/AzureUrlReader.ts","../src/reading/BitbucketUrlReader.ts","../src/reading/GithubUrlReader.ts","../src/reading/tree/util.ts","../src/reading/GitlabUrlReader.ts","../src/reading/AwsS3UrlReader.ts","../src/reading/FetchUrlReader.ts","../src/reading/UrlReaderPredicateMux.ts","../src/reading/tree/TarArchiveResponse.ts","../src/reading/tree/ZipArchiveResponse.ts","../src/reading/tree/ReadableArrayResponse.ts","../src/reading/tree/ReadTreeResponseFactory.ts","../src/reading/GoogleGcsUrlReader.ts","../src/reading/UrlReaders.ts","../src/scm/git.ts","../src/service/createServiceBuilder.ts","../src/service/createStatusCheckRouter.ts","../src/tokens/ServerTokenManager.ts","../src/util/DockerContainerRunner.ts"],"sourcesContent":["/*\n * Copyright 2020 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport * as winston from 'winston';\nimport { TransformableInfo } from 'logform';\n\nconst coloredTemplate = (info: TransformableInfo) => {\n  const { timestamp, level, message, plugin, service, ...fields } = info;\n  const colorizer = winston.format.colorize();\n  const prefix = plugin || service;\n  const timestampColor = colorizer.colorize('timestamp', timestamp);\n  const prefixColor = colorizer.colorize('prefix', prefix);\n\n  const extraFields = Object.entries(fields)\n    .map(([key, value]) => `${colorizer.colorize('field', `${key}`)}=${value}`)\n    .join(' ');\n\n  return `${timestampColor} ${prefixColor} ${level} ${message} ${extraFields}`;\n};\n\n/**\n * A logging format that adds coloring to console output.\n *\n * @public\n */\nexport const coloredFormat = winston.format.combine(\n  winston.format.timestamp(),\n  winston.format.colorize({\n    colors: { timestamp: 'dim', prefix: 'blue', field: 'cyan', debug: 'grey' },\n  }),\n  winston.format.printf(coloredTemplate),\n);\n","/*\n * Copyright 2021 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n/**\n * Escapes a given string to be used inside a RegExp.\n *\n * Taken from https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Regular_Expressions\n */\nexport const escapeRegExp = (text: string) => {\n  return text.replace(/[.*+?^${}(\\)|[\\]\\\\]/g, '\\\\$&');\n};\n","/*\n * Copyright 2020 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { merge } from 'lodash';\nimport * as winston from 'winston';\nimport { LoggerOptions } from 'winston';\nimport { coloredFormat } from './formats';\nimport { escapeRegExp } from '../util/escapeRegExp';\n\nlet rootLogger: winston.Logger;\nlet redactionRegExp: RegExp | undefined;\n\n/**\n * Gets the current root logger.\n *\n * @public\n */\nexport function getRootLogger(): winston.Logger {\n  return rootLogger;\n}\n\n/**\n * Sets a completely custom default \"root\" logger.\n *\n * @remarks\n *\n * This is the logger instance that will be the foundation for all other logger\n * instances passed to plugins etc, in a given backend.\n *\n * Only use this if you absolutely need to make a completely custom logger.\n * Normally if you want to make light adaptations to the default logger\n * behavior, you would instead call {@link createRootLogger}.\n *\n * @public\n */\nexport function setRootLogger(newLogger: winston.Logger) {\n  rootLogger = newLogger;\n}\n\nexport function setRootLoggerRedactionList(redactionList: string[]) {\n  // Exclude secrets that are empty or just one character in length. These\n  // typically mean that you are running local dev or tests, or using the\n  // --lax flag which sets things to just 'x'. So exclude those.\n  const filtered = redactionList.filter(r => r.length > 1);\n\n  if (filtered.length) {\n    redactionRegExp = new RegExp(\n      `(${filtered.map(escapeRegExp).join('|')})`,\n      'g',\n    );\n  } else {\n    redactionRegExp = undefined;\n  }\n}\n\n/**\n * A winston formatting function that finds occurrences of filteredKeys\n * and replaces them with the corresponding identifier.\n */\nfunction redactLogLine(info: winston.Logform.TransformableInfo) {\n  // TODO(hhogg): The logger is created before the config is loaded, because the\n  // logger is needed in the config loader. There is a risk of a secret being\n  // logged out during the config loading stage.\n  // TODO(freben): Added a check that info.message actually was a string,\n  // because it turned out that this was not necessarily guaranteed.\n  // https://github.com/backstage/backstage/issues/8306\n  if (redactionRegExp && typeof info.message === 'string') {\n    info.message = info.message.replace(redactionRegExp, '[REDACTED]');\n  }\n\n  return info;\n}\n\n/**\n * Creates a default \"root\" logger. This also calls {@link setRootLogger} under\n * the hood.\n *\n * @remarks\n *\n * This is the logger instance that will be the foundation for all other logger\n * instances passed to plugins etc, in a given backend.\n *\n * @public\n */\nexport function createRootLogger(\n  options: winston.LoggerOptions = {},\n  env = process.env,\n): winston.Logger {\n  const logger = winston.createLogger(\n    merge<LoggerOptions, LoggerOptions>(\n      {\n        level: env.LOG_LEVEL || 'info',\n        format: winston.format.combine(\n          winston.format(redactLogLine)(),\n          env.NODE_ENV === 'production' ? winston.format.json() : coloredFormat,\n        ),\n        defaultMeta: {\n          service: 'backstage',\n        },\n        transports: [\n          new winston.transports.Console({\n            silent: env.JEST_WORKER_ID !== undefined && !env.LOG_LEVEL,\n          }),\n        ],\n      },\n      options,\n    ),\n  );\n\n  setRootLogger(logger);\n\n  return logger;\n}\n\nrootLogger = createRootLogger();\n","/*\n * Copyright 2020 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { PassThrough } from 'stream';\nimport * as winston from 'winston';\n\n/**\n * A logger that just throws away all messages.\n *\n * @public\n */\nexport function getVoidLogger(): winston.Logger {\n  return winston.createLogger({\n    transports: [new winston.transports.Stream({ stream: new PassThrough() })],\n  });\n}\n","/*\n * Copyright 2021 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { JsonValue } from '@backstage/types';\nimport { createHash } from 'crypto';\nimport Keyv from 'keyv';\n\ntype CacheClientArgs = {\n  client: Keyv;\n};\n\n/**\n * Options passed to {@link CacheClient.set}.\n *\n * @public\n */\nexport type CacheClientSetOptions = {\n  /**\n   * Optional TTL in milliseconds. Defaults to the TTL provided when the client\n   * was set up (or no TTL if none are provided).\n   */\n  ttl?: number;\n};\n\n/**\n * A pre-configured, storage agnostic cache client suitable for use by\n * Backstage plugins.\n *\n * @public\n */\nexport interface CacheClient {\n  /**\n   * Reads data from a cache store for the given key. If no data was found,\n   * returns undefined.\n   */\n  get(key: string): Promise<JsonValue | undefined>;\n\n  /**\n   * Writes the given data to a cache store, associated with the given key. An\n   * optional TTL may also be provided, otherwise it defaults to the TTL that\n   * was provided when the client was instantiated.\n   */\n  set(\n    key: string,\n    value: JsonValue,\n    options?: CacheClientSetOptions,\n  ): Promise<void>;\n\n  /**\n   * Removes the given key from the cache store.\n   */\n  delete(key: string): Promise<void>;\n}\n\n/**\n * A basic, concrete implementation of the CacheClient, suitable for almost\n * all uses in Backstage.\n */\nexport class DefaultCacheClient implements CacheClient {\n  private readonly client: Keyv;\n\n  constructor({ client }: CacheClientArgs) {\n    this.client = client;\n  }\n\n  async get(key: string): Promise<JsonValue | undefined> {\n    const k = this.getNormalizedKey(key);\n    return await this.client.get(k);\n  }\n\n  async set(\n    key: string,\n    value: JsonValue,\n    opts: CacheClientSetOptions = {},\n  ): Promise<void> {\n    const k = this.getNormalizedKey(key);\n    await this.client.set(k, value, opts.ttl);\n  }\n\n  async delete(key: string): Promise<void> {\n    const k = this.getNormalizedKey(key);\n    await this.client.delete(k);\n  }\n\n  /**\n   * Ensures keys are well-formed for any/all cache stores.\n   */\n  private getNormalizedKey(candidateKey: string): string {\n    // Remove potentially invalid characters.\n    const wellFormedKey = Buffer.from(candidateKey).toString('base64');\n\n    // Memcache in particular doesn't do well with keys > 250 bytes.\n    // Padded because a plugin ID is also prepended to the key.\n    if (wellFormedKey.length < 200) {\n      return wellFormedKey;\n    }\n\n    return createHash('md5').update(candidateKey).digest('base64');\n  }\n}\n","/*\n * Copyright 2021 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n/**\n * Storage class compatible with Keyv which always results in a no-op. This is\n * used when no cache store is configured in a Backstage backend instance.\n */\nexport class NoStore extends Map<string, any> {\n  clear(): void {\n    return;\n  }\n\n  delete(_key: string): boolean {\n    return false;\n  }\n\n  get(_key: string) {\n    return;\n  }\n\n  has(_key: string): boolean {\n    return false;\n  }\n\n  set(_key: string, _value: any): this {\n    return this;\n  }\n}\n","/*\n * Copyright 2021 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Config } from '@backstage/config';\nimport Keyv from 'keyv';\n// @ts-expect-error\nimport KeyvMemcache from 'keyv-memcache';\n// @ts-expect-error\nimport KeyvRedis from '@keyv/redis';\nimport { Logger } from 'winston';\nimport { getRootLogger } from '../logging';\nimport { DefaultCacheClient, CacheClient } from './CacheClient';\nimport { NoStore } from './NoStore';\nimport { CacheManagerOptions, PluginCacheManager } from './types';\n\n/**\n * Implements a Cache Manager which will automatically create new cache clients\n * for plugins when requested. All requested cache clients are created with the\n * connection details provided.\n *\n * @public\n */\nexport class CacheManager {\n  /**\n   * Keys represent supported `backend.cache.store` values, mapped to factories\n   * that return Keyv instances appropriate to the store.\n   */\n  private readonly storeFactories = {\n    redis: this.getRedisClient,\n    memcache: this.getMemcacheClient,\n    memory: this.getMemoryClient,\n    none: this.getNoneClient,\n  };\n\n  /**\n   * Shared memory store for the in-memory cache client. Sharing the same Map\n   * instance ensures get/set/delete operations hit the same store, regardless\n   * of where/when a client is instantiated.\n   */\n  private readonly memoryStore = new Map();\n\n  private readonly logger: Logger;\n  private readonly store: keyof CacheManager['storeFactories'];\n  private readonly connection: string;\n  private readonly errorHandler: CacheManagerOptions['onError'];\n\n  /**\n   * Creates a new {@link CacheManager} instance by reading from the `backend`\n   * config section, specifically the `.cache` key.\n   *\n   * @param config - The loaded application configuration.\n   */\n  static fromConfig(\n    config: Config,\n    options: CacheManagerOptions = {},\n  ): CacheManager {\n    // If no `backend.cache` config is provided, instantiate the CacheManager\n    // with a \"NoStore\" cache client.\n    const store = config.getOptionalString('backend.cache.store') || 'none';\n    const connectionString =\n      config.getOptionalString('backend.cache.connection') || '';\n    const logger = (options.logger || getRootLogger()).child({\n      type: 'cacheManager',\n    });\n    return new CacheManager(store, connectionString, logger, options.onError);\n  }\n\n  private constructor(\n    store: string,\n    connectionString: string,\n    logger: Logger,\n    errorHandler: CacheManagerOptions['onError'],\n  ) {\n    if (!this.storeFactories.hasOwnProperty(store)) {\n      throw new Error(`Unknown cache store: ${store}`);\n    }\n    this.logger = logger;\n    this.store = store as keyof CacheManager['storeFactories'];\n    this.connection = connectionString;\n    this.errorHandler = errorHandler;\n  }\n\n  /**\n   * Generates a PluginCacheManager for consumption by plugins.\n   *\n   * @param pluginId - The plugin that the cache manager should be created for.\n   *        Plugin names should be unique.\n   */\n  forPlugin(pluginId: string): PluginCacheManager {\n    return {\n      getClient: (opts = {}): CacheClient => {\n        const concreteClient = this.getClientWithTtl(pluginId, opts.defaultTtl);\n\n        // Always provide an error handler to avoid killing the process.\n        concreteClient.on('error', (err: Error) => {\n          // In all cases, just log the error.\n          this.logger.error(err);\n\n          // Invoke any custom error handler if provided.\n          if (typeof this.errorHandler === 'function') {\n            this.errorHandler(err);\n          }\n        });\n\n        return new DefaultCacheClient({\n          client: concreteClient,\n        });\n      },\n    };\n  }\n\n  private getClientWithTtl(pluginId: string, ttl: number | undefined): Keyv {\n    return this.storeFactories[this.store].call(this, pluginId, ttl);\n  }\n\n  private getRedisClient(\n    pluginId: string,\n    defaultTtl: number | undefined,\n  ): Keyv {\n    return new Keyv({\n      namespace: pluginId,\n      ttl: defaultTtl,\n      store: new KeyvRedis(this.connection),\n    });\n  }\n\n  private getMemcacheClient(\n    pluginId: string,\n    defaultTtl: number | undefined,\n  ): Keyv {\n    return new Keyv({\n      namespace: pluginId,\n      ttl: defaultTtl,\n      store: new KeyvMemcache(this.connection),\n    });\n  }\n\n  private getMemoryClient(\n    pluginId: string,\n    defaultTtl: number | undefined,\n  ): Keyv {\n    return new Keyv({\n      namespace: pluginId,\n      ttl: defaultTtl,\n      store: this.memoryStore,\n    });\n  }\n\n  private getNoneClient(pluginId: string): Keyv {\n    return new Keyv({\n      namespace: pluginId,\n      store: new NoStore(),\n    });\n  }\n}\n","/*\n * Copyright 2021 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nexport function isValidUrl(url: string): boolean {\n  try {\n    // eslint-disable-next-line no-new\n    new URL(url);\n    return true;\n  } catch {\n    return false;\n  }\n}\n","/*\n * Copyright 2020 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { resolve as resolvePath } from 'path';\nimport parseArgs from 'minimist';\nimport { Logger } from 'winston';\nimport { findPaths } from '@backstage/cli-common';\nimport {\n  loadConfigSchema,\n  loadConfig,\n  ConfigSchema,\n  ConfigTarget,\n  LoadConfigOptionsRemote,\n} from '@backstage/config-loader';\nimport { AppConfig, Config, ConfigReader } from '@backstage/config';\nimport { JsonValue } from '@backstage/types';\nimport { getPackages } from '@manypkg/get-packages';\n\nimport { isValidUrl } from './urls';\n\nimport { setRootLoggerRedactionList } from './logging/rootLogger';\n\n// Fetch the schema and get all the secrets to pass to the rootLogger for redaction\nconst updateRedactionList = (\n  schema: ConfigSchema,\n  configs: AppConfig[],\n  logger: Logger,\n) => {\n  const secretAppConfigs = schema.process(configs, {\n    visibility: ['secret'],\n    withDeprecatedKeys: true,\n  });\n  const secretConfig = ConfigReader.fromConfigs(secretAppConfigs);\n  const values = new Set<string>();\n  const data = secretConfig.get();\n\n  JSON.parse(\n    JSON.stringify(data),\n    (_, v) => typeof v === 'string' && values.add(v),\n  );\n\n  logger.info(\n    `${values.size} secrets found in the config which will be redacted`,\n  );\n\n  setRootLoggerRedactionList(Array.from(values));\n};\n\nexport class ObservableConfigProxy implements Config {\n  private config: Config = new ConfigReader({});\n\n  private readonly subscribers: (() => void)[] = [];\n\n  constructor(\n    private readonly logger: Logger,\n    private readonly parent?: ObservableConfigProxy,\n    private parentKey?: string,\n  ) {\n    if (parent && !parentKey) {\n      throw new Error('parentKey is required if parent is set');\n    }\n  }\n\n  setConfig(config: Config) {\n    if (this.parent) {\n      throw new Error('immutable');\n    }\n    this.config = config;\n    for (const subscriber of this.subscribers) {\n      try {\n        subscriber();\n      } catch (error) {\n        this.logger.error(`Config subscriber threw error, ${error}`);\n      }\n    }\n  }\n\n  subscribe(onChange: () => void): { unsubscribe: () => void } {\n    if (this.parent) {\n      return this.parent.subscribe(onChange);\n    }\n\n    this.subscribers.push(onChange);\n    return {\n      unsubscribe: () => {\n        const index = this.subscribers.indexOf(onChange);\n        if (index >= 0) {\n          this.subscribers.splice(index, 1);\n        }\n      },\n    };\n  }\n\n  private select(required: true): Config;\n  private select(required: false): Config | undefined;\n  private select(required: boolean): Config | undefined {\n    if (this.parent && this.parentKey) {\n      if (required) {\n        return this.parent.select(true).getConfig(this.parentKey);\n      }\n      return this.parent.select(false)?.getOptionalConfig(this.parentKey);\n    }\n\n    return this.config;\n  }\n\n  has(key: string): boolean {\n    return this.select(false)?.has(key) ?? false;\n  }\n  keys(): string[] {\n    return this.select(false)?.keys() ?? [];\n  }\n  get<T = JsonValue>(key?: string): T {\n    return this.select(true).get(key);\n  }\n  getOptional<T = JsonValue>(key?: string): T | undefined {\n    return this.select(false)?.getOptional(key);\n  }\n  getConfig(key: string): Config {\n    return new ObservableConfigProxy(this.logger, this, key);\n  }\n  getOptionalConfig(key: string): Config | undefined {\n    if (this.select(false)?.has(key)) {\n      return new ObservableConfigProxy(this.logger, this, key);\n    }\n    return undefined;\n  }\n  getConfigArray(key: string): Config[] {\n    return this.select(true).getConfigArray(key);\n  }\n  getOptionalConfigArray(key: string): Config[] | undefined {\n    return this.select(false)?.getOptionalConfigArray(key);\n  }\n  getNumber(key: string): number {\n    return this.select(true).getNumber(key);\n  }\n  getOptionalNumber(key: string): number | undefined {\n    return this.select(false)?.getOptionalNumber(key);\n  }\n  getBoolean(key: string): boolean {\n    return this.select(true).getBoolean(key);\n  }\n  getOptionalBoolean(key: string): boolean | undefined {\n    return this.select(false)?.getOptionalBoolean(key);\n  }\n  getString(key: string): string {\n    return this.select(true).getString(key);\n  }\n  getOptionalString(key: string): string | undefined {\n    return this.select(false)?.getOptionalString(key);\n  }\n  getStringArray(key: string): string[] {\n    return this.select(true).getStringArray(key);\n  }\n  getOptionalStringArray(key: string): string[] | undefined {\n    return this.select(false)?.getOptionalStringArray(key);\n  }\n}\n\n// A global used to ensure that only a single file watcher is active at a time.\nlet currentCancelFunc: () => void;\n\n/**\n * Load configuration for a Backend.\n *\n * This function should only be called once, during the initialization of the backend.\n *\n * @public\n */\nexport async function loadBackendConfig(options: {\n  logger: Logger;\n  // process.argv or any other overrides\n  remote?: LoadConfigOptionsRemote;\n  argv: string[];\n}): Promise<Config> {\n  const args = parseArgs(options.argv);\n\n  const configTargets: ConfigTarget[] = [args.config ?? []]\n    .flat()\n    .map(arg => (isValidUrl(arg) ? { url: arg } : { path: resolvePath(arg) }));\n\n  /* eslint-disable-next-line no-restricted-syntax */\n  const paths = findPaths(__dirname);\n\n  // TODO(hhogg): This is fetching _all_ of the packages of the monorepo\n  // in order to find the secrets for redactions, however we only care about\n  // the backend ones, we need to find a way to exclude the frontend packages.\n  const { packages } = await getPackages(paths.targetDir);\n  const schema = await loadConfigSchema({\n    dependencies: packages.map(p => p.packageJson.name),\n  });\n\n  const config = new ObservableConfigProxy(options.logger);\n  const { appConfigs } = await loadConfig({\n    configRoot: paths.targetRoot,\n    configTargets: configTargets,\n    remote: options.remote,\n    watch: {\n      onChange(newConfigs) {\n        options.logger.info(\n          `Reloaded config from ${newConfigs.map(c => c.context).join(', ')}`,\n        );\n\n        config.setConfig(ConfigReader.fromConfigs(newConfigs));\n      },\n      stopSignal: new Promise(resolve => {\n        if (currentCancelFunc) {\n          currentCancelFunc();\n        }\n        currentCancelFunc = resolve;\n\n        // For reloads of this module we need to use a dispose handler rather than the global.\n        if (module.hot) {\n          module.hot.addDisposeHandler(resolve);\n        }\n      }),\n    },\n  });\n\n  options.logger.info(\n    `Loaded config from ${appConfigs.map(c => c.context).join(', ')}`,\n  );\n\n  config.setConfig(ConfigReader.fromConfigs(appConfigs));\n\n  // Subscribe to config changes and update the redaction list for logging\n  updateRedactionList(schema, appConfigs, options.logger);\n  config.subscribe(() =>\n    updateRedactionList(schema, appConfigs, options.logger),\n  );\n\n  return config;\n}\n","/*\n * Copyright 2021 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { AbortController, AbortSignal } from 'node-abort-controller';\nimport { Context } from './types';\n\n/**\n * A context that implements various abort related functionality.\n */\nexport class AbortContext implements Context {\n  /**\n   * Abort either when the parent aborts, or after the given timeout has\n   * expired.\n   *\n   * @param ctx - The parent context\n   * @param timeout - A timeout value, in milliseconds\n   * @returns A new context\n   */\n  static forTimeoutMillis(ctx: Context, timeout: number): Context {\n    const desiredDeadline = new Date(Date.now() + timeout);\n    const actualDeadline =\n      ctx.deadline && ctx.deadline < desiredDeadline\n        ? ctx.deadline\n        : desiredDeadline;\n\n    if (ctx.abortSignal.aborted) {\n      if (ctx.deadline && desiredDeadline === actualDeadline) {\n        return ctx;\n      }\n      return new AbortContext(ctx, ctx.abortSignal, actualDeadline);\n    }\n\n    const controller = new AbortController();\n    const timeoutHandle = setTimeout(abort, timeout);\n    ctx.abortSignal.addEventListener('abort', abort);\n\n    function abort() {\n      ctx.abortSignal.removeEventListener('abort', abort);\n      clearTimeout(timeoutHandle!);\n      controller.abort();\n    }\n\n    return new AbortContext(ctx, controller.signal, actualDeadline);\n  }\n\n  /**\n   * Abort either when the parent aborts, or when the given controller is\n   * triggered.\n   *\n   * @remarks\n   *\n   * If you have access to the controller, this function is more efficient than\n   * {@link AbortContext#forSignal}.\n   *\n   * @param ctx - The parent context\n   * @param controller - An abort controller\n   * @returns A new context\n   */\n  static forController(ctx: Context, controller: AbortController): Context {\n    // Already aborted context / signal are fine to reuse as-is\n    if (ctx.abortSignal.aborted) {\n      return ctx;\n    } else if (controller.signal.aborted) {\n      return new AbortContext(ctx, controller.signal, ctx.deadline);\n    }\n\n    function abort() {\n      ctx.abortSignal.removeEventListener('abort', abort);\n      controller.abort();\n    }\n\n    ctx.abortSignal.addEventListener('abort', abort);\n\n    return new AbortContext(ctx, controller.signal, ctx.deadline);\n  }\n\n  /**\n   * Abort either when the parent aborts, or when the given signal is triggered.\n   *\n   * @remarks\n   *\n   * If you have access to the controller and not just the signal,\n   * {@link AbortContext#forController} is slightly more efficient to use.\n   *\n   * @param ctx - The parent context\n   * @param signal - An abort signal\n   * @returns A new context\n   */\n  static forSignal(ctx: Context, signal: AbortSignal): Context {\n    // Already aborted context / signal are fine to reuse as-is\n    if (ctx.abortSignal.aborted) {\n      return ctx;\n    } else if (signal.aborted) {\n      return new AbortContext(ctx, signal, ctx.deadline);\n    }\n\n    const controller = new AbortController();\n\n    function abort() {\n      ctx.abortSignal.removeEventListener('abort', abort);\n      signal.removeEventListener('abort', abort);\n      controller.abort();\n    }\n\n    ctx.abortSignal.addEventListener('abort', abort);\n    signal.addEventListener('abort', abort);\n\n    return new AbortContext(ctx, controller.signal, ctx.deadline);\n  }\n\n  private constructor(\n    private readonly parent: Context,\n    readonly abortSignal: AbortSignal,\n    readonly deadline: Date | undefined,\n  ) {}\n\n  value<T = unknown>(key: string): T | undefined {\n    return this.parent.value(key);\n  }\n}\n","/*\n * Copyright 2021 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { AbortSignal } from 'node-abort-controller';\nimport { Context } from './types';\n\n/**\n * Since the root context can never abort, and since nobody is every meant to\n * dispatch events through it, we can use a static dummy instance for\n * efficiency.\n */\nconst dummyAbortSignal: AbortSignal = Object.freeze({\n  aborted: false,\n  addEventListener() {},\n  removeEventListener() {},\n  dispatchEvent() {\n    return true;\n  },\n  onabort: null,\n});\n\n/**\n * An empty root context.\n */\nexport class RootContext implements Context {\n  readonly abortSignal = dummyAbortSignal;\n  readonly deadline = undefined;\n\n  value<T = unknown>(_key: string): T | undefined {\n    return undefined;\n  }\n}\n","/*\n * Copyright 2021 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { AbortSignal } from 'node-abort-controller';\nimport { Context } from './types';\n\n/**\n * A context that just holds a single value, and delegates the rest to its\n * parent.\n */\nexport class ValueContext implements Context {\n  static forConstantValue(ctx: Context, key: string, value: unknown): Context {\n    return new ValueContext(ctx, key, value);\n  }\n\n  constructor(\n    private readonly _parent: Context,\n    private readonly _key: string,\n    private readonly _value: unknown,\n  ) {}\n\n  get abortSignal(): AbortSignal {\n    return this._parent.abortSignal;\n  }\n\n  get deadline(): Date | undefined {\n    return this._parent.deadline;\n  }\n\n  value<T = unknown>(key: string): T | undefined {\n    return key === this._key ? (this._value as T) : this._parent.value(key);\n  }\n}\n","/*\n * Copyright 2021 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Duration } from 'luxon';\nimport { AbortController, AbortSignal } from 'node-abort-controller';\nimport { AbortContext } from './AbortContext';\nimport { RootContext } from './RootContext';\nimport { Context } from './types';\nimport { ValueContext } from './ValueContext';\n\n/**\n * Common context decorators.\n *\n * @alpha\n */\nexport class Contexts {\n  /**\n   * Creates a root context.\n   *\n   * @remarks\n   *\n   * This should normally only be called near the root of an application. The\n   * created context is meant to be passed down into deeper levels, which may or\n   * may not make derived contexts out of it.\n   */\n  static root(): Context {\n    return new RootContext();\n  }\n\n  /**\n   * Creates a derived context, which signals to abort operations either when\n   * any parent context signals, or when the given source is aborted.\n   *\n   * @remarks\n   *\n   * If the parent context was already aborted, then it is returned as-is.\n   *\n   * If the given source was already aborted, then a new already-aborted context\n   * is returned.\n   *\n   * @param parentCtx - A parent context that shall be used as a base\n   * @param source - An abort controller or signal that you intend to perhaps\n   *                 trigger at some later point in time.\n   * @returns A new {@link Context}\n   */\n  static withAbort(\n    parentCtx: Context,\n    source: AbortController | AbortSignal,\n  ): Context {\n    return 'aborted' in source\n      ? AbortContext.forSignal(parentCtx, source)\n      : AbortContext.forController(parentCtx, source);\n  }\n\n  /**\n   * Creates a derived context, which signals to abort operations either when\n   * any parent context signals, or when the given amount of time has passed.\n   * This may affect the deadline.\n   *\n   * @param parentCtx - A parent context that shall be used as a base\n   * @param timeout - The duration of time, after which the derived context will\n   *                  signal to abort.\n   * @returns A new {@link Context}\n   */\n  static withTimeoutDuration(parentCtx: Context, timeout: Duration): Context {\n    return AbortContext.forTimeoutMillis(parentCtx, timeout.as('milliseconds'));\n  }\n\n  /**\n   * Creates a derived context, which signals to abort operations either when\n   * any parent context signals, or when the given amount of time has passed.\n   * This may affect the deadline.\n   *\n   * @param parentCtx - A parent context that shall be used as a base\n   * @param timeout - The number of milliseconds, after which the derived\n   *                  context will signal to abort.\n   * @returns A new {@link Context}\n   */\n  static withTimeoutMillis(parentCtx: Context, timeout: number): Context {\n    return AbortContext.forTimeoutMillis(parentCtx, timeout);\n  }\n\n  /**\n   * Creates a derived context, which has a specific key-value pair set as well\n   * as all key-value pairs that were set in the original context.\n   *\n   * @param parentCtx - A parent context that shall be used as a base\n   * @param key - The key of the value to set\n   * @param value - The value, or a function that accepts the previous value (or\n   *                undefined if not set yet) and computes the new value\n   * @returns A new {@link Context}\n   */\n  static withValue(\n    parentCtx: Context,\n    key: string,\n    value: unknown | ((previous: unknown | undefined) => unknown),\n  ): Context {\n    const v = typeof value === 'function' ? value(parentCtx.value(key)) : value;\n    return ValueContext.forConstantValue(parentCtx, key, v);\n  }\n}\n","/*\n * Copyright 2020 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { merge } from 'lodash';\n\n/**\n * Merges database objects together\n *\n * @public\n * @param config - The base config. The input is not modified\n * @param overrides - Any additional overrides\n */\nexport function mergeDatabaseConfig(config: any, ...overrides: any[]) {\n  return merge({}, config, ...overrides);\n}\n","/*\n * Copyright 2021 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nimport { Knex } from 'knex';\n\n/**\n * Provides a partial knex config with database name override.\n *\n * Default override for knex database drivers which accept ConnectionConfig\n * with `connection.database` as the database name field.\n *\n * @param name - database name to get config override for\n */\nexport default function defaultNameOverride(\n  name: string,\n): Partial<Knex.Config> {\n  return {\n    connection: {\n      database: name,\n    },\n  };\n}\n","/*\n * Copyright 2020 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport knexFactory, { Knex } from 'knex';\nimport yn from 'yn';\n\nimport { Config } from '@backstage/config';\nimport { InputError } from '@backstage/errors';\nimport { mergeDatabaseConfig } from '../config';\nimport { DatabaseConnector } from '../types';\nimport defaultNameOverride from './defaultNameOverride';\n\n/**\n * Creates a knex mysql database connection\n *\n * @param dbConfig - The database config\n * @param overrides - Additional options to merge with the config\n */\nexport function createMysqlDatabaseClient(\n  dbConfig: Config,\n  overrides?: Knex.Config,\n) {\n  const knexConfig = buildMysqlDatabaseConfig(dbConfig, overrides);\n  const database = knexFactory(knexConfig);\n  return database;\n}\n\n/**\n * Builds a knex mysql database connection\n *\n * @param dbConfig - The database config\n * @param overrides - Additional options to merge with the config\n */\nexport function buildMysqlDatabaseConfig(\n  dbConfig: Config,\n  overrides?: Knex.Config,\n) {\n  return mergeDatabaseConfig(\n    dbConfig.get(),\n    {\n      connection: getMysqlConnectionConfig(dbConfig, !!overrides),\n      useNullAsDefault: true,\n    },\n    overrides,\n  );\n}\n\n/**\n * Gets the mysql connection config\n *\n * @param dbConfig - The database config\n * @param parseConnectionString - Flag to explicitly control connection string parsing\n */\nexport function getMysqlConnectionConfig(\n  dbConfig: Config,\n  parseConnectionString?: boolean,\n): Knex.MySqlConnectionConfig | string {\n  const connection = dbConfig.get('connection') as any;\n  const isConnectionString =\n    typeof connection === 'string' || connection instanceof String;\n  const autoParse = typeof parseConnectionString !== 'boolean';\n\n  const shouldParseConnectionString = autoParse\n    ? isConnectionString\n    : parseConnectionString && isConnectionString;\n\n  return shouldParseConnectionString\n    ? parseMysqlConnectionString(connection as string)\n    : connection;\n}\n\n/**\n * Parses a mysql connection string.\n *\n * e.g. mysql://examplename:somepassword@examplehost:3306/dbname\n * @param connectionString - The mysql connection string\n */\nexport function parseMysqlConnectionString(\n  connectionString: string,\n): Knex.MySqlConnectionConfig {\n  try {\n    const {\n      protocol,\n      username,\n      password,\n      port,\n      hostname,\n      pathname,\n      searchParams,\n    } = new URL(connectionString);\n\n    if (protocol !== 'mysql:') {\n      throw new Error(`Unknown protocol ${protocol}`);\n    } else if (!username || !password) {\n      throw new Error(`Missing username/password`);\n    } else if (!pathname.match(/^\\/[^/]+$/)) {\n      throw new Error(`Expected single path segment`);\n    }\n\n    const result: Knex.MySqlConnectionConfig = {\n      user: username,\n      password,\n      host: hostname,\n      port: Number(port || 3306),\n      database: decodeURIComponent(pathname.substr(1)),\n    };\n\n    const ssl = searchParams.get('ssl');\n    if (ssl) {\n      result.ssl = ssl;\n    }\n\n    const debug = searchParams.get('debug');\n    if (debug) {\n      result.debug = yn(debug);\n    }\n\n    return result;\n  } catch (e) {\n    throw new InputError(\n      `Error while parsing MySQL connection string, ${e}`,\n      e,\n    );\n  }\n}\n\n/**\n * Creates the missing mysql database if it does not exist\n *\n * @param dbConfig - The database config\n * @param databases - The names of the databases to create\n */\nexport async function ensureMysqlDatabaseExists(\n  dbConfig: Config,\n  ...databases: Array<string>\n) {\n  const admin = createMysqlDatabaseClient(dbConfig, {\n    connection: {\n      database: null as unknown as string,\n    },\n  });\n\n  try {\n    const ensureDatabase = async (database: string) => {\n      await admin.raw(`CREATE DATABASE IF NOT EXISTS ??`, [database]);\n    };\n    await Promise.all(databases.map(ensureDatabase));\n  } finally {\n    await admin.destroy();\n  }\n}\n\n/**\n * MySQL database connector.\n *\n * Exposes database connector functionality via an immutable object.\n */\nexport const mysqlConnector: DatabaseConnector = Object.freeze({\n  createClient: createMysqlDatabaseClient,\n  ensureDatabaseExists: ensureMysqlDatabaseExists,\n  createNameOverride: defaultNameOverride,\n  parseConnectionString: parseMysqlConnectionString,\n});\n","/*\n * Copyright 2021 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nimport { Knex } from 'knex';\n\n/**\n * Provides a partial knex config with schema name override.\n *\n * @param name - schema name to get config override for\n */\nexport default function defaultSchemaOverride(\n  name: string,\n): Partial<Knex.Config> {\n  return {\n    searchPath: [name],\n  };\n}\n","/*\n * Copyright 2020 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport knexFactory, { Knex } from 'knex';\n\nimport { Config } from '@backstage/config';\nimport { ForwardedError } from '@backstage/errors';\nimport { mergeDatabaseConfig } from '../config';\nimport { DatabaseConnector } from '../types';\nimport defaultNameOverride from './defaultNameOverride';\nimport defaultSchemaOverride from './defaultSchemaOverride';\n\n/**\n * Creates a knex postgres database connection\n *\n * @param dbConfig - The database config\n * @param overrides - Additional options to merge with the config\n */\nexport function createPgDatabaseClient(\n  dbConfig: Config,\n  overrides?: Knex.Config,\n) {\n  const knexConfig = buildPgDatabaseConfig(dbConfig, overrides);\n  const database = knexFactory(knexConfig);\n  return database;\n}\n\n/**\n * Builds a knex postgres database connection\n *\n * @param dbConfig - The database config\n * @param overrides - Additional options to merge with the config\n */\nexport function buildPgDatabaseConfig(\n  dbConfig: Config,\n  overrides?: Knex.Config,\n) {\n  return mergeDatabaseConfig(\n    dbConfig.get(),\n    {\n      connection: getPgConnectionConfig(dbConfig, !!overrides),\n      useNullAsDefault: true,\n    },\n    overrides,\n  );\n}\n\n/**\n * Gets the postgres connection config\n *\n * @param dbConfig - The database config\n * @param parseConnectionString - Flag to explicitly control connection string parsing\n */\nexport function getPgConnectionConfig(\n  dbConfig: Config,\n  parseConnectionString?: boolean,\n): Knex.PgConnectionConfig | string {\n  const connection = dbConfig.get('connection') as any;\n  const isConnectionString =\n    typeof connection === 'string' || connection instanceof String;\n  const autoParse = typeof parseConnectionString !== 'boolean';\n\n  const shouldParseConnectionString = autoParse\n    ? isConnectionString\n    : parseConnectionString && isConnectionString;\n\n  return shouldParseConnectionString\n    ? parsePgConnectionString(connection as string)\n    : connection;\n}\n\n/**\n * Parses a connection string using pg-connection-string\n *\n * @param connectionString - The postgres connection string\n */\nexport function parsePgConnectionString(connectionString: string) {\n  const parse = requirePgConnectionString();\n  return parse(connectionString);\n}\n\nfunction requirePgConnectionString() {\n  try {\n    return require('pg-connection-string').parse;\n  } catch (e) {\n    throw new ForwardedError(\"Postgres: Install 'pg-connection-string'\", e);\n  }\n}\n\n/**\n * Creates the missing Postgres database if it does not exist\n *\n * @param dbConfig - The database config\n * @param databases - The name of the databases to create\n */\nexport async function ensurePgDatabaseExists(\n  dbConfig: Config,\n  ...databases: Array<string>\n) {\n  const admin = createPgDatabaseClient(dbConfig, {\n    connection: {\n      database: 'postgres',\n    },\n  });\n\n  try {\n    const ensureDatabase = async (database: string) => {\n      const result = await admin\n        .from('pg_database')\n        .where('datname', database)\n        .count<Record<string, { count: string }>>();\n\n      if (parseInt(result[0].count, 10) > 0) {\n        return;\n      }\n\n      await admin.raw(`CREATE DATABASE ??`, [database]);\n    };\n\n    await Promise.all(databases.map(ensureDatabase));\n  } finally {\n    await admin.destroy();\n  }\n}\n\n/**\n * Creates the missing Postgres schema if it does not exist\n *\n * @param dbConfig - The database config\n * @param schemas - The name of the schemas to create\n */\nexport async function ensurePgSchemaExists(\n  dbConfig: Config,\n  ...schemas: Array<string>\n): Promise<void> {\n  const admin = createPgDatabaseClient(dbConfig);\n\n  try {\n    const ensureSchema = async (database: string) => {\n      await admin.raw(`CREATE SCHEMA IF NOT EXISTS ??`, [database]);\n    };\n\n    await Promise.all(schemas.map(ensureSchema));\n  } finally {\n    await admin.destroy();\n  }\n}\n\n/**\n * PostgreSQL database connector.\n *\n * Exposes database connector functionality via an immutable object.\n */\nexport const pgConnector: DatabaseConnector = Object.freeze({\n  createClient: createPgDatabaseClient,\n  ensureDatabaseExists: ensurePgDatabaseExists,\n  ensureSchemaExists: ensurePgSchemaExists,\n  createNameOverride: defaultNameOverride,\n  createSchemaOverride: defaultSchemaOverride,\n  parseConnectionString: parsePgConnectionString,\n});\n","/*\n * Copyright 2020 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Config } from '@backstage/config';\nimport { ensureDirSync } from 'fs-extra';\nimport knexFactory, { Knex } from 'knex';\nimport path from 'path';\nimport { mergeDatabaseConfig } from '../config';\nimport { DatabaseConnector } from '../types';\n\n/**\n * Creates a knex SQLite3 database connection\n *\n * @param dbConfig - The database config\n * @param overrides - Additional options to merge with the config\n */\nexport function createSqliteDatabaseClient(\n  dbConfig: Config,\n  overrides?: Knex.Config,\n) {\n  const knexConfig = buildSqliteDatabaseConfig(dbConfig, overrides);\n\n  // If storage on disk is used, ensure that the directory exists\n  if (\n    (knexConfig.connection as Knex.Sqlite3ConnectionConfig).filename &&\n    (knexConfig.connection as Knex.Sqlite3ConnectionConfig).filename !==\n      ':memory:'\n  ) {\n    const { filename } = knexConfig.connection as Knex.Sqlite3ConnectionConfig;\n    const directory = path.dirname(filename);\n\n    ensureDirSync(directory);\n  }\n\n  const database = knexFactory(knexConfig);\n\n  database.client.pool.on('createSuccess', (_eventId: any, resource: any) => {\n    resource.run('PRAGMA foreign_keys = ON', () => {});\n  });\n\n  return database;\n}\n\n/**\n * Builds a knex SQLite3 connection config\n *\n * @param dbConfig - The database config\n * @param overrides - Additional options to merge with the config\n */\nexport function buildSqliteDatabaseConfig(\n  dbConfig: Config,\n  overrides?: Knex.Config,\n): Knex.Config {\n  const baseConfig = dbConfig.get<Knex.Config>();\n\n  // Normalize config to always contain a connection object\n  if (typeof baseConfig.connection === 'string') {\n    baseConfig.connection = { filename: baseConfig.connection };\n  }\n  if (overrides && typeof overrides.connection === 'string') {\n    overrides.connection = { filename: overrides.connection };\n  }\n\n  const config: Knex.Config = mergeDatabaseConfig(\n    {\n      connection: {},\n    },\n    baseConfig,\n    {\n      useNullAsDefault: true,\n    },\n    overrides,\n  );\n\n  return config;\n}\n\n/**\n * Provides a partial knex SQLite3 config to override database name.\n */\nexport function createSqliteNameOverride(name: string): Partial<Knex.Config> {\n  return {\n    connection: parseSqliteConnectionString(name),\n  };\n}\n\n/**\n * Produces a partial knex SQLite3 connection config with database name.\n */\nexport function parseSqliteConnectionString(\n  name: string,\n): Knex.Sqlite3ConnectionConfig {\n  return {\n    filename: name,\n  };\n}\n\n/**\n * SQLite3 database connector.\n *\n * Exposes database connector functionality via an immutable object.\n */\nexport const sqlite3Connector: DatabaseConnector = Object.freeze({\n  createClient: createSqliteDatabaseClient,\n  createNameOverride: createSqliteNameOverride,\n  parseConnectionString: parseSqliteConnectionString,\n});\n","/*\n * Copyright 2020 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Config } from '@backstage/config';\nimport { JsonObject } from '@backstage/types';\nimport { InputError } from '@backstage/errors';\nimport knexFactory, { Knex } from 'knex';\nimport { mergeDatabaseConfig } from './config';\nimport { DatabaseConnector } from './types';\n\nimport { mysqlConnector, pgConnector, sqlite3Connector } from './connectors';\n\ntype DatabaseClient =\n  | 'pg'\n  | 'better-sqlite3'\n  | 'sqlite3'\n  | 'mysql'\n  | 'mysql2'\n  | string;\n\n/**\n * Mapping of client type to supported database connectors\n *\n * Database connectors can be aliased here, for example mysql2 uses\n * the same connector as mysql.\n */\nconst ConnectorMapping: Record<DatabaseClient, DatabaseConnector> = {\n  pg: pgConnector,\n  'better-sqlite3': sqlite3Connector,\n  sqlite3: sqlite3Connector,\n  mysql: mysqlConnector,\n  mysql2: mysqlConnector,\n};\n\n/**\n * Creates a knex database connection\n *\n * @public\n * @param dbConfig - The database config\n * @param overrides - Additional options to merge with the config\n */\nexport function createDatabaseClient(\n  dbConfig: Config,\n  overrides?: Partial<Knex.Config>,\n) {\n  const client: DatabaseClient = dbConfig.getString('client');\n\n  return (\n    ConnectorMapping[client]?.createClient(dbConfig, overrides) ??\n    knexFactory(mergeDatabaseConfig(dbConfig.get(), overrides))\n  );\n}\n\n/**\n * Ensures that the given databases all exist, creating them if they do not.\n *\n * @public\n */\nexport async function ensureDatabaseExists(\n  dbConfig: Config,\n  ...databases: Array<string>\n): Promise<void> {\n  const client: DatabaseClient = dbConfig.getString('client');\n\n  return ConnectorMapping[client]?.ensureDatabaseExists?.(\n    dbConfig,\n    ...databases,\n  );\n}\n\n/**\n * Ensures that the given schemas all exist, creating them if they do not.\n *\n * @public\n */\nexport async function ensureSchemaExists(\n  dbConfig: Config,\n  ...schemas: Array<string>\n): Promise<void> {\n  const client: DatabaseClient = dbConfig.getString('client');\n\n  return await ConnectorMapping[client]?.ensureSchemaExists?.(\n    dbConfig,\n    ...schemas,\n  );\n}\n\n/**\n * Provides a `Knex.Config` object with the provided database name for a given\n * client.\n */\nexport function createNameOverride(\n  client: string,\n  name: string,\n): Partial<Knex.Config> {\n  try {\n    return ConnectorMapping[client].createNameOverride(name);\n  } catch (e) {\n    throw new InputError(\n      `Unable to create database name override for '${client}' connector`,\n      e,\n    );\n  }\n}\n\n/**\n * Provides a `Knex.Config` object with the provided database schema for a given\n * client. Currently only supported by `pg`.\n */\nexport function createSchemaOverride(\n  client: string,\n  name: string,\n): Partial<Knex.Config | undefined> {\n  try {\n    return ConnectorMapping[client]?.createSchemaOverride?.(name);\n  } catch (e) {\n    throw new InputError(\n      `Unable to create database schema override for '${client}' connector`,\n      e,\n    );\n  }\n}\n\n/**\n * Parses a connection string for a given client and provides a connection config.\n */\nexport function parseConnectionString(\n  connectionString: string,\n  client?: string,\n): Knex.StaticConnectionConfig {\n  if (typeof client === 'undefined' || client === null) {\n    throw new InputError(\n      'Database connection string client type auto-detection is not yet supported.',\n    );\n  }\n\n  try {\n    return ConnectorMapping[client].parseConnectionString(connectionString);\n  } catch (e) {\n    throw new InputError(\n      `Unable to parse connection string for '${client}' connector`,\n    );\n  }\n}\n\n/**\n * Normalizes a connection config or string into an object which can be passed\n * to Knex.\n */\nexport function normalizeConnection(\n  connection: Knex.StaticConnectionConfig | JsonObject | string | undefined,\n  client: string,\n): Partial<Knex.StaticConnectionConfig> {\n  if (typeof connection === 'undefined' || connection === null) {\n    return {};\n  }\n\n  return typeof connection === 'string' || connection instanceof String\n    ? parseConnectionString(connection as string, client)\n    : connection;\n}\n","/*\n * Copyright 2021 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Config, ConfigReader } from '@backstage/config';\nimport { JsonObject } from '@backstage/types';\nimport { Knex } from 'knex';\nimport { merge, omit } from 'lodash';\nimport { mergeDatabaseConfig } from './config';\nimport {\n  createDatabaseClient,\n  createNameOverride,\n  createSchemaOverride,\n  ensureDatabaseExists,\n  ensureSchemaExists,\n  normalizeConnection,\n} from './connection';\nimport { PluginDatabaseManager } from './types';\nimport path from 'path';\n\n/**\n * Provides a config lookup path for a plugin's config block.\n */\nfunction pluginPath(pluginId: string): string {\n  return `plugin.${pluginId}`;\n}\n\n/**\n * Creation options for {@link DatabaseManager}.\n *\n * @public\n */\nexport type DatabaseManagerOptions = {\n  migrations?: PluginDatabaseManager['migrations'];\n};\n\n/**\n * Manages database connections for Backstage backend plugins.\n *\n * The database manager allows the user to set connection and client settings on\n * a per pluginId basis by defining a database config block under\n * `plugin.<pluginId>` in addition to top level defaults. Optionally, a user may\n * set `prefix` which is used to prefix generated database names if config is\n * not provided.\n *\n * @public\n */\nexport class DatabaseManager {\n  /**\n   * Creates a {@link DatabaseManager} from `backend.database` config.\n   *\n   * @param config - The loaded application configuration.\n   * @param options - An optional configuration object.\n   */\n  static fromConfig(\n    config: Config,\n    options?: DatabaseManagerOptions,\n  ): DatabaseManager {\n    const databaseConfig = config.getConfig('backend.database');\n\n    return new DatabaseManager(\n      databaseConfig,\n      databaseConfig.getOptionalString('prefix'),\n      options,\n    );\n  }\n\n  private constructor(\n    private readonly config: Config,\n    private readonly prefix: string = 'backstage_plugin_',\n    private readonly options?: DatabaseManagerOptions,\n  ) {}\n\n  /**\n   * Generates a PluginDatabaseManager for consumption by plugins.\n   *\n   * @param pluginId - The plugin that the database manager should be created for. Plugin names\n   * should be unique as they are used to look up database config overrides under\n   * `backend.database.plugin`.\n   */\n  forPlugin(pluginId: string): PluginDatabaseManager {\n    const _this = this;\n\n    return {\n      getClient(): Promise<Knex> {\n        return _this.getDatabase(pluginId);\n      },\n      migrations: {\n        skip: false,\n        ..._this.options?.migrations,\n      },\n    };\n  }\n\n  /**\n   * Provides the canonical database name for a given plugin.\n   *\n   * This method provides the effective database name which is determined using global\n   * and plugin specific database config. If no explicit database name is configured\n   * and `pluginDivisionMode` is not `schema`, this method will provide a generated name\n   * which is the pluginId prefixed with 'backstage_plugin_'. If `pluginDivisionMode` is\n   * `schema`, it will fallback to using the default database for the knex instance.\n   *\n   * @param pluginId - Lookup the database name for given plugin\n   * @returns String representing the plugin's database name\n   */\n  private getDatabaseName(pluginId: string): string | undefined {\n    const connection = this.getConnectionConfig(pluginId);\n\n    if (this.getClientType(pluginId).client.includes('sqlite3')) {\n      const sqliteFilename: string | undefined = (\n        connection as Knex.Sqlite3ConnectionConfig\n      ).filename;\n\n      if (sqliteFilename === ':memory:') {\n        return sqliteFilename;\n      }\n\n      const sqliteDirectory =\n        (connection as { directory?: string }).directory ?? '.';\n\n      return path.join(sqliteDirectory, sqliteFilename ?? `${pluginId}.sqlite`);\n    }\n\n    const databaseName = (connection as Knex.ConnectionConfig)?.database;\n\n    // `pluginDivisionMode` as `schema` should use overridden databaseName if supplied or fallback to default knex database\n    if (this.getPluginDivisionModeConfig() === 'schema') {\n      return databaseName;\n    }\n\n    // all other supported databases should fallback to an auto-prefixed name\n    return databaseName ?? `${this.prefix}${pluginId}`;\n  }\n\n  /**\n   * Provides the client type which should be used for a given plugin.\n   *\n   * The client type is determined by plugin specific config if present.\n   * Otherwise the base client is used as the fallback.\n   *\n   * @param pluginId - Plugin to get the client type for\n   * @returns Object with client type returned as `client` and boolean\n   *          representing whether or not the client was overridden as\n   *          `overridden`\n   */\n  private getClientType(pluginId: string): {\n    client: string;\n    overridden: boolean;\n  } {\n    const pluginClient = this.config.getOptionalString(\n      `${pluginPath(pluginId)}.client`,\n    );\n\n    const baseClient = this.config.getString('client');\n    const client = pluginClient ?? baseClient;\n    return {\n      client,\n      overridden: client !== baseClient,\n    };\n  }\n\n  /**\n   * Provides the knexConfig which should be used for a given plugin.\n   *\n   * @param pluginId - Plugin to get the knexConfig for\n   * @returns The merged knexConfig value or undefined if it isn't specified\n   */\n  private getAdditionalKnexConfig(pluginId: string): JsonObject | undefined {\n    const pluginConfig = this.config\n      .getOptionalConfig(`${pluginPath(pluginId)}.knexConfig`)\n      ?.get<JsonObject>();\n\n    const baseConfig = this.config\n      .getOptionalConfig('knexConfig')\n      ?.get<JsonObject>();\n\n    return merge(baseConfig, pluginConfig);\n  }\n\n  private getEnsureExistsConfig(pluginId: string): boolean {\n    const baseConfig = this.config.getOptionalBoolean('ensureExists') ?? true;\n    return (\n      this.config.getOptionalBoolean(`${pluginPath(pluginId)}.ensureExists`) ??\n      baseConfig\n    );\n  }\n\n  private getPluginDivisionModeConfig(): string {\n    return this.config.getOptionalString('pluginDivisionMode') ?? 'database';\n  }\n\n  /**\n   * Provides a Knex connection plugin config by combining base and plugin\n   * config.\n   *\n   * This method provides a baseConfig for a plugin database connector. If the\n   * client type has not been overridden, the global connection config will be\n   * included with plugin specific config as the base. Values from the plugin\n   * connection take precedence over the base. Base database name is omitted for\n   * all supported databases excluding SQLite unless `pluginDivisionMode` is set\n   * to `schema`.\n   */\n  private getConnectionConfig(\n    pluginId: string,\n  ): Partial<Knex.StaticConnectionConfig> {\n    const { client, overridden } = this.getClientType(pluginId);\n\n    let baseConnection = normalizeConnection(\n      this.config.get('connection'),\n      this.config.getString('client'),\n    );\n\n    if (\n      client.includes('sqlite3') &&\n      'filename' in baseConnection &&\n      baseConnection.filename !== ':memory:'\n    ) {\n      throw new Error(\n        '`connection.filename` is not supported for the base sqlite connection. Prefer `connection.directory` or provide a filename for the plugin connection instead.',\n      );\n    }\n\n    // Databases cannot be shared unless the `pluginDivisionMode` is set to `schema`. The\n    // `database` property from the base connection is omitted unless `pluginDivisionMode`\n    // is set to `schema`. SQLite3's `filename` property is an exception as this is used as a\n    // directory elsewhere so we preserve `filename`.\n    if (this.getPluginDivisionModeConfig() !== 'schema') {\n      baseConnection = omit(baseConnection, 'database');\n    }\n\n    // get and normalize optional plugin specific database connection\n    const connection = normalizeConnection(\n      this.config.getOptional(`${pluginPath(pluginId)}.connection`),\n      client,\n    );\n\n    return {\n      // include base connection if client type has not been overridden\n      ...(overridden ? {} : baseConnection),\n      ...connection,\n    };\n  }\n\n  /**\n   * Provides a Knex database config for a given plugin.\n   *\n   * This method provides a Knex configuration object along with the plugin's\n   * client type.\n   *\n   * @param pluginId - The plugin that the database config should correspond with\n   */\n  private getConfigForPlugin(pluginId: string): Knex.Config {\n    const { client } = this.getClientType(pluginId);\n\n    return {\n      ...this.getAdditionalKnexConfig(pluginId),\n      client,\n      connection: this.getConnectionConfig(pluginId),\n    };\n  }\n\n  /**\n   * Provides a partial `Knex.Config` database schema override for a given\n   * plugin.\n   *\n   * @param pluginId - Target plugin to get database schema override\n   * @returns Partial `Knex.Config` with database schema override\n   */\n  private getSchemaOverrides(pluginId: string): Knex.Config | undefined {\n    return createSchemaOverride(this.getClientType(pluginId).client, pluginId);\n  }\n\n  /**\n   * Provides a partial `Knex.Config`• database name override for a given plugin.\n   *\n   * @param pluginId - Target plugin to get database name override\n   * @returns Partial `Knex.Config` with database name override\n   */\n  private getDatabaseOverrides(pluginId: string): Knex.Config {\n    const databaseName = this.getDatabaseName(pluginId);\n    return databaseName\n      ? createNameOverride(this.getClientType(pluginId).client, databaseName)\n      : {};\n  }\n\n  /**\n   * Provides a scoped Knex client for a plugin as per application config.\n   *\n   * @param pluginId - Plugin to get a Knex client for\n   * @returns Promise which resolves to a scoped Knex database client for a\n   *          plugin\n   */\n  private async getDatabase(pluginId: string): Promise<Knex> {\n    const pluginConfig = new ConfigReader(\n      this.getConfigForPlugin(pluginId) as JsonObject,\n    );\n\n    const databaseName = this.getDatabaseName(pluginId);\n    if (databaseName && this.getEnsureExistsConfig(pluginId)) {\n      try {\n        await ensureDatabaseExists(pluginConfig, databaseName);\n      } catch (error) {\n        throw new Error(\n          `Failed to connect to the database to make sure that '${databaseName}' exists, ${error}`,\n        );\n      }\n    }\n\n    let schemaOverrides;\n    if (this.getPluginDivisionModeConfig() === 'schema') {\n      try {\n        schemaOverrides = this.getSchemaOverrides(pluginId);\n        await ensureSchemaExists(pluginConfig, pluginId);\n      } catch (error) {\n        throw new Error(\n          `Failed to connect to the database to make sure that schema for plugin '${pluginId}' exists, ${error}`,\n        );\n      }\n    }\n\n    const databaseClientOverrides = mergeDatabaseConfig(\n      {},\n      this.getDatabaseOverrides(pluginId),\n      schemaOverrides,\n    );\n\n    return createDatabaseClient(pluginConfig, databaseClientOverrides);\n  }\n}\n","/*\n * Copyright 2021 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n/**\n * Tries to deduce whether a thrown error is a database conflict.\n *\n * @public\n * @param e - A thrown error\n * @returns True if the error looks like it was a conflict error thrown by a\n *          known database engine\n */\nexport function isDatabaseConflictError(e: unknown) {\n  const message = (e as any)?.message;\n\n  return (\n    typeof message === 'string' &&\n    (/SQLITE_CONSTRAINT(?:_UNIQUE)?: UNIQUE/.test(message) ||\n      /unique constraint/.test(message))\n  );\n}\n","/*\n * Copyright 2020 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Config } from '@backstage/config';\nimport { CorsOptions } from 'cors';\nimport { Minimatch } from 'minimatch';\n\nexport type BaseOptions = {\n  listenPort?: string | number;\n  listenHost?: string;\n};\n\nexport type HttpsSettings = {\n  certificate: CertificateGenerationOptions | CertificateReferenceOptions;\n};\n\nexport type CertificateReferenceOptions = {\n  key: string;\n  cert: string;\n};\n\nexport type CertificateGenerationOptions = {\n  hostname: string;\n};\n\nexport type CertificateAttributes = {\n  commonName: string;\n};\n\n/**\n * A map from CSP directive names to their values.\n */\nexport type CspOptions = Record<string, string[]>;\n\ntype StaticOrigin = boolean | string | RegExp | (boolean | string | RegExp)[];\n\ntype CustomOrigin = (\n  requestOrigin: string | undefined,\n  callback: (err: Error | null, origin?: StaticOrigin) => void,\n) => void;\n\n/**\n * Reads some base options out of a config object.\n *\n * @param config - The root of a backend config object\n * @returns A base options object\n *\n * @example\n * ```json\n * {\n *   baseUrl: \"http://localhost:7007\",\n *   listen: \"0.0.0.0:7007\"\n * }\n * ```\n */\nexport function readBaseOptions(config: Config): BaseOptions {\n  if (typeof config.get('listen') === 'string') {\n    // TODO(freben): Expand this to support more addresses and perhaps optional\n    const { host, port } = parseListenAddress(config.getString('listen'));\n\n    return removeUnknown({\n      listenPort: port,\n      listenHost: host,\n    });\n  }\n\n  const port = config.getOptional('listen.port');\n  if (\n    typeof port !== 'undefined' &&\n    typeof port !== 'number' &&\n    typeof port !== 'string'\n  ) {\n    throw new Error(\n      `Invalid type in config for key 'backend.listen.port', got ${typeof port}, wanted string or number`,\n    );\n  }\n\n  return removeUnknown({\n    listenPort: port,\n    listenHost: config.getOptionalString('listen.host'),\n    baseUrl: config.getOptionalString('baseUrl'),\n  });\n}\n\n/**\n * Attempts to read a CORS options object from the root of a config object.\n *\n * @param config - The root of a backend config object\n * @returns A CORS options object, or undefined if not specified\n *\n * @example\n * ```json\n * {\n *   cors: {\n *    origin: \"http://localhost:3000\",\n *    credentials: true\n *   }\n * }\n * ```\n */\nexport function readCorsOptions(config: Config): CorsOptions | undefined {\n  const cc = config.getOptionalConfig('cors');\n  if (!cc) {\n    return undefined;\n  }\n\n  return removeUnknown({\n    origin: createCorsOriginMatcher(getOptionalStringOrStrings(cc, 'origin')),\n    methods: getOptionalStringOrStrings(cc, 'methods'),\n    allowedHeaders: getOptionalStringOrStrings(cc, 'allowedHeaders'),\n    exposedHeaders: getOptionalStringOrStrings(cc, 'exposedHeaders'),\n    credentials: cc.getOptionalBoolean('credentials'),\n    maxAge: cc.getOptionalNumber('maxAge'),\n    preflightContinue: cc.getOptionalBoolean('preflightContinue'),\n    optionsSuccessStatus: cc.getOptionalNumber('optionsSuccessStatus'),\n  });\n}\n\n/**\n * Attempts to read a CSP options object from the root of a config object.\n *\n * @param config - The root of a backend config object\n * @returns A CSP options object, or undefined if not specified. Values can be\n *          false as well, which means to remove the default behavior for that\n *          key.\n *\n * @example\n * ```yaml\n * backend:\n *   csp:\n *     connect-src: [\"'self'\", 'http:', 'https:']\n *     upgrade-insecure-requests: false\n * ```\n */\nexport function readCspOptions(\n  config: Config,\n): Record<string, string[] | false> | undefined {\n  const cc = config.getOptionalConfig('csp');\n  if (!cc) {\n    return undefined;\n  }\n\n  const result: Record<string, string[] | false> = {};\n  for (const key of cc.keys()) {\n    if (cc.get(key) === false) {\n      result[key] = false;\n    } else {\n      result[key] = cc.getStringArray(key);\n    }\n  }\n\n  return result;\n}\n\n/**\n * Attempts to read a https settings object from the root of a config object.\n *\n * @param config - The root of a backend config object\n * @returns A https settings object, or undefined if not specified\n *\n * @example\n * ```json\n * {\n *   https: {\n *    certificate: ...\n *   }\n * }\n * ```\n */\nexport function readHttpsSettings(config: Config): HttpsSettings | undefined {\n  const https = config.getOptional('https');\n  if (https === true) {\n    const baseUrl = config.getString('baseUrl');\n    let hostname;\n    try {\n      hostname = new URL(baseUrl).hostname;\n    } catch (error) {\n      throw new Error(`Invalid backend.baseUrl \"${baseUrl}\"`);\n    }\n\n    return { certificate: { hostname } };\n  }\n\n  const cc = config.getOptionalConfig('https');\n  if (!cc) {\n    return undefined;\n  }\n\n  const certificateConfig = cc.get('certificate');\n\n  const cfg = {\n    certificate: certificateConfig,\n  };\n\n  return removeUnknown(cfg as HttpsSettings);\n}\n\nfunction getOptionalStringOrStrings(\n  config: Config,\n  key: string,\n): string | string[] | undefined {\n  const value = config.getOptional(key);\n  if (value === undefined || isStringOrStrings(value)) {\n    return value;\n  }\n  throw new Error(`Expected string or array of strings, got ${typeof value}`);\n}\n\nfunction createCorsOriginMatcher(\n  originValue: string | string[] | undefined,\n): CustomOrigin | undefined {\n  if (originValue === undefined) {\n    return originValue;\n  }\n\n  if (!isStringOrStrings(originValue)) {\n    throw new Error(\n      `Expected string or array of strings, got ${typeof originValue}`,\n    );\n  }\n\n  const allowedOrigin =\n    typeof originValue === 'string' ? [originValue] : originValue;\n\n  const allowedOriginPatterns =\n    allowedOrigin?.map(\n      pattern => new Minimatch(pattern, { nocase: true, noglobstar: true }),\n    ) ?? [];\n\n  return (origin, callback) => {\n    return callback(\n      null,\n      allowedOriginPatterns.some(pattern => pattern.match(origin ?? '')),\n    );\n  };\n}\n\nfunction isStringOrStrings(value: any): value is string | string[] {\n  return typeof value === 'string' || isStringArray(value);\n}\n\nfunction isStringArray(value: any): value is string[] {\n  if (!Array.isArray(value)) {\n    return false;\n  }\n  for (const v of value) {\n    if (typeof v !== 'string') {\n      return false;\n    }\n  }\n  return true;\n}\n\nfunction removeUnknown<T extends object>(obj: T): T {\n  return Object.fromEntries(\n    Object.entries(obj).filter(([, v]) => v !== undefined),\n  ) as T;\n}\n\nfunction parseListenAddress(value: string): { host?: string; port?: number } {\n  const parts = value.split(':');\n  if (parts.length === 1) {\n    return { port: parseInt(parts[0], 10) };\n  }\n  if (parts.length === 2) {\n    return { host: parts[0], port: parseInt(parts[1], 10) };\n  }\n  throw new Error(\n    `Unable to parse listen address ${value}, expected <port> or <host>:<port>`,\n  );\n}\n","/*\n * Copyright 2020 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n// Find all active hot module APIs of all ancestors of a module, including the module itself\nfunction findAllAncestors(_module: NodeModule): NodeModule[] {\n  const ancestors = new Array<NodeModule>();\n  const parentIds = new Set<string | number>();\n\n  function add(id: string | number, m: NodeModule) {\n    if (parentIds.has(id)) {\n      return;\n    }\n    parentIds.add(id);\n    ancestors.push(m);\n\n    for (const parentId of (m as any).parents) {\n      const parent = require.cache[parentId];\n      if (parent) {\n        add(parentId, parent);\n      }\n    }\n  }\n\n  add(_module.id, _module);\n\n  return ancestors;\n}\n\n/**\n * useHotCleanup allows cleanup of ongoing effects when a module is\n * hot-reloaded during development. The cleanup function will be called\n * whenever the module itself or any of its parent modules is hot-reloaded.\n *\n * Useful for cleaning intervals, timers, requests etc\n *\n * @public\n * @example\n * ```ts\n * const intervalId = setInterval(doStuff, 1000);\n * useHotCleanup(module, () => clearInterval(intervalId));\n * ```\n * @param _module - Reference to the current module where you invoke the fn\n * @param cancelEffect - Fn that cleans up the ongoing effects\n */\nexport function useHotCleanup(_module: NodeModule, cancelEffect: () => void) {\n  if (_module.hot) {\n    const ancestors = findAllAncestors(_module);\n    let cancelled = false;\n\n    const handler = () => {\n      if (!cancelled) {\n        cancelled = true;\n        cancelEffect();\n      }\n    };\n\n    for (const m of ancestors) {\n      m.hot?.addDisposeHandler(handler);\n    }\n  }\n}\n\nconst CURRENT_HOT_MEMOIZE_INDEX_KEY = 'backstage.io/hmr-memoize-key';\n\n/**\n * Memoizes a generated value across hot-module reloads. This is useful for\n * stateful parts of the backend, e.g. to retain a database.\n *\n * @public\n * @example\n * ```ts\n * const db = useHotMemoize(module, () => createDB(dbParams));\n * ```\n *\n * **NOTE:** Do not use inside conditionals or loops,\n * same rules as for hooks apply (https://reactjs.org/docs/hooks-rules.html)\n *\n * @param _module - Reference to the current module where you invoke the fn\n * @param valueFactory - Fn that returns the value you want to memoize\n */\nexport function useHotMemoize<T>(\n  _module: NodeModule,\n  valueFactory: () => T,\n): T {\n  if (!_module.hot) {\n    return valueFactory();\n  }\n\n  // When starting blank, reset the counter\n  if (!_module.hot.data?.[CURRENT_HOT_MEMOIZE_INDEX_KEY]) {\n    for (const ancestor of findAllAncestors(_module)) {\n      ancestor.hot?.addDisposeHandler(data => {\n        data[CURRENT_HOT_MEMOIZE_INDEX_KEY] = 1;\n      });\n    }\n\n    _module.hot.data = {\n      ..._module.hot.data,\n      [CURRENT_HOT_MEMOIZE_INDEX_KEY]: 1,\n    };\n  }\n\n  // Store data per module, based on the order of the code invocation\n  const index = _module.hot.data[CURRENT_HOT_MEMOIZE_INDEX_KEY]++;\n  const value = _module.hot.data[index] ?? valueFactory();\n\n  // Always add a handler that, upon a HMR event, reinstates the value.\n  _module.hot.addDisposeHandler(data => {\n    data[index] = value;\n  });\n\n  return value;\n}\n","/*\n * Copyright 2020 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  AuthenticationError,\n  ConflictError,\n  ErrorResponseBody,\n  InputError,\n  NotAllowedError,\n  NotFoundError,\n  NotModifiedError,\n  serializeError,\n} from '@backstage/errors';\nimport { ErrorRequestHandler, NextFunction, Request, Response } from 'express';\nimport { Logger } from 'winston';\nimport { getRootLogger } from '../logging';\n\n/**\n * Options passed to the {@link errorHandler} middleware.\n *\n * @public\n */\nexport type ErrorHandlerOptions = {\n  /**\n   * Whether error response bodies should show error stack traces or not.\n   *\n   * If not specified, by default shows stack traces only in development mode.\n   */\n  showStackTraces?: boolean;\n\n  /**\n   * Logger instance to log errors.\n   *\n   * If not specified, the root logger will be used.\n   */\n  logger?: Logger;\n\n  /**\n   * Whether any 4xx errors should be logged or not.\n   *\n   * If not specified, default to only logging 5xx errors.\n   */\n  logClientErrors?: boolean;\n};\n\n/**\n * Express middleware to handle errors during request processing.\n *\n * This is commonly the very last middleware in the chain.\n *\n * Its primary purpose is not to do translation of business logic exceptions,\n * but rather to be a global catch-all for uncaught \"fatal\" errors that are\n * expected to result in a 500 error. However, it also does handle some common\n * error types (such as http-error exceptions) and returns the enclosed status\n * code accordingly.\n *\n * @public\n * @returns An Express error request handler\n */\nexport function errorHandler(\n  options: ErrorHandlerOptions = {},\n): ErrorRequestHandler {\n  const showStackTraces =\n    options.showStackTraces ?? process.env.NODE_ENV === 'development';\n\n  const logger = (options.logger || getRootLogger()).child({\n    type: 'errorHandler',\n  });\n\n  return (error: Error, req: Request, res: Response, next: NextFunction) => {\n    const statusCode = getStatusCode(error);\n    if (options.logClientErrors || statusCode >= 500) {\n      logger.error(error);\n    }\n\n    if (res.headersSent) {\n      // If the headers have already been sent, do not send the response again\n      // as this will throw an error in the backend.\n      next(error);\n      return;\n    }\n\n    const body: ErrorResponseBody = {\n      error: serializeError(error, { includeStack: showStackTraces }),\n      request: { method: req.method, url: req.url },\n      response: { statusCode },\n    };\n\n    res.status(statusCode).json(body);\n  };\n}\n\nfunction getStatusCode(error: Error): number {\n  // Look for common http library status codes\n  const knownStatusCodeFields = ['statusCode', 'status'];\n  for (const field of knownStatusCodeFields) {\n    const statusCode = (error as any)[field];\n    if (\n      typeof statusCode === 'number' &&\n      (statusCode | 0) === statusCode && // is whole integer\n      statusCode >= 100 &&\n      statusCode <= 599\n    ) {\n      return statusCode;\n    }\n  }\n\n  // Handle well-known error types\n  switch (error.name) {\n    case NotModifiedError.name:\n      return 304;\n    case InputError.name:\n      return 400;\n    case AuthenticationError.name:\n      return 401;\n    case NotAllowedError.name:\n      return 403;\n    case NotFoundError.name:\n      return 404;\n    case ConflictError.name:\n      return 409;\n    default:\n      break;\n  }\n\n  // Fall back to internal server error\n  return 500;\n}\n","/*\n * Copyright 2020 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { NextFunction, Request, RequestHandler, Response } from 'express';\n\n/**\n * Express middleware to handle requests for missing routes.\n *\n * Should be used as the very last handler in the chain, as it unconditionally\n * returns a 404 status.\n *\n * @public\n * @returns An Express request handler\n */\nexport function notFoundHandler(): RequestHandler {\n  /* eslint-disable @typescript-eslint/no-unused-vars */\n  return (_request: Request, response: Response, _next: NextFunction) => {\n    response.status(404).send();\n  };\n}\n","/*\n * Copyright 2020 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { RequestHandler } from 'express';\nimport { Logger } from 'winston';\nimport morgan from 'morgan';\nimport { getRootLogger } from '../logging';\n\n/**\n * Logs incoming requests.\n *\n * @public\n * @param logger - An optional logger to use. If not specified, the root logger will be used.\n * @returns An Express request handler\n */\nexport function requestLoggingHandler(logger?: Logger): RequestHandler {\n  const actualLogger = (logger || getRootLogger()).child({\n    type: 'incomingRequest',\n  });\n\n  return morgan('combined', {\n    stream: {\n      write(message: String) {\n        actualLogger.info(message.trimRight());\n      },\n    },\n  });\n}\n","/*\n * Copyright 2020 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { NextFunction, Request, Response, RequestHandler } from 'express';\n\n/**\n * A custom status checking function, passed to {@link statusCheckHandler} and\n * {@link createStatusCheckRouter}.\n *\n * @public\n */\nexport type StatusCheck = () => Promise<any>;\n\n/**\n * Options passed to {@link statusCheckHandler}.\n *\n * @public\n */\nexport interface StatusCheckHandlerOptions {\n  /**\n   * Optional status function which returns a message.\n   */\n  statusCheck?: StatusCheck;\n}\n\n/**\n * Express middleware for status checks.\n *\n * This is commonly used to implement healthcheck and readiness routes.\n *\n * @public\n * @param options - An optional configuration object.\n * @returns An Express error request handler\n */\nexport async function statusCheckHandler(\n  options: StatusCheckHandlerOptions = {},\n): Promise<RequestHandler> {\n  const statusCheck: StatusCheck = options.statusCheck\n    ? options.statusCheck\n    : () => Promise.resolve({ status: 'ok' });\n\n  return async (_request: Request, response: Response, next: NextFunction) => {\n    try {\n      const status = await statusCheck();\n      response.status(200).header('').send(status);\n    } catch (err) {\n      next(err);\n    }\n  };\n}\n","/*\n * Copyright 2020 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport fs from 'fs-extra';\nimport { resolve as resolvePath, dirname } from 'path';\nimport express from 'express';\nimport * as http from 'http';\nimport * as https from 'https';\nimport { Logger } from 'winston';\nimport { HttpsSettings } from './config';\n\nconst ALMOST_MONTH_IN_MS = 25 * 24 * 60 * 60 * 1000;\n\nconst IP_HOSTNAME_REGEX = /:|^\\d+\\.\\d+\\.\\d+\\.\\d+$/;\n\n/**\n * Creates a Http server instance based on an Express application.\n *\n * @param app - The Express application object\n * @param logger - Optional Winston logger object\n * @returns A Http server instance\n *\n */\nexport function createHttpServer(\n  app: express.Express,\n  logger?: Logger,\n): http.Server {\n  logger?.info('Initializing http server');\n\n  return http.createServer(app);\n}\n\n/**\n * Creates a Https server instance based on an Express application.\n *\n * @param app - The Express application object\n * @param httpsSettings - HttpsSettings for self-signed certificate generation\n * @param logger - Optional Winston logger object\n * @returns A Https server instance\n *\n */\nexport async function createHttpsServer(\n  app: express.Express,\n  httpsSettings: HttpsSettings,\n  logger?: Logger,\n): Promise<http.Server> {\n  logger?.info('Initializing https server');\n\n  let credentials: { key: string | Buffer; cert: string | Buffer };\n\n  if ('hostname' in httpsSettings?.certificate) {\n    credentials = await getGeneratedCertificate(\n      httpsSettings.certificate.hostname,\n      logger,\n    );\n  } else {\n    logger?.info('Loading certificate from config');\n\n    credentials = {\n      key: httpsSettings?.certificate?.key,\n      cert: httpsSettings?.certificate?.cert,\n    };\n  }\n\n  if (!credentials.key || !credentials.cert) {\n    throw new Error('Invalid HTTPS credentials');\n  }\n\n  return https.createServer(credentials, app) as http.Server;\n}\n\nasync function getGeneratedCertificate(hostname: string, logger?: Logger) {\n  const hasModules = await fs.pathExists('node_modules');\n  let certPath;\n  if (hasModules) {\n    certPath = resolvePath(\n      'node_modules/.cache/backstage-backend/dev-cert.pem',\n    );\n    await fs.ensureDir(dirname(certPath));\n  } else {\n    certPath = resolvePath('.dev-cert.pem');\n  }\n\n  let cert = undefined;\n  if (await fs.pathExists(certPath)) {\n    const stat = await fs.stat(certPath);\n    const ageMs = Date.now() - stat.ctimeMs;\n    if (stat.isFile() && ageMs < ALMOST_MONTH_IN_MS) {\n      cert = await fs.readFile(certPath);\n    }\n  }\n\n  if (cert) {\n    logger?.info('Using existing self-signed certificate');\n    return {\n      key: cert,\n      cert: cert,\n    };\n  }\n\n  logger?.info('Generating new self-signed certificate');\n  const newCert = await createCertificate(hostname);\n  await fs.writeFile(certPath, newCert.cert + newCert.key, 'utf8');\n  return newCert;\n}\n\nasync function createCertificate(hostname: string) {\n  const attributes = [\n    {\n      name: 'commonName',\n      value: 'dev-cert',\n    },\n  ];\n\n  const sans = [\n    {\n      type: 2, // DNS\n      value: 'localhost',\n    },\n    {\n      type: 2,\n      value: 'localhost.localdomain',\n    },\n    {\n      type: 2,\n      value: '[::1]',\n    },\n    {\n      type: 7, // IP\n      ip: '127.0.0.1',\n    },\n    {\n      type: 7,\n      ip: 'fe80::1',\n    },\n  ];\n\n  // Add hostname from backend.baseUrl if it doesn't already exist in our list of SANs\n  if (!sans.find(({ value, ip }) => value === hostname || ip === hostname)) {\n    sans.push(\n      IP_HOSTNAME_REGEX.test(hostname)\n        ? {\n            type: 7,\n            ip: hostname,\n          }\n        : {\n            type: 2,\n            value: hostname,\n          },\n    );\n  }\n\n  const params = {\n    algorithm: 'sha256',\n    keySize: 2048,\n    days: 30,\n    extensions: [\n      {\n        name: 'keyUsage',\n        keyCertSign: true,\n        digitalSignature: true,\n        nonRepudiation: true,\n        keyEncipherment: true,\n        dataEncipherment: true,\n      },\n      {\n        name: 'extKeyUsage',\n        serverAuth: true,\n        clientAuth: true,\n        codeSigning: true,\n        timeStamping: true,\n      },\n      {\n        name: 'subjectAltName',\n        altNames: sans,\n      },\n    ],\n  };\n\n  return new Promise<{ key: string; cert: string }>((resolve, reject) =>\n    require('selfsigned').generate(\n      attributes,\n      params,\n      (err: Error, bundle: { private: string; cert: string }) => {\n        if (err) {\n          reject(err);\n        } else {\n          resolve({ key: bundle.private, cert: bundle.cert });\n        }\n      },\n    ),\n  );\n}\n","/*\n * Copyright 2020 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Config } from '@backstage/config';\nimport compression from 'compression';\nimport cors from 'cors';\nimport express, { Router, ErrorRequestHandler } from 'express';\nimport helmet from 'helmet';\nimport { ContentSecurityPolicyOptions } from 'helmet/dist/types/middlewares/content-security-policy';\nimport * as http from 'http';\nimport stoppable from 'stoppable';\nimport { Logger } from 'winston';\nimport { useHotCleanup } from '../../hot';\nimport { getRootLogger } from '../../logging';\nimport {\n  errorHandler as defaultErrorHandler,\n  notFoundHandler,\n  requestLoggingHandler as defaultRequestLoggingHandler,\n} from '../../middleware';\nimport { RequestLoggingHandlerFactory, ServiceBuilder } from '../types';\nimport {\n  CspOptions,\n  HttpsSettings,\n  readBaseOptions,\n  readCorsOptions,\n  readCspOptions,\n  readHttpsSettings,\n} from './config';\nimport { createHttpServer, createHttpsServer } from './hostFactory';\n\nexport const DEFAULT_PORT = 7007;\n// '' is express default, which listens to all interfaces\nconst DEFAULT_HOST = '';\n\nexport class ServiceBuilderImpl implements ServiceBuilder {\n  private port: number | undefined;\n  private host: string | undefined;\n  private logger: Logger | undefined;\n  private corsOptions: cors.CorsOptions | undefined;\n  private cspOptions: Record<string, string[] | false> | undefined;\n  private httpsSettings: HttpsSettings | undefined;\n  private routers: [string, Router][];\n  private requestLoggingHandler: RequestLoggingHandlerFactory | undefined;\n  private errorHandler: ErrorRequestHandler | undefined;\n  private useDefaultErrorHandler: boolean;\n  // Reference to the module where builder is created - needed for hot module\n  // reloading\n  private module: NodeModule;\n\n  constructor(moduleRef: NodeModule) {\n    this.routers = [];\n    this.module = moduleRef;\n    this.useDefaultErrorHandler = true;\n  }\n\n  loadConfig(config: Config): ServiceBuilder {\n    const backendConfig = config.getOptionalConfig('backend');\n    if (!backendConfig) {\n      return this;\n    }\n\n    const baseOptions = readBaseOptions(backendConfig);\n    if (baseOptions.listenPort) {\n      this.port =\n        typeof baseOptions.listenPort === 'string'\n          ? parseInt(baseOptions.listenPort, 10)\n          : baseOptions.listenPort;\n    }\n    if (baseOptions.listenHost) {\n      this.host = baseOptions.listenHost;\n    }\n\n    const corsOptions = readCorsOptions(backendConfig);\n    if (corsOptions) {\n      this.corsOptions = corsOptions;\n    }\n\n    const cspOptions = readCspOptions(backendConfig);\n    if (cspOptions) {\n      this.cspOptions = cspOptions;\n    }\n\n    const httpsSettings = readHttpsSettings(backendConfig);\n    if (httpsSettings) {\n      this.httpsSettings = httpsSettings;\n    }\n\n    return this;\n  }\n\n  setPort(port: number): ServiceBuilder {\n    this.port = port;\n    return this;\n  }\n\n  setHost(host: string): ServiceBuilder {\n    this.host = host;\n    return this;\n  }\n\n  setLogger(logger: Logger): ServiceBuilder {\n    this.logger = logger;\n    return this;\n  }\n\n  setHttpsSettings(settings: HttpsSettings): ServiceBuilder {\n    this.httpsSettings = settings;\n    return this;\n  }\n\n  enableCors(options: cors.CorsOptions): ServiceBuilder {\n    this.corsOptions = options;\n    return this;\n  }\n\n  setCsp(options: CspOptions): ServiceBuilder {\n    this.cspOptions = options;\n    return this;\n  }\n\n  addRouter(root: string, router: Router): ServiceBuilder {\n    this.routers.push([root, router]);\n    return this;\n  }\n\n  setRequestLoggingHandler(\n    requestLoggingHandler: RequestLoggingHandlerFactory,\n  ) {\n    this.requestLoggingHandler = requestLoggingHandler;\n    return this;\n  }\n\n  setErrorHandler(errorHandler: ErrorRequestHandler) {\n    this.errorHandler = errorHandler;\n    return this;\n  }\n\n  disableDefaultErrorHandler() {\n    this.useDefaultErrorHandler = false;\n    return this;\n  }\n\n  async start(): Promise<http.Server> {\n    const app = express();\n    const { port, host, logger, corsOptions, httpsSettings, helmetOptions } =\n      this.getOptions();\n\n    app.use(helmet(helmetOptions));\n    if (corsOptions) {\n      app.use(cors(corsOptions));\n    }\n    app.use(compression());\n    app.use(\n      (this.requestLoggingHandler ?? defaultRequestLoggingHandler)(logger),\n    );\n    for (const [root, route] of this.routers) {\n      app.use(root, route);\n    }\n    app.use(notFoundHandler());\n\n    if (this.errorHandler) {\n      app.use(this.errorHandler);\n    }\n\n    if (this.useDefaultErrorHandler) {\n      app.use(defaultErrorHandler());\n    }\n\n    const server: http.Server = httpsSettings\n      ? await createHttpsServer(app, httpsSettings, logger)\n      : createHttpServer(app, logger);\n    const stoppableServer = stoppable(server, 0);\n\n    useHotCleanup(this.module, () =>\n      stoppableServer.stop((e: any) => {\n        if (e) console.error(e);\n      }),\n    );\n\n    return new Promise((resolve, reject) => {\n      function handleStartupError(e: unknown) {\n        server.close();\n        reject(e);\n      }\n\n      server.on('error', handleStartupError);\n\n      server.listen(port, host, () => {\n        server.off('error', handleStartupError);\n        logger.info(`Listening on ${host}:${port}`);\n        resolve(stoppableServer);\n      });\n    });\n  }\n\n  private getOptions() {\n    return {\n      port: this.port ?? DEFAULT_PORT,\n      host: this.host ?? DEFAULT_HOST,\n      logger: this.logger ?? getRootLogger(),\n      corsOptions: this.corsOptions,\n      httpsSettings: this.httpsSettings,\n      helmetOptions: {\n        contentSecurityPolicy: {\n          useDefaults: false,\n          directives: applyCspDirectives(this.cspOptions),\n        },\n        // These are all disabled in order to maintain backwards compatibility\n        // when bumping helmet v5. We can't enable these by default because\n        // there is no way for users to configure them.\n        // TODO(Rugvip): We should give control of this setup to consumers\n        crossOriginEmbedderPolicy: false,\n        crossOriginOpenerPolicy: false,\n        crossOriginResourcePolicy: false,\n        originAgentCluster: false,\n      },\n    };\n  }\n}\n\nexport function applyCspDirectives(\n  directives: Record<string, string[] | false> | undefined,\n): ContentSecurityPolicyOptions['directives'] {\n  const result: ContentSecurityPolicyOptions['directives'] =\n    helmet.contentSecurityPolicy.getDefaultDirectives();\n\n  // TODO(Rugvip): We currently use non-precompiled AJV for validation in the frontend, which uses eval.\n  //               It should be replaced by any other solution that doesn't require unsafe-eval.\n  result['script-src'] = [\"'self'\", \"'unsafe-eval'\"];\n\n  // TODO(Rugvip): This is removed so that we maintained backwards compatibility\n  //               when bumping to helmet v5, we could remove this as well as\n  //               skip setting `useDefaults: false` in the future.\n  delete result['form-action'];\n\n  if (directives) {\n    for (const [key, value] of Object.entries(directives)) {\n      if (value === false) {\n        delete result[key];\n      } else {\n        result[key] = value;\n      }\n    }\n  }\n\n  return result;\n}\n","/*\n * Copyright 2020 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Config } from '@backstage/config';\nimport { PluginEndpointDiscovery } from './types';\nimport { readBaseOptions } from '../service/lib/config';\nimport { DEFAULT_PORT } from '../service/lib/ServiceBuilderImpl';\n\n/**\n * SingleHostDiscovery is a basic PluginEndpointDiscovery implementation\n * that assumes that all plugins are hosted in a single deployment.\n *\n * The deployment may be scaled horizontally, as long as the external URL\n * is the same for all instances. However, internal URLs will always be\n * resolved to the same host, so there won't be any balancing of internal traffic.\n *\n * @public\n */\nexport class SingleHostDiscovery implements PluginEndpointDiscovery {\n  /**\n   * Creates a new SingleHostDiscovery discovery instance by reading\n   * from the `backend` config section, specifically the `.baseUrl` for\n   * discovering the external URL, and the `.listen` and `.https` config\n   * for the internal one.\n   *\n   * The basePath defaults to `/api`, meaning the default full internal\n   * path for the `catalog` plugin will be `http://localhost:7007/api/catalog`.\n   */\n  static fromConfig(config: Config, options?: { basePath?: string }) {\n    const basePath = options?.basePath ?? '/api';\n    const externalBaseUrl = config.getString('backend.baseUrl');\n\n    const { listenHost = '::', listenPort = DEFAULT_PORT } = readBaseOptions(\n      config.getConfig('backend'),\n    );\n    const protocol = config.has('backend.https') ? 'https' : 'http';\n\n    // Translate bind-all to localhost, and support IPv6\n    let host = listenHost;\n    if (host === '::') {\n      // We use localhost instead of ::1, since IPv6-compatible systems should default\n      // to using IPv6 when they see localhost, but if the system doesn't support IPv6\n      // things will still work.\n      host = 'localhost';\n    } else if (host === '0.0.0.0') {\n      host = '127.0.0.1';\n    }\n    if (host.includes(':')) {\n      host = `[${host}]`;\n    }\n\n    const internalBaseUrl = `${protocol}://${host}:${listenPort}`;\n\n    return new SingleHostDiscovery(\n      internalBaseUrl + basePath,\n      externalBaseUrl + basePath,\n    );\n  }\n\n  private constructor(\n    private readonly internalBaseUrl: string,\n    private readonly externalBaseUrl: string,\n  ) {}\n\n  async getBaseUrl(pluginId: string): Promise<string> {\n    return `${this.internalBaseUrl}/${pluginId}`;\n  }\n\n  async getExternalBaseUrl(pluginId: string): Promise<string> {\n    return `${this.externalBaseUrl}/${pluginId}`;\n  }\n}\n","/*\n * Copyright 2020 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { isChildPath } from '@backstage/cli-common';\nimport { NotAllowedError } from '@backstage/errors';\nimport { resolve as resolvePath } from 'path';\n\n/**\n * Resolve a path relative to the root of a package directory.\n * Additional path arguments are resolved relative to the package dir.\n *\n * This is particularly useful when you want to access assets shipped with\n * your backend plugin package. When doing so, do not forget to include the assets\n * in your published package by adding them to `files` in your `package.json`.\n *\n * @public\n */\nexport function resolvePackagePath(name: string, ...paths: string[]) {\n  const req =\n    typeof __non_webpack_require__ === 'undefined'\n      ? require\n      : __non_webpack_require__;\n\n  return resolvePath(req.resolve(`${name}/package.json`), '..', ...paths);\n}\n\n/**\n * Resolves a target path from a base path while guaranteeing that the result is\n * a path that point to or within the base path. This is useful for resolving\n * paths from user input, as it otherwise opens up for vulnerabilities.\n *\n * @public\n * @param base - The base directory to resolve the path from.\n * @param path - The target path, relative or absolute\n * @returns A path that is guaranteed to point to or within the base path.\n */\nexport function resolveSafeChildPath(base: string, path: string): string {\n  const targetPath = resolvePath(base, path);\n\n  if (!isChildPath(base, targetPath)) {\n    throw new NotAllowedError(\n      'Relative path is not allowed to refer to a directory outside its parent',\n    );\n  }\n\n  return targetPath;\n}\n\n// Re-export isChildPath so that backend packages don't need to depend on cli-common\nexport { isChildPath };\n","/*\n * Copyright 2020 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  AzureIntegration,\n  getAzureCommitsUrl,\n  getAzureDownloadUrl,\n  getAzureFileFetchUrl,\n  getAzureRequestOptions,\n  ScmIntegrations,\n} from '@backstage/integration';\nimport fetch, { Response } from 'node-fetch';\nimport { Minimatch } from 'minimatch';\nimport { Readable } from 'stream';\nimport { NotFoundError, NotModifiedError } from '@backstage/errors';\nimport {\n  ReadTreeResponseFactory,\n  ReaderFactory,\n  ReadTreeOptions,\n  ReadTreeResponse,\n  SearchOptions,\n  SearchResponse,\n  UrlReader,\n  ReadUrlOptions,\n  ReadUrlResponse,\n} from './types';\n\n/**\n * Implements a {@link UrlReader} for Azure repos.\n *\n * @public\n */\nexport class AzureUrlReader implements UrlReader {\n  static factory: ReaderFactory = ({ config, treeResponseFactory }) => {\n    const integrations = ScmIntegrations.fromConfig(config);\n    return integrations.azure.list().map(integration => {\n      const reader = new AzureUrlReader(integration, { treeResponseFactory });\n      const predicate = (url: URL) => url.host === integration.config.host;\n      return { reader, predicate };\n    });\n  };\n\n  constructor(\n    private readonly integration: AzureIntegration,\n    private readonly deps: { treeResponseFactory: ReadTreeResponseFactory },\n  ) {}\n\n  async read(url: string): Promise<Buffer> {\n    const response = await this.readUrl(url);\n    return response.buffer();\n  }\n\n  async readUrl(\n    url: string,\n    options?: ReadUrlOptions,\n  ): Promise<ReadUrlResponse> {\n    // TODO: etag is not implemented yet.\n    const { signal } = options ?? {};\n\n    const builtUrl = getAzureFileFetchUrl(url);\n\n    let response: Response;\n    try {\n      response = await fetch(builtUrl, {\n        ...getAzureRequestOptions(this.integration.config),\n        // TODO(freben): The signal cast is there because pre-3.x versions of\n        // node-fetch have a very slightly deviating AbortSignal type signature.\n        // The difference does not affect us in practice however. The cast can\n        // be removed after we support ESM for CLI dependencies and migrate to\n        // version 3 of node-fetch.\n        // https://github.com/backstage/backstage/issues/8242\n        ...(signal && { signal: signal as any }),\n      });\n    } catch (e) {\n      throw new Error(`Unable to read ${url}, ${e}`);\n    }\n\n    // for private repos when PAT is not valid, Azure API returns a http status code 203 with sign in page html\n    if (response.ok && response.status !== 203) {\n      return {\n        buffer: async () => Buffer.from(await response.arrayBuffer()),\n      };\n    }\n\n    const message = `${url} could not be read as ${builtUrl}, ${response.status} ${response.statusText}`;\n    if (response.status === 404) {\n      throw new NotFoundError(message);\n    }\n    throw new Error(message);\n  }\n\n  async readTree(\n    url: string,\n    options?: ReadTreeOptions,\n  ): Promise<ReadTreeResponse> {\n    const { etag, filter, signal } = options ?? {};\n\n    // TODO: Support filepath based reading tree feature like other providers\n\n    // Get latest commit SHA\n\n    const commitsAzureResponse = await fetch(\n      getAzureCommitsUrl(url),\n      getAzureRequestOptions(this.integration.config),\n    );\n    if (!commitsAzureResponse.ok) {\n      const message = `Failed to read tree from ${url}, ${commitsAzureResponse.status} ${commitsAzureResponse.statusText}`;\n      if (commitsAzureResponse.status === 404) {\n        throw new NotFoundError(message);\n      }\n      throw new Error(message);\n    }\n\n    const commitSha = (await commitsAzureResponse.json()).value[0].commitId;\n    if (etag && etag === commitSha) {\n      throw new NotModifiedError();\n    }\n\n    const archiveAzureResponse = await fetch(getAzureDownloadUrl(url), {\n      ...getAzureRequestOptions(this.integration.config, {\n        Accept: 'application/zip',\n      }),\n      // TODO(freben): The signal cast is there because pre-3.x versions of\n      // node-fetch have a very slightly deviating AbortSignal type signature.\n      // The difference does not affect us in practice however. The cast can be\n      // removed after we support ESM for CLI dependencies and migrate to\n      // version 3 of node-fetch.\n      // https://github.com/backstage/backstage/issues/8242\n      ...(signal && { signal: signal as any }),\n    });\n    if (!archiveAzureResponse.ok) {\n      const message = `Failed to read tree from ${url}, ${archiveAzureResponse.status} ${archiveAzureResponse.statusText}`;\n      if (archiveAzureResponse.status === 404) {\n        throw new NotFoundError(message);\n      }\n      throw new Error(message);\n    }\n\n    // When downloading a zip archive from azure on a subpath we get an extra directory\n    // layer added at the top. With for example the file /a/b/c.txt and a download of\n    // /a/b, we'll see /b/c.txt in the zip archive. This picks out /b so that we can remove it.\n    let subpath;\n    const path = new URL(url).searchParams.get('path');\n    if (path) {\n      subpath = path.split('/').filter(Boolean).slice(-1)[0];\n    }\n\n    return await this.deps.treeResponseFactory.fromZipArchive({\n      stream: archiveAzureResponse.body as unknown as Readable,\n      etag: commitSha,\n      filter,\n      subpath,\n    });\n  }\n\n  async search(url: string, options?: SearchOptions): Promise<SearchResponse> {\n    const treeUrl = new URL(url);\n\n    const path = treeUrl.searchParams.get('path');\n    const matcher = path && new Minimatch(path.replace(/^\\/+/, ''));\n\n    // TODO(freben): For now, read the entire repo and filter through that. In\n    // a future improvement, we could be smart and try to deduce that non-glob\n    // prefixes (like for filepaths such as some-prefix/**/a.yaml) can be used\n    // to get just that part of the repo.\n    treeUrl.searchParams.delete('path');\n\n    const tree = await this.readTree(treeUrl.toString(), {\n      etag: options?.etag,\n      signal: options?.signal,\n      filter: p => (matcher ? matcher.match(p) : true),\n    });\n    const files = await tree.files();\n\n    return {\n      etag: tree.etag,\n      files: files.map(file => ({\n        url: this.integration.resolveUrl({\n          url: `/${file.path}`,\n          base: url,\n        }),\n        content: file.content,\n      })),\n    };\n  }\n\n  toString() {\n    const { host, token } = this.integration.config;\n    return `azure{host=${host},authed=${Boolean(token)}}`;\n  }\n}\n","/*\n * Copyright 2020 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { NotFoundError, NotModifiedError } from '@backstage/errors';\nimport {\n  BitbucketIntegration,\n  getBitbucketDefaultBranch,\n  getBitbucketDownloadUrl,\n  getBitbucketFileFetchUrl,\n  getBitbucketRequestOptions,\n  ScmIntegrations,\n} from '@backstage/integration';\nimport fetch, { Response } from 'node-fetch';\nimport parseGitUrl from 'git-url-parse';\nimport { trimEnd } from 'lodash';\nimport { Minimatch } from 'minimatch';\nimport { Readable } from 'stream';\nimport {\n  ReaderFactory,\n  ReadTreeOptions,\n  ReadTreeResponse,\n  ReadTreeResponseFactory,\n  ReadUrlOptions,\n  ReadUrlResponse,\n  SearchOptions,\n  SearchResponse,\n  UrlReader,\n} from './types';\n\n/**\n * Implements a {@link UrlReader} for files from Bitbucket v1 and v2 APIs, such\n * as the one exposed by Bitbucket Cloud itself.\n *\n * @public\n */\nexport class BitbucketUrlReader implements UrlReader {\n  static factory: ReaderFactory = ({ config, treeResponseFactory }) => {\n    const integrations = ScmIntegrations.fromConfig(config);\n    return integrations.bitbucket.list().map(integration => {\n      const reader = new BitbucketUrlReader(integration, {\n        treeResponseFactory,\n      });\n      const predicate = (url: URL) => url.host === integration.config.host;\n      return { reader, predicate };\n    });\n  };\n\n  constructor(\n    private readonly integration: BitbucketIntegration,\n    private readonly deps: { treeResponseFactory: ReadTreeResponseFactory },\n  ) {\n    const { host, token, username, appPassword } = integration.config;\n\n    if (!token && username && !appPassword) {\n      throw new Error(\n        `Bitbucket integration for '${host}' has configured a username but is missing a required appPassword.`,\n      );\n    }\n  }\n\n  async read(url: string): Promise<Buffer> {\n    const response = await this.readUrl(url);\n    return response.buffer();\n  }\n\n  async readUrl(\n    url: string,\n    options?: ReadUrlOptions,\n  ): Promise<ReadUrlResponse> {\n    const { etag, signal } = options ?? {};\n    const bitbucketUrl = getBitbucketFileFetchUrl(url, this.integration.config);\n    const requestOptions = getBitbucketRequestOptions(this.integration.config);\n\n    let response: Response;\n    try {\n      response = await fetch(bitbucketUrl.toString(), {\n        headers: {\n          ...requestOptions.headers,\n          ...(etag && { 'If-None-Match': etag }),\n        },\n        // TODO(freben): The signal cast is there because pre-3.x versions of\n        // node-fetch have a very slightly deviating AbortSignal type signature.\n        // The difference does not affect us in practice however. The cast can be\n        // removed after we support ESM for CLI dependencies and migrate to\n        // version 3 of node-fetch.\n        // https://github.com/backstage/backstage/issues/8242\n        ...(signal && { signal: signal as any }),\n      });\n    } catch (e) {\n      throw new Error(`Unable to read ${url}, ${e}`);\n    }\n\n    if (response.status === 304) {\n      throw new NotModifiedError();\n    }\n\n    if (response.ok) {\n      return {\n        buffer: async () => Buffer.from(await response.arrayBuffer()),\n        etag: response.headers.get('ETag') ?? undefined,\n      };\n    }\n\n    const message = `${url} could not be read as ${bitbucketUrl}, ${response.status} ${response.statusText}`;\n    if (response.status === 404) {\n      throw new NotFoundError(message);\n    }\n    throw new Error(message);\n  }\n\n  async readTree(\n    url: string,\n    options?: ReadTreeOptions,\n  ): Promise<ReadTreeResponse> {\n    const { filepath } = parseGitUrl(url);\n\n    const lastCommitShortHash = await this.getLastCommitShortHash(url);\n    if (options?.etag && options.etag === lastCommitShortHash) {\n      throw new NotModifiedError();\n    }\n\n    const downloadUrl = await getBitbucketDownloadUrl(\n      url,\n      this.integration.config,\n    );\n    const archiveBitbucketResponse = await fetch(\n      downloadUrl,\n      getBitbucketRequestOptions(this.integration.config),\n    );\n    if (!archiveBitbucketResponse.ok) {\n      const message = `Failed to read tree from ${url}, ${archiveBitbucketResponse.status} ${archiveBitbucketResponse.statusText}`;\n      if (archiveBitbucketResponse.status === 404) {\n        throw new NotFoundError(message);\n      }\n      throw new Error(message);\n    }\n\n    return await this.deps.treeResponseFactory.fromTarArchive({\n      stream: archiveBitbucketResponse.body as unknown as Readable,\n      subpath: filepath,\n      etag: lastCommitShortHash,\n      filter: options?.filter,\n    });\n  }\n\n  async search(url: string, options?: SearchOptions): Promise<SearchResponse> {\n    const { filepath } = parseGitUrl(url);\n    const matcher = new Minimatch(filepath);\n\n    // TODO(freben): For now, read the entire repo and filter through that. In\n    // a future improvement, we could be smart and try to deduce that non-glob\n    // prefixes (like for filepaths such as some-prefix/**/a.yaml) can be used\n    // to get just that part of the repo.\n    const treeUrl = trimEnd(url.replace(filepath, ''), '/');\n\n    const tree = await this.readTree(treeUrl, {\n      etag: options?.etag,\n      filter: path => matcher.match(path),\n    });\n    const files = await tree.files();\n\n    return {\n      etag: tree.etag,\n      files: files.map(file => ({\n        url: this.integration.resolveUrl({\n          url: `/${file.path}`,\n          base: url,\n        }),\n        content: file.content,\n      })),\n    };\n  }\n\n  toString() {\n    const { host, token, username, appPassword } = this.integration.config;\n    let authed = Boolean(token);\n    if (!authed) {\n      authed = Boolean(username && appPassword);\n    }\n    return `bitbucket{host=${host},authed=${authed}}`;\n  }\n\n  private async getLastCommitShortHash(url: string): Promise<string> {\n    const { resource, name: repoName, owner: project, ref } = parseGitUrl(url);\n\n    let branch = ref;\n    if (!branch) {\n      branch = await getBitbucketDefaultBranch(url, this.integration.config);\n    }\n\n    const isHosted = resource === 'bitbucket.org';\n    // Bitbucket Server https://docs.atlassian.com/bitbucket-server/rest/7.9.0/bitbucket-rest.html#idp222\n    const commitsApiUrl = isHosted\n      ? `${this.integration.config.apiBaseUrl}/repositories/${project}/${repoName}/commits/${branch}`\n      : `${this.integration.config.apiBaseUrl}/projects/${project}/repos/${repoName}/commits`;\n\n    const commitsResponse = await fetch(\n      commitsApiUrl,\n      getBitbucketRequestOptions(this.integration.config),\n    );\n    if (!commitsResponse.ok) {\n      const message = `Failed to retrieve commits from ${commitsApiUrl}, ${commitsResponse.status} ${commitsResponse.statusText}`;\n      if (commitsResponse.status === 404) {\n        throw new NotFoundError(message);\n      }\n      throw new Error(message);\n    }\n\n    const commits = await commitsResponse.json();\n    if (isHosted) {\n      if (\n        commits &&\n        commits.values &&\n        commits.values.length > 0 &&\n        commits.values[0].hash\n      ) {\n        return commits.values[0].hash.substring(0, 12);\n      }\n    } else {\n      if (\n        commits &&\n        commits.values &&\n        commits.values.length > 0 &&\n        commits.values[0].id\n      ) {\n        return commits.values[0].id.substring(0, 12);\n      }\n    }\n\n    throw new Error(`Failed to read response from ${commitsApiUrl}`);\n  }\n}\n","/*\n * Copyright 2020 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  getGitHubFileFetchUrl,\n  DefaultGithubCredentialsProvider,\n  GithubCredentialsProvider,\n  GitHubIntegration,\n  ScmIntegrations,\n} from '@backstage/integration';\nimport { RestEndpointMethodTypes } from '@octokit/rest';\nimport fetch, { RequestInit, Response } from 'node-fetch';\nimport parseGitUrl from 'git-url-parse';\nimport { Minimatch } from 'minimatch';\nimport { Readable } from 'stream';\nimport { NotFoundError, NotModifiedError } from '@backstage/errors';\nimport {\n  ReadTreeResponseFactory,\n  ReaderFactory,\n  ReadTreeOptions,\n  ReadTreeResponse,\n  SearchOptions,\n  SearchResponse,\n  SearchResponseFile,\n  UrlReader,\n  ReadUrlOptions,\n  ReadUrlResponse,\n} from './types';\n\nexport type GhRepoResponse =\n  RestEndpointMethodTypes['repos']['get']['response']['data'];\nexport type GhBranchResponse =\n  RestEndpointMethodTypes['repos']['getBranch']['response']['data'];\nexport type GhTreeResponse =\n  RestEndpointMethodTypes['git']['getTree']['response']['data'];\nexport type GhBlobResponse =\n  RestEndpointMethodTypes['git']['getBlob']['response']['data'];\n\n/**\n * Implements a {@link UrlReader} for files through the GitHub v3 APIs, such as\n * the one exposed by GitHub itself.\n *\n * @public\n */\nexport class GithubUrlReader implements UrlReader {\n  static factory: ReaderFactory = ({ config, treeResponseFactory }) => {\n    const integrations = ScmIntegrations.fromConfig(config);\n    const credentialsProvider =\n      DefaultGithubCredentialsProvider.fromIntegrations(integrations);\n    return integrations.github.list().map(integration => {\n      const reader = new GithubUrlReader(integration, {\n        treeResponseFactory,\n        credentialsProvider,\n      });\n      const predicate = (url: URL) => url.host === integration.config.host;\n      return { reader, predicate };\n    });\n  };\n\n  constructor(\n    private readonly integration: GitHubIntegration,\n    private readonly deps: {\n      treeResponseFactory: ReadTreeResponseFactory;\n      credentialsProvider: GithubCredentialsProvider;\n    },\n  ) {\n    if (!integration.config.apiBaseUrl && !integration.config.rawBaseUrl) {\n      throw new Error(\n        `GitHub integration '${integration.title}' must configure an explicit apiBaseUrl or rawBaseUrl`,\n      );\n    }\n  }\n\n  async read(url: string): Promise<Buffer> {\n    const response = await this.readUrl(url);\n    return response.buffer();\n  }\n\n  async readUrl(\n    url: string,\n    options?: ReadUrlOptions,\n  ): Promise<ReadUrlResponse> {\n    const credentials = await this.deps.credentialsProvider.getCredentials({\n      url,\n    });\n    const ghUrl = getGitHubFileFetchUrl(\n      url,\n      this.integration.config,\n      credentials,\n    );\n\n    let response: Response;\n    try {\n      response = await fetch(ghUrl, {\n        headers: {\n          ...credentials?.headers,\n          ...(options?.etag && { 'If-None-Match': options.etag }),\n          Accept: 'application/vnd.github.v3.raw',\n        },\n        // TODO(freben): The signal cast is there because pre-3.x versions of\n        // node-fetch have a very slightly deviating AbortSignal type signature.\n        // The difference does not affect us in practice however. The cast can\n        // be removed after we support ESM for CLI dependencies and migrate to\n        // version 3 of node-fetch.\n        // https://github.com/backstage/backstage/issues/8242\n        signal: options?.signal as any,\n      });\n    } catch (e) {\n      throw new Error(`Unable to read ${url}, ${e}`);\n    }\n\n    if (response.status === 304) {\n      throw new NotModifiedError();\n    }\n\n    if (response.ok) {\n      return {\n        buffer: async () => Buffer.from(await response.arrayBuffer()),\n        etag: response.headers.get('ETag') ?? undefined,\n      };\n    }\n\n    let message = `${url} could not be read as ${ghUrl}, ${response.status} ${response.statusText}`;\n    if (response.status === 404) {\n      throw new NotFoundError(message);\n    }\n\n    // GitHub returns a 403 response with a couple of headers indicating rate\n    // limit status. See more in the GitHub docs:\n    // https://docs.github.com/en/rest/overview/resources-in-the-rest-api#rate-limiting\n    if (\n      response.status === 403 &&\n      response.headers.get('X-RateLimit-Remaining') === '0'\n    ) {\n      message += ' (rate limit exceeded)';\n    }\n\n    throw new Error(message);\n  }\n\n  async readTree(\n    url: string,\n    options?: ReadTreeOptions,\n  ): Promise<ReadTreeResponse> {\n    const repoDetails = await this.getRepoDetails(url);\n    const commitSha = repoDetails.branch.commit.sha!;\n\n    if (options?.etag && options.etag === commitSha) {\n      throw new NotModifiedError();\n    }\n\n    const { filepath } = parseGitUrl(url);\n    const { headers } = await this.deps.credentialsProvider.getCredentials({\n      url,\n    });\n\n    return this.doReadTree(\n      repoDetails.repo.archive_url,\n      commitSha,\n      filepath,\n      // TODO(freben): The signal cast is there because pre-3.x versions of\n      // node-fetch have a very slightly deviating AbortSignal type signature.\n      // The difference does not affect us in practice however. The cast can be\n      // removed after we support ESM for CLI dependencies and migrate to\n      // version 3 of node-fetch.\n      // https://github.com/backstage/backstage/issues/8242\n      { headers, signal: options?.signal as any },\n      options,\n    );\n  }\n\n  async search(url: string, options?: SearchOptions): Promise<SearchResponse> {\n    const repoDetails = await this.getRepoDetails(url);\n    const commitSha = repoDetails.branch.commit.sha!;\n\n    if (options?.etag && options.etag === commitSha) {\n      throw new NotModifiedError();\n    }\n\n    const { filepath } = parseGitUrl(url);\n    const { headers } = await this.deps.credentialsProvider.getCredentials({\n      url,\n    });\n\n    const files = await this.doSearch(\n      url,\n      repoDetails.repo.trees_url,\n      repoDetails.repo.archive_url,\n      commitSha,\n      filepath,\n      { headers, signal: options?.signal as any },\n    );\n\n    return { files, etag: commitSha };\n  }\n\n  toString() {\n    const { host, token } = this.integration.config;\n    return `github{host=${host},authed=${Boolean(token)}}`;\n  }\n\n  private async doReadTree(\n    archiveUrl: string,\n    sha: string,\n    subpath: string,\n    init: RequestInit,\n    options?: ReadTreeOptions,\n  ): Promise<ReadTreeResponse> {\n    // archive_url looks like \"https://api.github.com/repos/owner/repo/{archive_format}{/ref}\"\n    const archive = await this.fetchResponse(\n      archiveUrl\n        .replace('{archive_format}', 'tarball')\n        .replace('{/ref}', `/${sha}`),\n      init,\n    );\n\n    return await this.deps.treeResponseFactory.fromTarArchive({\n      // TODO(Rugvip): Underlying implementation of fetch will be node-fetch, we probably want\n      //               to stick to using that in exclusively backend code.\n      stream: archive.body as unknown as Readable,\n      subpath,\n      etag: sha,\n      filter: options?.filter,\n    });\n  }\n\n  private async doSearch(\n    url: string,\n    treesUrl: string,\n    archiveUrl: string,\n    sha: string,\n    query: string,\n    init: RequestInit,\n  ): Promise<SearchResponseFile[]> {\n    function pathToUrl(path: string): string {\n      // TODO(freben): Use the integration package facility for this instead\n      // pathname starts as /backstage/backstage/blob/master/<path>\n      const updated = new URL(url);\n      const base = updated.pathname.split('/').slice(1, 5).join('/');\n      updated.pathname = `${base}/${path}`;\n      return updated.toString();\n    }\n\n    const matcher = new Minimatch(query.replace(/^\\/+/, ''));\n\n    // trees_url looks like \"https://api.github.com/repos/octocat/Hello-World/git/trees{/sha}\"\n    const recursiveTree: GhTreeResponse = await this.fetchJson(\n      treesUrl.replace('{/sha}', `/${sha}?recursive=true`),\n      init,\n    );\n\n    // The simple case is that we got the entire tree in a single operation.\n    if (!recursiveTree.truncated) {\n      const matching = recursiveTree.tree.filter(\n        item =>\n          item.type === 'blob' &&\n          item.path &&\n          item.url &&\n          matcher.match(item.path),\n      );\n\n      return matching.map(item => ({\n        url: pathToUrl(item.path!),\n        content: async () => {\n          const blob: GhBlobResponse = await this.fetchJson(item.url!, init);\n          return Buffer.from(blob.content, 'base64');\n        },\n      }));\n    }\n\n    // For larger repos, we leverage readTree and filter through that instead\n    const tree = await this.doReadTree(archiveUrl, sha, '', init, {\n      filter: path => matcher.match(path),\n    });\n    const files = await tree.files();\n\n    return files.map(file => ({\n      url: pathToUrl(file.path),\n      content: file.content,\n    }));\n  }\n\n  private async getRepoDetails(url: string): Promise<{\n    repo: GhRepoResponse;\n    branch: GhBranchResponse;\n  }> {\n    const parsed = parseGitUrl(url);\n    const { ref, full_name } = parsed;\n\n    // Caveat: The ref will totally be incorrect if the branch name includes a\n    // slash. Thus, some operations can not work on URLs containing branch\n    // names that have a slash in them.\n\n    const { headers } = await this.deps.credentialsProvider.getCredentials({\n      url,\n    });\n\n    const repo: GhRepoResponse = await this.fetchJson(\n      `${this.integration.config.apiBaseUrl}/repos/${full_name}`,\n      { headers },\n    );\n\n    // branches_url looks like \"https://api.github.com/repos/owner/repo/branches{/branch}\"\n    const branch: GhBranchResponse = await this.fetchJson(\n      repo.branches_url.replace('{/branch}', `/${ref || repo.default_branch}`),\n      { headers },\n    );\n\n    return { repo, branch };\n  }\n\n  private async fetchResponse(\n    url: string | URL,\n    init: RequestInit,\n  ): Promise<Response> {\n    const urlAsString = url.toString();\n\n    const response = await fetch(urlAsString, init);\n\n    if (!response.ok) {\n      const message = `Request failed for ${urlAsString}, ${response.status} ${response.statusText}`;\n      if (response.status === 404) {\n        throw new NotFoundError(message);\n      }\n      throw new Error(message);\n    }\n\n    return response;\n  }\n\n  private async fetchJson(url: string | URL, init: RequestInit): Promise<any> {\n    const response = await this.fetchResponse(url, init);\n    return await response.json();\n  }\n}\n","/*\n * Copyright 2021 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n// Matches a directory name + one `/` at the start of any string,\n// containing any character except `/` one or more times, and ending with a `/`\n// e.g. Will match `dirA/` in `dirA/dirB/file.ext`\nconst directoryNameRegex = /^[^\\/]+\\//;\n\n// Removes the first segment of a forward-slash-separated path\nexport function stripFirstDirectoryFromPath(path: string): string {\n  return path.replace(directoryNameRegex, '');\n}\n","/*\n * Copyright 2020 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  getGitLabFileFetchUrl,\n  getGitLabRequestOptions,\n  GitLabIntegration,\n  ScmIntegrations,\n} from '@backstage/integration';\nimport fetch, { Response } from 'node-fetch';\nimport parseGitUrl from 'git-url-parse';\nimport { Minimatch } from 'minimatch';\nimport { Readable } from 'stream';\nimport { NotFoundError, NotModifiedError } from '@backstage/errors';\nimport { stripFirstDirectoryFromPath } from './tree/util';\nimport {\n  ReadTreeResponseFactory,\n  ReaderFactory,\n  ReadTreeOptions,\n  ReadTreeResponse,\n  SearchOptions,\n  SearchResponse,\n  UrlReader,\n  ReadUrlResponse,\n  ReadUrlOptions,\n} from './types';\nimport { trimEnd } from 'lodash';\n\n/**\n * Implements a {@link UrlReader} for files on GitLab.\n *\n * @public\n */\nexport class GitlabUrlReader implements UrlReader {\n  static factory: ReaderFactory = ({ config, treeResponseFactory }) => {\n    const integrations = ScmIntegrations.fromConfig(config);\n    return integrations.gitlab.list().map(integration => {\n      const reader = new GitlabUrlReader(integration, {\n        treeResponseFactory,\n      });\n      const predicate = (url: URL) => url.host === integration.config.host;\n      return { reader, predicate };\n    });\n  };\n\n  constructor(\n    private readonly integration: GitLabIntegration,\n    private readonly deps: { treeResponseFactory: ReadTreeResponseFactory },\n  ) {}\n\n  async read(url: string): Promise<Buffer> {\n    const response = await this.readUrl(url);\n    return response.buffer();\n  }\n\n  async readUrl(\n    url: string,\n    options?: ReadUrlOptions,\n  ): Promise<ReadUrlResponse> {\n    const { etag, signal } = options ?? {};\n    const builtUrl = await getGitLabFileFetchUrl(url, this.integration.config);\n\n    let response: Response;\n    try {\n      response = await fetch(builtUrl, {\n        headers: {\n          ...getGitLabRequestOptions(this.integration.config).headers,\n          ...(etag && { 'If-None-Match': etag }),\n        },\n        // TODO(freben): The signal cast is there because pre-3.x versions of\n        // node-fetch have a very slightly deviating AbortSignal type signature.\n        // The difference does not affect us in practice however. The cast can be\n        // removed after we support ESM for CLI dependencies and migrate to\n        // version 3 of node-fetch.\n        // https://github.com/backstage/backstage/issues/8242\n        ...(signal && { signal: signal as any }),\n      });\n    } catch (e) {\n      throw new Error(`Unable to read ${url}, ${e}`);\n    }\n\n    if (response.status === 304) {\n      throw new NotModifiedError();\n    }\n\n    if (response.ok) {\n      return {\n        buffer: async () => Buffer.from(await response.arrayBuffer()),\n        etag: response.headers.get('ETag') ?? undefined,\n      };\n    }\n\n    const message = `${url} could not be read as ${builtUrl}, ${response.status} ${response.statusText}`;\n    if (response.status === 404) {\n      throw new NotFoundError(message);\n    }\n    throw new Error(message);\n  }\n\n  async readTree(\n    url: string,\n    options?: ReadTreeOptions,\n  ): Promise<ReadTreeResponse> {\n    const { etag, signal } = options ?? {};\n    const { ref, full_name, filepath } = parseGitUrl(url);\n\n    // Use GitLab API to get the default branch\n    // encodeURIComponent is required for GitLab API\n    // https://docs.gitlab.com/ee/api/README.html#namespaced-path-encoding\n    const projectGitlabResponse = await fetch(\n      new URL(\n        `${this.integration.config.apiBaseUrl}/projects/${encodeURIComponent(\n          full_name,\n        )}`,\n      ).toString(),\n      getGitLabRequestOptions(this.integration.config),\n    );\n    if (!projectGitlabResponse.ok) {\n      const msg = `Failed to read tree from ${url}, ${projectGitlabResponse.status} ${projectGitlabResponse.statusText}`;\n      if (projectGitlabResponse.status === 404) {\n        throw new NotFoundError(msg);\n      }\n      throw new Error(msg);\n    }\n    const projectGitlabResponseJson = await projectGitlabResponse.json();\n\n    // ref is an empty string if no branch is set in provided url to readTree.\n    const branch = ref || projectGitlabResponseJson.default_branch;\n\n    // Fetch the latest commit that modifies the the filepath in the provided or default branch\n    // to compare against the provided sha.\n    const commitsReqParams = new URLSearchParams();\n    commitsReqParams.set('ref_name', branch);\n    if (!!filepath) {\n      commitsReqParams.set('path', filepath);\n    }\n    const commitsGitlabResponse = await fetch(\n      new URL(\n        `${this.integration.config.apiBaseUrl}/projects/${encodeURIComponent(\n          full_name,\n        )}/repository/commits?${commitsReqParams.toString()}`,\n      ).toString(),\n      {\n        ...getGitLabRequestOptions(this.integration.config),\n        // TODO(freben): The signal cast is there because pre-3.x versions of\n        // node-fetch have a very slightly deviating AbortSignal type signature.\n        // The difference does not affect us in practice however. The cast can\n        // be removed after we support ESM for CLI dependencies and migrate to\n        // version 3 of node-fetch.\n        // https://github.com/backstage/backstage/issues/8242\n        ...(signal && { signal: signal as any }),\n      },\n    );\n    if (!commitsGitlabResponse.ok) {\n      const message = `Failed to read tree (branch) from ${url}, ${commitsGitlabResponse.status} ${commitsGitlabResponse.statusText}`;\n      if (commitsGitlabResponse.status === 404) {\n        throw new NotFoundError(message);\n      }\n      throw new Error(message);\n    }\n\n    const commitSha = (await commitsGitlabResponse.json())[0].id;\n\n    if (etag && etag === commitSha) {\n      throw new NotModifiedError();\n    }\n\n    // https://docs.gitlab.com/ee/api/repositories.html#get-file-archive\n    const archiveGitLabResponse = await fetch(\n      `${this.integration.config.apiBaseUrl}/projects/${encodeURIComponent(\n        full_name,\n      )}/repository/archive?sha=${branch}`,\n      {\n        ...getGitLabRequestOptions(this.integration.config),\n        // TODO(freben): The signal cast is there because pre-3.x versions of\n        // node-fetch have a very slightly deviating AbortSignal type signature.\n        // The difference does not affect us in practice however. The cast can\n        // be removed after we support ESM for CLI dependencies and migrate to\n        // version 3 of node-fetch.\n        // https://github.com/backstage/backstage/issues/8242\n        ...(signal && { signal: signal as any }),\n      },\n    );\n    if (!archiveGitLabResponse.ok) {\n      const message = `Failed to read tree (archive) from ${url}, ${archiveGitLabResponse.status} ${archiveGitLabResponse.statusText}`;\n      if (archiveGitLabResponse.status === 404) {\n        throw new NotFoundError(message);\n      }\n      throw new Error(message);\n    }\n\n    return await this.deps.treeResponseFactory.fromTarArchive({\n      stream: archiveGitLabResponse.body as unknown as Readable,\n      subpath: filepath,\n      etag: commitSha,\n      filter: options?.filter,\n    });\n  }\n\n  async search(url: string, options?: SearchOptions): Promise<SearchResponse> {\n    const { filepath } = parseGitUrl(url);\n    const matcher = new Minimatch(filepath);\n\n    // TODO(freben): For now, read the entire repo and filter through that. In\n    // a future improvement, we could be smart and try to deduce that non-glob\n    // prefixes (like for filepaths such as some-prefix/**/a.yaml) can be used\n    // to get just that part of the repo.\n    const treeUrl = trimEnd(url.replace(filepath, ''), '/');\n\n    const tree = await this.readTree(treeUrl, {\n      etag: options?.etag,\n      signal: options?.signal,\n      filter: path => matcher.match(stripFirstDirectoryFromPath(path)),\n    });\n    const files = await tree.files();\n\n    return {\n      etag: tree.etag,\n      files: files.map(file => ({\n        url: this.integration.resolveUrl({ url: `/${file.path}`, base: url }),\n        content: file.content,\n      })),\n    };\n  }\n\n  toString() {\n    const { host, token } = this.integration.config;\n    return `gitlab{host=${host},authed=${Boolean(token)}}`;\n  }\n}\n","/*\n * Copyright 2021 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport aws, { Credentials, S3 } from 'aws-sdk';\nimport { CredentialsOptions } from 'aws-sdk/lib/credentials';\nimport {\n  ReaderFactory,\n  ReadTreeOptions,\n  ReadTreeResponse,\n  ReadTreeResponseFactory,\n  ReadUrlOptions,\n  ReadUrlResponse,\n  SearchResponse,\n  UrlReader,\n} from './types';\nimport getRawBody from 'raw-body';\nimport {\n  AwsS3Integration,\n  ScmIntegrations,\n  AwsS3IntegrationConfig,\n} from '@backstage/integration';\nimport { ForwardedError, NotModifiedError } from '@backstage/errors';\nimport { ListObjectsV2Output, ObjectList } from 'aws-sdk/clients/s3';\n\nconst parseURL = (\n  url: string,\n  config: AwsS3IntegrationConfig,\n): { path: string; bucket: string; region: string } => {\n  let { host, pathname } = new URL(url);\n\n  /**\n   * Removes the leading '/' from the pathname to be processed\n   * as a parameter by AWS S3 SDK getObject method.\n   */\n  pathname = pathname.substr(1);\n\n  let bucket;\n  let region;\n\n  /**\n   * Path style URLs: https://s3.Region.amazonaws.com/bucket-name/key-name\n   * Virtual hosted style URLs: https://bucket-name.s3.Region.amazonaws.com/key-name\n   * See https://docs.aws.amazon.com/AmazonS3/latest/userguide/VirtualHosting.html#path-style-access\n   */\n  if (config.s3ForcePathStyle) {\n    if (pathname.indexOf('/') < 0) {\n      throw new Error(\n        `invalid path-style AWS S3 URL, ${url} does not contain bucket in the path`,\n      );\n    }\n    [bucket] = pathname.split('/');\n    pathname = pathname.substr(bucket.length + 1);\n  } else {\n    if (host.indexOf('.') < 0) {\n      throw new Error(\n        `invalid virtual hosted-style AWS S3 URL, ${url} does not contain bucket prefix in the host`,\n      );\n    }\n    [bucket] = host.split('.');\n    host = host.substr(bucket.length + 1);\n  }\n\n  // Only extract region from *.amazonaws.com hosts\n  if (config.host === 'amazonaws.com') {\n    // At this point bucket prefix is removed from host for virtual hosted URLs\n    const match = host.match(/^s3\\.([a-z\\d-]+)\\.amazonaws\\.com$/);\n    if (!match) {\n      throw new Error(\n        `invalid AWS S3 URL, cannot parse region from host in ${url}`,\n      );\n    }\n    region = match[1];\n  } else {\n    region = '';\n  }\n\n  return {\n    path: pathname,\n    bucket: bucket,\n    region: region,\n  };\n};\n\n/**\n * Implements a {@link UrlReader} for AWS S3 buckets.\n *\n * @public\n */\nexport class AwsS3UrlReader implements UrlReader {\n  static factory: ReaderFactory = ({ config, treeResponseFactory }) => {\n    const integrations = ScmIntegrations.fromConfig(config);\n\n    return integrations.awsS3.list().map(integration => {\n      const creds = AwsS3UrlReader.buildCredentials(integration);\n\n      const s3 = new S3({\n        apiVersion: '2006-03-01',\n        credentials: creds,\n        endpoint: integration.config.endpoint,\n        s3ForcePathStyle: integration.config.s3ForcePathStyle,\n      });\n      const reader = new AwsS3UrlReader(integration, {\n        s3,\n        treeResponseFactory,\n      });\n      const predicate = (url: URL) =>\n        url.host.endsWith(integration.config.host);\n      return { reader, predicate };\n    });\n  };\n\n  constructor(\n    private readonly integration: AwsS3Integration,\n    private readonly deps: {\n      s3: S3;\n      treeResponseFactory: ReadTreeResponseFactory;\n    },\n  ) {}\n\n  /**\n   * If accessKeyId and secretAccessKey are missing, the standard credentials provider chain will be used:\n   * https://docs.aws.amazon.com/AWSJavaSDK/latest/javadoc/com/amazonaws/auth/DefaultAWSCredentialsProviderChain.html\n   */\n  private static buildCredentials(\n    integration?: AwsS3Integration,\n  ): Credentials | CredentialsOptions | undefined {\n    if (!integration) {\n      return undefined;\n    }\n\n    const accessKeyId = integration.config.accessKeyId;\n    const secretAccessKey = integration.config.secretAccessKey;\n    let explicitCredentials: Credentials | undefined;\n\n    if (accessKeyId && secretAccessKey) {\n      explicitCredentials = new Credentials({\n        accessKeyId,\n        secretAccessKey,\n      });\n    }\n\n    const roleArn = integration.config.roleArn;\n    if (roleArn) {\n      return new aws.ChainableTemporaryCredentials({\n        masterCredentials: explicitCredentials,\n        params: {\n          RoleSessionName: 'backstage-aws-s3-url-reader',\n          RoleArn: roleArn,\n        },\n      });\n    }\n\n    return explicitCredentials;\n  }\n\n  async read(url: string): Promise<Buffer> {\n    const response = await this.readUrl(url);\n    return response.buffer();\n  }\n\n  async readUrl(\n    url: string,\n    options?: ReadUrlOptions,\n  ): Promise<ReadUrlResponse> {\n    try {\n      const { path, bucket, region } = parseURL(url, this.integration.config);\n      aws.config.update({ region: region });\n\n      let params;\n      if (options?.etag) {\n        params = {\n          Bucket: bucket,\n          Key: path,\n          IfNoneMatch: options.etag,\n        };\n      } else {\n        params = {\n          Bucket: bucket,\n          Key: path,\n        };\n      }\n\n      const request = this.deps.s3.getObject(params);\n      options?.signal?.addEventListener('abort', () => request.abort());\n      const buffer = await getRawBody(request.createReadStream());\n      const etag = (await request.promise()).ETag;\n\n      return {\n        buffer: async () => buffer,\n        etag: etag,\n      };\n    } catch (e) {\n      if (e.statusCode === 304) {\n        throw new NotModifiedError();\n      }\n\n      throw new ForwardedError('Could not retrieve file from S3', e);\n    }\n  }\n\n  async readTree(\n    url: string,\n    options?: ReadTreeOptions,\n  ): Promise<ReadTreeResponse> {\n    try {\n      const { path, bucket, region } = parseURL(url, this.integration.config);\n      const allObjects: ObjectList = [];\n      const responses = [];\n      let continuationToken: string | undefined;\n      let output: ListObjectsV2Output;\n      do {\n        aws.config.update({ region: region });\n        const request = this.deps.s3.listObjectsV2({\n          Bucket: bucket,\n          ContinuationToken: continuationToken,\n          Prefix: path,\n        });\n        options?.signal?.addEventListener('abort', () => request.abort());\n        output = await request.promise();\n        if (output.Contents) {\n          output.Contents.forEach(contents => {\n            allObjects.push(contents);\n          });\n        }\n        continuationToken = output.NextContinuationToken;\n      } while (continuationToken);\n\n      for (let i = 0; i < allObjects.length; i++) {\n        const object = this.deps.s3.getObject({\n          Bucket: bucket,\n          Key: String(allObjects[i].Key),\n        });\n        responses.push({\n          data: object.createReadStream(),\n          path: String(allObjects[i].Key),\n        });\n      }\n\n      return await this.deps.treeResponseFactory.fromReadableArray(responses);\n    } catch (e) {\n      throw new ForwardedError('Could not retrieve file tree from S3', e);\n    }\n  }\n\n  async search(): Promise<SearchResponse> {\n    throw new Error('AwsS3Reader does not implement search');\n  }\n\n  toString() {\n    const secretAccessKey = this.integration.config.secretAccessKey;\n    return `awsS3{host=${this.integration.config.host},authed=${Boolean(\n      secretAccessKey,\n    )}}`;\n  }\n}\n","/*\n * Copyright 2020 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { NotFoundError, NotModifiedError } from '@backstage/errors';\nimport fetch, { Response } from 'node-fetch';\nimport {\n  ReaderFactory,\n  ReadTreeResponse,\n  ReadUrlOptions,\n  ReadUrlResponse,\n  SearchResponse,\n  UrlReader,\n} from './types';\nimport path from 'path';\n\n/**\n * A {@link UrlReader} that does a plain fetch of the URL.\n *\n * @public\n */\nexport class FetchUrlReader implements UrlReader {\n  /**\n   * The factory creates a single reader that will be used for reading any URL that's listed\n   * in configuration at `backend.reading.allow`. The allow list contains a list of objects describing\n   * targets to allow, containing the following fields:\n   *\n   * `host`:\n   *   Either full hostnames to match, or subdomain wildcard matchers with a leading `*`.\n   *   For example `example.com` and `*.example.com` are valid values, `prod.*.example.com` is not.\n   *\n   * `paths`:\n   *   An optional list of paths which are allowed. If the list is omitted all paths are allowed.\n   */\n  static factory: ReaderFactory = ({ config }) => {\n    const predicates =\n      config\n        .getOptionalConfigArray('backend.reading.allow')\n        ?.map(allowConfig => {\n          const paths = allowConfig.getOptionalStringArray('paths');\n          const checkPath = paths\n            ? (url: URL) => {\n                const targetPath = path.posix.normalize(url.pathname);\n                return paths.some(allowedPath =>\n                  targetPath.startsWith(allowedPath),\n                );\n              }\n            : (_url: URL) => true;\n          const host = allowConfig.getString('host');\n          if (host.startsWith('*.')) {\n            const suffix = host.slice(1);\n            return (url: URL) => url.host.endsWith(suffix) && checkPath(url);\n          }\n          return (url: URL) => url.host === host && checkPath(url);\n        }) ?? [];\n\n    const reader = new FetchUrlReader();\n    const predicate = (url: URL) => predicates.some(p => p(url));\n    return [{ reader, predicate }];\n  };\n\n  async read(url: string): Promise<Buffer> {\n    const response = await this.readUrl(url);\n    return response.buffer();\n  }\n\n  async readUrl(\n    url: string,\n    options?: ReadUrlOptions,\n  ): Promise<ReadUrlResponse> {\n    let response: Response;\n    try {\n      response = await fetch(url, {\n        headers: {\n          ...(options?.etag && { 'If-None-Match': options.etag }),\n        },\n        // TODO(freben): The signal cast is there because pre-3.x versions of\n        // node-fetch have a very slightly deviating AbortSignal type signature.\n        // The difference does not affect us in practice however. The cast can\n        // be removed after we support ESM for CLI dependencies and migrate to\n        // version 3 of node-fetch.\n        // https://github.com/backstage/backstage/issues/8242\n        signal: options?.signal as any,\n      });\n    } catch (e) {\n      throw new Error(`Unable to read ${url}, ${e}`);\n    }\n\n    if (response.status === 304) {\n      throw new NotModifiedError();\n    }\n\n    if (response.ok) {\n      return {\n        buffer: async () => Buffer.from(await response.arrayBuffer()),\n        etag: response.headers.get('ETag') ?? undefined,\n      };\n    }\n\n    const message = `could not read ${url}, ${response.status} ${response.statusText}`;\n    if (response.status === 404) {\n      throw new NotFoundError(message);\n    }\n    throw new Error(message);\n  }\n\n  async readTree(): Promise<ReadTreeResponse> {\n    throw new Error('FetchUrlReader does not implement readTree');\n  }\n\n  async search(): Promise<SearchResponse> {\n    throw new Error('FetchUrlReader does not implement search');\n  }\n\n  toString() {\n    return 'fetch{}';\n  }\n}\n","/*\n * Copyright 2020 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { NotAllowedError } from '@backstage/errors';\nimport { Logger } from 'winston';\nimport {\n  ReadTreeOptions,\n  ReadTreeResponse,\n  ReadUrlOptions,\n  ReadUrlResponse,\n  SearchOptions,\n  SearchResponse,\n  UrlReader,\n  UrlReaderPredicateTuple,\n} from './types';\n\nconst MIN_WARNING_INTERVAL_MS = 1000 * 60 * 15;\n\n/**\n * A UrlReader implementation that selects from a set of UrlReaders\n * based on a predicate tied to each reader.\n */\nexport class UrlReaderPredicateMux implements UrlReader {\n  private readonly readers: UrlReaderPredicateTuple[] = [];\n  private readonly readerWarnings: Map<UrlReader, number> = new Map();\n\n  constructor(private readonly logger: Logger) {}\n\n  register(tuple: UrlReaderPredicateTuple): void {\n    this.readers.push(tuple);\n  }\n\n  async read(url: string): Promise<Buffer> {\n    const parsed = new URL(url);\n\n    for (const { predicate, reader } of this.readers) {\n      if (predicate(parsed)) {\n        return reader.read(url);\n      }\n    }\n\n    throw new NotAllowedError(\n      `Reading from '${url}' is not allowed. ` +\n        `You may need to configure an integration for the target host, or add it ` +\n        `to the configured list of allowed hosts at 'backend.reading.allow'`,\n    );\n  }\n\n  async readUrl(\n    url: string,\n    options?: ReadUrlOptions,\n  ): Promise<ReadUrlResponse> {\n    const parsed = new URL(url);\n\n    for (const { predicate, reader } of this.readers) {\n      if (predicate(parsed)) {\n        if (reader.readUrl) {\n          return reader.readUrl(url, options);\n        }\n        const now = Date.now();\n        const lastWarned = this.readerWarnings.get(reader) ?? 0;\n        if (now > lastWarned + MIN_WARNING_INTERVAL_MS) {\n          this.readerWarnings.set(reader, now);\n          this.logger.warn(\n            `No implementation of readUrl found for ${reader}, this method will be required in the ` +\n              `future and will replace the 'read' method. See the changelog for more details here: ` +\n              'https://github.com/backstage/backstage/blob/master/packages/backend-common/CHANGELOG.md#085',\n          );\n        }\n        const buffer = await reader.read(url);\n        return {\n          buffer: async () => buffer,\n        };\n      }\n    }\n\n    throw new NotAllowedError(`Reading from '${url}' is not allowed`);\n  }\n\n  async readTree(\n    url: string,\n    options?: ReadTreeOptions,\n  ): Promise<ReadTreeResponse> {\n    const parsed = new URL(url);\n\n    for (const { predicate, reader } of this.readers) {\n      if (predicate(parsed)) {\n        return await reader.readTree(url, options);\n      }\n    }\n\n    throw new NotAllowedError(`Reading from '${url}' is not allowed`);\n  }\n\n  async search(url: string, options?: SearchOptions): Promise<SearchResponse> {\n    const parsed = new URL(url);\n\n    for (const { predicate, reader } of this.readers) {\n      if (predicate(parsed)) {\n        return await reader.search(url, options);\n      }\n    }\n\n    throw new NotAllowedError(`Reading from '${url}' is not allowed`);\n  }\n\n  toString() {\n    return `predicateMux{readers=${this.readers.map(t => t.reader).join(',')}`;\n  }\n}\n","/*\n * Copyright 2020 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport concatStream from 'concat-stream';\nimport fs from 'fs-extra';\nimport platformPath from 'path';\nimport { pipeline as pipelineCb, Readable } from 'stream';\nimport tar, { Parse, ParseStream, ReadEntry } from 'tar';\nimport { promisify } from 'util';\nimport {\n  ReadTreeResponse,\n  ReadTreeResponseDirOptions,\n  ReadTreeResponseFile,\n} from '../types';\nimport { stripFirstDirectoryFromPath } from './util';\n\n// Tar types for `Parse` is not a proper constructor, but it should be\nconst TarParseStream = Parse as unknown as { new (): ParseStream };\n\nconst pipeline = promisify(pipelineCb);\n\n/**\n * Wraps a tar archive stream into a tree response reader.\n */\nexport class TarArchiveResponse implements ReadTreeResponse {\n  private read = false;\n\n  constructor(\n    private readonly stream: Readable,\n    private readonly subPath: string,\n    private readonly workDir: string,\n    public readonly etag: string,\n    private readonly filter?: (path: string, info: { size: number }) => boolean,\n  ) {\n    if (subPath) {\n      if (!subPath.endsWith('/')) {\n        this.subPath += '/';\n      }\n      if (subPath.startsWith('/')) {\n        throw new TypeError(\n          `TarArchiveResponse subPath must not start with a /, got '${subPath}'`,\n        );\n      }\n    }\n\n    this.etag = etag;\n  }\n\n  // Make sure the input stream is only read once\n  private onlyOnce() {\n    if (this.read) {\n      throw new Error('Response has already been read');\n    }\n    this.read = true;\n  }\n\n  async files(): Promise<ReadTreeResponseFile[]> {\n    this.onlyOnce();\n\n    const files = Array<ReadTreeResponseFile>();\n    const parser = new TarParseStream();\n\n    parser.on('entry', (entry: ReadEntry & Readable) => {\n      if (entry.type === 'Directory') {\n        entry.resume();\n        return;\n      }\n\n      // File path relative to the root extracted directory. Will remove the\n      // top level dir name from the path since its name is hard to predetermine.\n      const relativePath = stripFirstDirectoryFromPath(entry.path);\n\n      if (this.subPath) {\n        if (!relativePath.startsWith(this.subPath)) {\n          entry.resume();\n          return;\n        }\n      }\n\n      const path = relativePath.slice(this.subPath.length);\n      if (this.filter) {\n        if (!this.filter(path, { size: entry.remain })) {\n          entry.resume();\n          return;\n        }\n      }\n\n      const content = new Promise<Buffer>(async resolve => {\n        await pipeline(entry, concatStream(resolve));\n      });\n\n      files.push({\n        path,\n        content: () => content,\n      });\n\n      entry.resume();\n    });\n\n    await pipeline(this.stream, parser);\n\n    return files;\n  }\n\n  async archive(): Promise<Readable> {\n    if (!this.subPath) {\n      this.onlyOnce();\n\n      return this.stream;\n    }\n\n    // TODO(Rugvip): method for repacking a tar with a subpath is to simply extract into a\n    //               tmp dir and recreate the archive. Would be nicer to stream things instead.\n    const tmpDir = await this.dir();\n\n    try {\n      const data = await new Promise<Buffer>(async resolve => {\n        await pipeline(\n          tar.create({ cwd: tmpDir }, ['']),\n          concatStream(resolve),\n        );\n      });\n      return Readable.from(data);\n    } finally {\n      await fs.remove(tmpDir);\n    }\n  }\n\n  async dir(options?: ReadTreeResponseDirOptions): Promise<string> {\n    this.onlyOnce();\n\n    const dir =\n      options?.targetDir ??\n      (await fs.mkdtemp(platformPath.join(this.workDir, 'backstage-')));\n\n    // Equivalent of tar --strip-components=N\n    // When no subPath is given, remove just 1 top level directory\n    const strip = this.subPath ? this.subPath.split('/').length : 1;\n\n    let filterError: Error | undefined = undefined;\n\n    await pipeline(\n      this.stream,\n      tar.extract({\n        strip,\n        cwd: dir,\n        filter: (path, stat) => {\n          // Filter errors will short-circuit the rest of the filtering and then throw\n          if (filterError) {\n            return false;\n          }\n\n          // File path relative to the root extracted directory. Will remove the\n          // top level dir name from the path since its name is hard to predetermine.\n          const relativePath = stripFirstDirectoryFromPath(path);\n          if (this.subPath && !relativePath.startsWith(this.subPath)) {\n            return false;\n          }\n          if (this.filter) {\n            const innerPath = path.split('/').slice(strip).join('/');\n            try {\n              return this.filter(innerPath, { size: stat.size });\n            } catch (error) {\n              filterError = error;\n              return false;\n            }\n          }\n          return true;\n        },\n      }),\n    );\n\n    if (filterError) {\n      // If the dir was provided we don't want to remove it, but if it wasn't it means\n      // we created a temporary directory and we should remove it.\n      if (!options?.targetDir) {\n        await fs.remove(dir).catch(() => {});\n      }\n      throw filterError;\n    }\n\n    return dir;\n  }\n}\n","/*\n * Copyright 2020 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport archiver from 'archiver';\nimport fs from 'fs-extra';\nimport platformPath from 'path';\nimport { Readable } from 'stream';\nimport unzipper, { Entry } from 'unzipper';\nimport {\n  ReadTreeResponse,\n  ReadTreeResponseDirOptions,\n  ReadTreeResponseFile,\n} from '../types';\n\n/**\n * Wraps a zip archive stream into a tree response reader.\n */\nexport class ZipArchiveResponse implements ReadTreeResponse {\n  private read = false;\n\n  constructor(\n    private readonly stream: Readable,\n    private readonly subPath: string,\n    private readonly workDir: string,\n    public readonly etag: string,\n    private readonly filter?: (path: string, info: { size: number }) => boolean,\n  ) {\n    if (subPath) {\n      if (!subPath.endsWith('/')) {\n        this.subPath += '/';\n      }\n      if (subPath.startsWith('/')) {\n        throw new TypeError(\n          `ZipArchiveResponse subPath must not start with a /, got '${subPath}'`,\n        );\n      }\n    }\n\n    this.etag = etag;\n  }\n\n  // Make sure the input stream is only read once\n  private onlyOnce() {\n    if (this.read) {\n      throw new Error('Response has already been read');\n    }\n    this.read = true;\n  }\n\n  // File path relative to the root extracted directory or a sub directory if subpath is set.\n  private getInnerPath(path: string): string {\n    return path.slice(this.subPath.length);\n  }\n\n  private shouldBeIncluded(entry: Entry): boolean {\n    if (this.subPath) {\n      if (!entry.path.startsWith(this.subPath)) {\n        return false;\n      }\n    }\n    if (this.filter) {\n      return this.filter(this.getInnerPath(entry.path), {\n        size:\n          (entry.vars as { uncompressedSize?: number }).uncompressedSize ??\n          entry.vars.compressedSize,\n      });\n    }\n    return true;\n  }\n\n  async files(): Promise<ReadTreeResponseFile[]> {\n    this.onlyOnce();\n\n    const files = Array<ReadTreeResponseFile>();\n\n    await this.stream\n      .pipe(unzipper.Parse())\n      .on('entry', (entry: Entry) => {\n        if (entry.type === 'Directory') {\n          entry.resume();\n          return;\n        }\n\n        if (this.shouldBeIncluded(entry)) {\n          files.push({\n            path: this.getInnerPath(entry.path),\n            content: () => entry.buffer(),\n          });\n        } else {\n          entry.autodrain();\n        }\n      })\n      .promise();\n\n    return files;\n  }\n\n  async archive(): Promise<Readable> {\n    this.onlyOnce();\n\n    if (!this.subPath) {\n      return this.stream;\n    }\n\n    const archive = archiver('zip');\n    await this.stream\n      .pipe(unzipper.Parse())\n      .on('entry', (entry: Entry) => {\n        if (entry.type === 'File' && this.shouldBeIncluded(entry)) {\n          archive.append(entry, { name: this.getInnerPath(entry.path) });\n        } else {\n          entry.autodrain();\n        }\n      })\n      .promise();\n    archive.finalize();\n\n    return archive;\n  }\n\n  async dir(options?: ReadTreeResponseDirOptions): Promise<string> {\n    this.onlyOnce();\n\n    const dir =\n      options?.targetDir ??\n      (await fs.mkdtemp(platformPath.join(this.workDir, 'backstage-')));\n\n    await this.stream\n      .pipe(unzipper.Parse())\n      .on('entry', async (entry: Entry) => {\n        // Ignore directory entries since we handle that with the file entries\n        // as a zip can have files with directories without directory entries\n        if (entry.type === 'File' && this.shouldBeIncluded(entry)) {\n          const entryPath = this.getInnerPath(entry.path);\n          const dirname = platformPath.dirname(entryPath);\n          if (dirname) {\n            await fs.mkdirp(platformPath.join(dir, dirname));\n          }\n          entry.pipe(fs.createWriteStream(platformPath.join(dir, entryPath)));\n        } else {\n          entry.autodrain();\n        }\n      })\n      .promise();\n\n    return dir;\n  }\n}\n","/*\n * Copyright 2020 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport concatStream from 'concat-stream';\nimport platformPath, { basename } from 'path';\n\nimport getRawBody from 'raw-body';\nimport fs from 'fs-extra';\nimport { promisify } from 'util';\nimport tar from 'tar';\nimport { pipeline as pipelineCb, Readable } from 'stream';\nimport {\n  ReadTreeResponse,\n  ReadTreeResponseFile,\n  ReadTreeResponseDirOptions,\n  FromReadableArrayOptions,\n} from '../types';\n\nconst pipeline = promisify(pipelineCb);\n\n/**\n * Wraps a array of Readable objects into a tree response reader.\n */\nexport class ReadableArrayResponse implements ReadTreeResponse {\n  private read = false;\n\n  constructor(\n    private readonly stream: FromReadableArrayOptions,\n    private readonly workDir: string,\n    public readonly etag: string,\n  ) {\n    this.etag = etag;\n  }\n\n  // Make sure the input stream is only read once\n  private onlyOnce() {\n    if (this.read) {\n      throw new Error('Response has already been read');\n    }\n    this.read = true;\n  }\n\n  async files(): Promise<ReadTreeResponseFile[]> {\n    this.onlyOnce();\n\n    const files = Array<ReadTreeResponseFile>();\n\n    for (let i = 0; i < this.stream.length; i++) {\n      if (!this.stream[i].path.endsWith('/')) {\n        files.push({\n          path: this.stream[i].path,\n          content: () => getRawBody(this.stream[i].data),\n        });\n      }\n    }\n\n    return files;\n  }\n\n  async archive(): Promise<NodeJS.ReadableStream> {\n    const tmpDir = await this.dir();\n\n    try {\n      const data = await new Promise<Buffer>(async resolve => {\n        await pipeline(\n          tar.create({ cwd: tmpDir }, ['']),\n          concatStream(resolve),\n        );\n      });\n      return Readable.from(data);\n    } finally {\n      await fs.remove(tmpDir);\n    }\n  }\n\n  async dir(options?: ReadTreeResponseDirOptions): Promise<string> {\n    this.onlyOnce();\n\n    const dir =\n      options?.targetDir ??\n      (await fs.mkdtemp(platformPath.join(this.workDir, 'backstage-')));\n\n    for (let i = 0; i < this.stream.length; i++) {\n      if (!this.stream[i].path.endsWith('/')) {\n        await pipeline(\n          this.stream[i].data,\n          fs.createWriteStream(\n            platformPath.join(dir, basename(this.stream[i].path)),\n          ),\n        );\n      }\n    }\n\n    return dir;\n  }\n}\n","/*\n * Copyright 2020 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport os from 'os';\nimport { Config } from '@backstage/config';\nimport {\n  ReadTreeResponse,\n  ReadTreeResponseFactoryOptions,\n  ReadTreeResponseFactory,\n  FromReadableArrayOptions,\n} from '../types';\nimport { TarArchiveResponse } from './TarArchiveResponse';\nimport { ZipArchiveResponse } from './ZipArchiveResponse';\nimport { ReadableArrayResponse } from './ReadableArrayResponse';\n\nexport class DefaultReadTreeResponseFactory implements ReadTreeResponseFactory {\n  static create(options: { config: Config }): DefaultReadTreeResponseFactory {\n    return new DefaultReadTreeResponseFactory(\n      options.config.getOptionalString('backend.workingDirectory') ??\n        os.tmpdir(),\n    );\n  }\n\n  constructor(private readonly workDir: string) {}\n\n  async fromTarArchive(\n    options: ReadTreeResponseFactoryOptions,\n  ): Promise<ReadTreeResponse> {\n    return new TarArchiveResponse(\n      options.stream,\n      options.subpath ?? '',\n      this.workDir,\n      options.etag,\n      options.filter,\n    );\n  }\n\n  async fromZipArchive(\n    options: ReadTreeResponseFactoryOptions,\n  ): Promise<ReadTreeResponse> {\n    return new ZipArchiveResponse(\n      options.stream,\n      options.subpath ?? '',\n      this.workDir,\n      options.etag,\n      options.filter,\n    );\n  }\n\n  async fromReadableArray(\n    options: FromReadableArrayOptions,\n  ): Promise<ReadTreeResponse> {\n    return new ReadableArrayResponse(options, this.workDir, '');\n  }\n}\n","/*\n * Copyright 2020 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Storage } from '@google-cloud/storage';\nimport {\n  ReaderFactory,\n  ReadTreeResponse,\n  ReadUrlOptions,\n  ReadUrlResponse,\n  SearchResponse,\n  UrlReader,\n} from './types';\nimport getRawBody from 'raw-body';\nimport {\n  GoogleGcsIntegrationConfig,\n  readGoogleGcsIntegrationConfig,\n} from '@backstage/integration';\n\nconst GOOGLE_GCS_HOST = 'storage.cloud.google.com';\n\nconst parseURL = (\n  url: string,\n): { host: string; bucket: string; key: string } => {\n  const { host, pathname } = new URL(url);\n\n  if (host !== GOOGLE_GCS_HOST) {\n    throw new Error(`not a valid GCS URL: ${url}`);\n  }\n\n  const [, bucket, ...key] = pathname.split('/');\n  return {\n    host: host,\n    bucket,\n    key: key.join('/'),\n  };\n};\n\n/**\n * Implements a {@link UrlReader} for files on Google GCS.\n *\n * @public\n */\nexport class GoogleGcsUrlReader implements UrlReader {\n  static factory: ReaderFactory = ({ config, logger }) => {\n    if (!config.has('integrations.googleGcs')) {\n      return [];\n    }\n    const gcsConfig = readGoogleGcsIntegrationConfig(\n      config.getConfig('integrations.googleGcs'),\n    );\n    let storage: Storage;\n    if (!gcsConfig.clientEmail || !gcsConfig.privateKey) {\n      logger.info(\n        'googleGcs credentials not found in config. Using default credentials provider.',\n      );\n      storage = new Storage();\n    } else {\n      storage = new Storage({\n        credentials: {\n          client_email: gcsConfig.clientEmail || undefined,\n          private_key: gcsConfig.privateKey || undefined,\n        },\n      });\n    }\n    const reader = new GoogleGcsUrlReader(gcsConfig, storage);\n    const predicate = (url: URL) => url.host === GOOGLE_GCS_HOST;\n    return [{ reader, predicate }];\n  };\n\n  constructor(\n    private readonly integration: GoogleGcsIntegrationConfig,\n    private readonly storage: Storage,\n  ) {}\n\n  async read(url: string): Promise<Buffer> {\n    try {\n      const { bucket, key } = parseURL(url);\n\n      return await getRawBody(\n        this.storage.bucket(bucket).file(key).createReadStream(),\n      );\n    } catch (error) {\n      throw new Error(`unable to read gcs file from ${url}, ${error}`);\n    }\n  }\n\n  async readUrl(\n    url: string,\n    _options?: ReadUrlOptions,\n  ): Promise<ReadUrlResponse> {\n    // TODO etag is not implemented yet.\n    const buffer = await this.read(url);\n    return { buffer: async () => buffer };\n  }\n\n  async readTree(): Promise<ReadTreeResponse> {\n    throw new Error('GcsUrlReader does not implement readTree');\n  }\n\n  async search(): Promise<SearchResponse> {\n    throw new Error('GcsUrlReader does not implement search');\n  }\n\n  toString() {\n    const key = this.integration.privateKey;\n    return `googleGcs{host=${GOOGLE_GCS_HOST},authed=${Boolean(key)}}`;\n  }\n}\n","/*\n * Copyright 2020 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Logger } from 'winston';\nimport { Config } from '@backstage/config';\nimport { ReaderFactory, UrlReader } from './types';\nimport { UrlReaderPredicateMux } from './UrlReaderPredicateMux';\nimport { AzureUrlReader } from './AzureUrlReader';\nimport { BitbucketUrlReader } from './BitbucketUrlReader';\nimport { GithubUrlReader } from './GithubUrlReader';\nimport { GitlabUrlReader } from './GitlabUrlReader';\nimport { DefaultReadTreeResponseFactory } from './tree';\nimport { FetchUrlReader } from './FetchUrlReader';\nimport { GoogleGcsUrlReader } from './GoogleGcsUrlReader';\nimport { AwsS3UrlReader } from './AwsS3UrlReader';\n\n/**\n * Creation options for {@link UrlReaders}.\n *\n * @public\n */\nexport type UrlReadersOptions = {\n  /** Root config object */\n  config: Config;\n  /** Logger used by all the readers */\n  logger: Logger;\n  /** A list of factories used to construct individual readers that match on URLs */\n  factories?: ReaderFactory[];\n};\n\n/**\n * Helps construct {@link UrlReader}s.\n *\n * @public\n */\nexport class UrlReaders {\n  /**\n   * Creates a custom {@link UrlReader} wrapper for your own set of factories.\n   */\n  static create(options: UrlReadersOptions): UrlReader {\n    const { logger, config, factories } = options;\n    const mux = new UrlReaderPredicateMux(logger);\n    const treeResponseFactory = DefaultReadTreeResponseFactory.create({\n      config,\n    });\n\n    for (const factory of factories ?? []) {\n      const tuples = factory({ config, logger: logger, treeResponseFactory });\n\n      for (const tuple of tuples) {\n        mux.register(tuple);\n      }\n    }\n\n    return mux;\n  }\n\n  /**\n   * Creates a {@link UrlReader} wrapper that includes all the default factories\n   * from this package.\n   *\n   * Any additional factories passed will be loaded before the default ones.\n   */\n  static default(options: UrlReadersOptions) {\n    const { logger, config, factories = [] } = options;\n    return UrlReaders.create({\n      logger,\n      config,\n      factories: factories.concat([\n        AzureUrlReader.factory,\n        BitbucketUrlReader.factory,\n        GithubUrlReader.factory,\n        GitlabUrlReader.factory,\n        GoogleGcsUrlReader.factory,\n        AwsS3UrlReader.factory,\n        FetchUrlReader.factory,\n      ]),\n    });\n  }\n}\n","/*\n * Copyright 2020 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport git, {\n  ProgressCallback,\n  MergeResult,\n  ReadCommitResult,\n} from 'isomorphic-git';\nimport http from 'isomorphic-git/http/node';\nimport fs from 'fs-extra';\nimport { Logger } from 'winston';\n\n/*\nprovider    username         password\nGitHub      'x-access-token' token\nBitBucket   'x-token-auth'   token\nGitLab      'oauth2'         token\nFrom : https://isomorphic-git.org/docs/en/onAuth with fix for GitHub\n\nAzure       'notempty'      token\n*/\n\n/**\n * A convenience wrapper around the `isomorphic-git` library.\n *\n * @public\n */\nexport class Git {\n  private constructor(\n    private readonly config: {\n      username?: string;\n      password?: string;\n      logger?: Logger;\n    },\n  ) {}\n\n  async add(options: { dir: string; filepath: string }): Promise<void> {\n    const { dir, filepath } = options;\n    this.config.logger?.info(`Adding file {dir=${dir},filepath=${filepath}}`);\n\n    return git.add({ fs, dir, filepath });\n  }\n\n  async addRemote(options: {\n    dir: string;\n    remote: string;\n    url: string;\n  }): Promise<void> {\n    const { dir, url, remote } = options;\n    this.config.logger?.info(\n      `Creating new remote {dir=${dir},remote=${remote},url=${url}}`,\n    );\n    return git.addRemote({ fs, dir, remote, url });\n  }\n\n  async commit(options: {\n    dir: string;\n    message: string;\n    author: { name: string; email: string };\n    committer: { name: string; email: string };\n  }): Promise<string> {\n    const { dir, message, author, committer } = options;\n    this.config.logger?.info(\n      `Committing file to repo {dir=${dir},message=${message}}`,\n    );\n\n    return git.commit({ fs, dir, message, author, committer });\n  }\n\n  /** https://isomorphic-git.org/docs/en/clone */\n  async clone(options: {\n    url: string;\n    dir: string;\n    ref?: string;\n    depth?: number;\n    noCheckout?: boolean;\n  }): Promise<void> {\n    const { url, dir, ref, depth, noCheckout } = options;\n    this.config.logger?.info(`Cloning repo {dir=${dir},url=${url}}`);\n    return git.clone({\n      fs,\n      http,\n      url,\n      dir,\n      ref,\n      singleBranch: true,\n      depth: depth ?? 1,\n      noCheckout,\n      onProgress: this.onProgressHandler(),\n      headers: {\n        'user-agent': 'git/@isomorphic-git',\n      },\n      onAuth: this.onAuth,\n    });\n  }\n\n  /** https://isomorphic-git.org/docs/en/currentBranch */\n  async currentBranch(options: {\n    dir: string;\n    fullName?: boolean;\n  }): Promise<string | undefined> {\n    const { dir, fullName = false } = options;\n    return git.currentBranch({ fs, dir, fullname: fullName }) as Promise<\n      string | undefined\n    >;\n  }\n\n  /** https://isomorphic-git.org/docs/en/fetch */\n  async fetch(options: { dir: string; remote?: string }): Promise<void> {\n    const { dir, remote = 'origin' } = options;\n    this.config.logger?.info(\n      `Fetching remote=${remote} for repository {dir=${dir}}`,\n    );\n    await git.fetch({\n      fs,\n      http,\n      dir,\n      remote,\n      onProgress: this.onProgressHandler(),\n      headers: { 'user-agent': 'git/@isomorphic-git' },\n      onAuth: this.onAuth,\n    });\n  }\n\n  async init(options: { dir: string; defaultBranch?: string }): Promise<void> {\n    const { dir, defaultBranch = 'master' } = options;\n    this.config.logger?.info(`Init git repository {dir=${dir}}`);\n\n    return git.init({\n      fs,\n      dir,\n      defaultBranch,\n    });\n  }\n\n  /** https://isomorphic-git.org/docs/en/merge */\n  async merge(options: {\n    dir: string;\n    theirs: string;\n    ours?: string;\n    author: { name: string; email: string };\n    committer: { name: string; email: string };\n  }): Promise<MergeResult> {\n    const { dir, theirs, ours, author, committer } = options;\n    this.config.logger?.info(\n      `Merging branch '${theirs}' into '${ours}' for repository {dir=${dir}}`,\n    );\n\n    // If ours is undefined, current branch is used.\n    return git.merge({\n      fs,\n      dir,\n      ours,\n      theirs,\n      author,\n      committer,\n    });\n  }\n\n  async push(options: { dir: string; remote: string }) {\n    const { dir, remote } = options;\n    this.config.logger?.info(\n      `Pushing directory to remote {dir=${dir},remote=${remote}}`,\n    );\n    return git.push({\n      fs,\n      dir,\n      http,\n      onProgress: this.onProgressHandler(),\n      headers: {\n        'user-agent': 'git/@isomorphic-git',\n      },\n      remote: remote,\n      onAuth: this.onAuth,\n    });\n  }\n\n  /** https://isomorphic-git.org/docs/en/readCommit */\n  async readCommit(options: {\n    dir: string;\n    sha: string;\n  }): Promise<ReadCommitResult> {\n    const { dir, sha } = options;\n    return git.readCommit({ fs, dir, oid: sha });\n  }\n\n  /** https://isomorphic-git.org/docs/en/resolveRef */\n  async resolveRef(options: { dir: string; ref: string }): Promise<string> {\n    const { dir, ref } = options;\n    return git.resolveRef({ fs, dir, ref });\n  }\n\n  /** https://isomorphic-git.org/docs/en/log */\n  async log(options: {\n    dir: string;\n    ref?: string;\n  }): Promise<ReadCommitResult[]> {\n    const { dir, ref } = options;\n    return git.log({\n      fs,\n      dir,\n      ref: ref ?? 'HEAD',\n    });\n  }\n\n  private onAuth = () => ({\n    username: this.config.username,\n    password: this.config.password,\n  });\n\n  private onProgressHandler = (): ProgressCallback => {\n    let currentPhase = '';\n\n    return event => {\n      if (currentPhase !== event.phase) {\n        currentPhase = event.phase;\n        this.config.logger?.info(event.phase);\n      }\n      const total = event.total\n        ? `${Math.round((event.loaded / event.total) * 100)}%`\n        : event.loaded;\n      this.config.logger?.debug(`status={${event.phase},total={${total}}}`);\n    };\n  };\n\n  static fromAuth = (options: {\n    username?: string;\n    password?: string;\n    logger?: Logger;\n  }) => {\n    const { username, password, logger } = options;\n    return new Git({ username, password, logger });\n  };\n}\n","/*\n * Copyright 2020 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { ServiceBuilderImpl } from './lib/ServiceBuilderImpl';\nimport { ServiceBuilder } from './types';\n\n/**\n * Creates a new service builder.\n *\n * @public\n */\nexport function createServiceBuilder(_module: NodeModule): ServiceBuilder {\n  return new ServiceBuilderImpl(_module);\n}\n","/*\n * Copyright 2020 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Logger } from 'winston';\nimport Router from 'express-promise-router';\nimport express from 'express';\nimport { errorHandler, statusCheckHandler, StatusCheck } from '../middleware';\n\n/**\n * Creates a default status checking router, that you can add to your express\n * app.\n *\n * @remarks\n *\n * This adds a `/healthcheck` route (or any other path, if given as an\n * argument), which your infra can call to see if the service is ready to serve\n * requests.\n *\n * @public\n */\nexport async function createStatusCheckRouter(options: {\n  logger: Logger;\n  /**\n   * The path (including a leading slash) that the health check should be\n   * mounted on.\n   *\n   * @defaultValue '/healthcheck'\n   */\n  path?: string;\n  /**\n   * If not implemented, the default express middleware always returns 200.\n   * Override this to implement your own logic for a health check.\n   */\n  statusCheck?: StatusCheck;\n}): Promise<express.Router> {\n  const router = Router();\n  const { path = '/healthcheck', statusCheck } = options;\n\n  router.use(path, await statusCheckHandler({ statusCheck }));\n  router.use(errorHandler());\n\n  return router;\n}\n","/*\n * Copyright 2021 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { JWKS, JWK, JWT } from 'jose';\nimport { Config } from '@backstage/config';\nimport { AuthenticationError } from '@backstage/errors';\nimport { TokenManager } from './types';\nimport { Logger } from 'winston';\n\nclass NoopTokenManager implements TokenManager {\n  public readonly isInsecureServerTokenManager: boolean = true;\n\n  async getToken() {\n    return { token: '' };\n  }\n\n  async authenticate() {}\n}\n\n/**\n * Creates and validates tokens for use during backend-to-backend\n * authentication.\n *\n * @public\n */\nexport class ServerTokenManager implements TokenManager {\n  private readonly verificationKeys: JWKS.KeyStore;\n  private readonly signingKey: JWK.Key;\n\n  static noop(): TokenManager {\n    return new NoopTokenManager();\n  }\n\n  static fromConfig(config: Config, options: { logger: Logger }) {\n    const { logger } = options;\n\n    const keys = config.getOptionalConfigArray('backend.auth.keys');\n    if (keys?.length) {\n      return new ServerTokenManager(keys.map(key => key.getString('secret')));\n    }\n    if (process.env.NODE_ENV !== 'development') {\n      throw new Error(\n        'You must configure at least one key in backend.auth.keys for production.',\n      );\n    }\n\n    // For development, if a secret has not been configured, we auto generate a secret instead of throwing.\n    const generatedDevOnlyKey = JWK.generateSync('oct', 24 * 8);\n    if (generatedDevOnlyKey.k === undefined) {\n      throw new Error('Internal error, JWK key generation returned no data');\n    }\n    logger.warn(\n      'Generated a secret for backend-to-backend authentication: DEVELOPMENT USE ONLY.',\n    );\n    return new ServerTokenManager([generatedDevOnlyKey.k]);\n  }\n\n  private constructor(secrets: string[]) {\n    if (!secrets.length) {\n      throw new Error(\n        'No secrets provided when constructing ServerTokenManager',\n      );\n    }\n\n    this.verificationKeys = new JWKS.KeyStore(\n      secrets.map(k => JWK.asKey({ kty: 'oct', k })),\n    );\n    this.signingKey = this.verificationKeys.all()[0];\n  }\n\n  async getToken(): Promise<{ token: string }> {\n    const jwt = JWT.sign({ sub: 'backstage-server' }, this.signingKey, {\n      algorithm: 'HS256',\n    });\n\n    return { token: jwt };\n  }\n\n  async authenticate(token: string): Promise<void> {\n    try {\n      JWT.verify(token, this.verificationKeys);\n    } catch (e) {\n      throw new AuthenticationError('Invalid server token');\n    }\n  }\n}\n","/*\n * Copyright 2020 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport Docker from 'dockerode';\nimport fs from 'fs-extra';\nimport { ForwardedError } from '@backstage/errors';\nimport { PassThrough } from 'stream';\nimport { ContainerRunner, RunContainerOptions } from './ContainerRunner';\n\nexport type UserOptions = {\n  User?: string;\n};\n\n/**\n * A {@link ContainerRunner} for Docker containers.\n *\n * @public\n */\nexport class DockerContainerRunner implements ContainerRunner {\n  private readonly dockerClient: Docker;\n\n  constructor(options: { dockerClient: Docker }) {\n    this.dockerClient = options.dockerClient;\n  }\n\n  async runContainer(options: RunContainerOptions) {\n    const {\n      imageName,\n      command,\n      args,\n      logStream = new PassThrough(),\n      mountDirs = {},\n      workingDir,\n      envVars = {},\n      pullImage = true,\n    } = options;\n\n    // Show a better error message when Docker is unavailable.\n    try {\n      await this.dockerClient.ping();\n    } catch (e) {\n      throw new ForwardedError(\n        'This operation requires Docker. Docker does not appear to be available. Docker.ping() failed with',\n        e,\n      );\n    }\n\n    if (pullImage) {\n      await new Promise<void>((resolve, reject) => {\n        this.dockerClient.pull(imageName, {}, (err, stream) => {\n          if (err) return reject(err);\n          stream.pipe(logStream, { end: false });\n          stream.on('end', () => resolve());\n          stream.on('error', (error: Error) => reject(error));\n          return undefined;\n        });\n      });\n    }\n\n    const userOptions: UserOptions = {};\n    if (process.getuid && process.getgid) {\n      // Files that are created inside the Docker container will be owned by\n      // root on the host system on non Mac systems, because of reasons. Mainly the fact that\n      // volume sharing is done using NFS on Mac and actual mounts in Linux world.\n      // So we set the user in the container as the same user and group id as the host.\n      // On Windows we don't have process.getuid nor process.getgid\n      userOptions.User = `${process.getuid()}:${process.getgid()}`;\n    }\n\n    // Initialize volumes to mount based on mountDirs map\n    const Volumes: { [T: string]: object } = {};\n    for (const containerDir of Object.values(mountDirs)) {\n      Volumes[containerDir] = {};\n    }\n\n    // Create bind volumes\n    const Binds: string[] = [];\n    for (const [hostDir, containerDir] of Object.entries(mountDirs)) {\n      // Need to use realpath here as Docker mounting does not like\n      // symlinks for binding volumes\n      const realHostDir = await fs.realpath(hostDir);\n      Binds.push(`${realHostDir}:${containerDir}`);\n    }\n\n    // Create docker environment variables array\n    const Env = [];\n    for (const [key, value] of Object.entries(envVars)) {\n      Env.push(`${key}=${value}`);\n    }\n\n    const [{ Error: error, StatusCode: statusCode }] =\n      await this.dockerClient.run(imageName, args, logStream, {\n        Volumes,\n        HostConfig: {\n          AutoRemove: true,\n          Binds,\n        },\n        ...(workingDir ? { WorkingDir: workingDir } : {}),\n        Entrypoint: command,\n        Env,\n        ...userOptions,\n      } as Docker.ContainerCreateOptions);\n\n    if (error) {\n      throw new Error(\n        `Docker failed to run with the following error message: ${error}`,\n      );\n    }\n\n    if (statusCode !== 0) {\n      throw new Error(\n        `Docker container returned a non-zero exit code (${statusCode})`,\n      );\n    }\n  }\n}\n"],"names":["winston","merge","PassThrough","createHash","Keyv","KeyvRedis","KeyvMemcache","ConfigReader","parseArgs","resolvePath","findPaths","getPackages","loadConfigSchema","config","loadConfig","AbortController","knexFactory","yn","InputError","ForwardedError","path","omit","Minimatch","serializeError","NotModifiedError","AuthenticationError","NotAllowedError","NotFoundError","ConflictError","morgan","http","https","fs","dirname","express","helmet","cors","compression","defaultRequestLoggingHandler","defaultErrorHandler","stoppable","isChildPath","getAzureFileFetchUrl","fetch","getAzureRequestOptions","getAzureCommitsUrl","getAzureDownloadUrl","ScmIntegrations","getBitbucketFileFetchUrl","getBitbucketRequestOptions","parseGitUrl","getBitbucketDownloadUrl","trimEnd","getBitbucketDefaultBranch","getGitHubFileFetchUrl","DefaultGithubCredentialsProvider","getGitLabFileFetchUrl","getGitLabRequestOptions","parseURL","Credentials","aws","getRawBody","S3","Parse","pipeline","promisify","pipelineCb","concatStream","tar","Readable","platformPath","unzipper","archiver","basename","os","readGoogleGcsIntegrationConfig","storage","Storage","git","Router","JWK","JWKS","JWT"],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAmBA,MAAM,kBAAkB,CAAC,SAA4B;AACnD,QAAM,EAAE,WAAW,OAAO,SAAS,QAAQ,YAAY,WAAW;AAClE,QAAM,YAAYA,mBAAQ,OAAO;AACjC,QAAM,SAAS,UAAU;AACzB,QAAM,iBAAiB,UAAU,SAAS,aAAa;AACvD,QAAM,cAAc,UAAU,SAAS,UAAU;AAEjD,QAAM,cAAc,OAAO,QAAQ,QAChC,IAAI,CAAC,CAAC,KAAK,WAAW,GAAG,UAAU,SAAS,SAAS,GAAG,UAAU,SAClE,KAAK;AAER,SAAO,GAAG,kBAAkB,eAAe,SAAS,WAAW;AAAA;MAQpD,gBAAgBA,mBAAQ,OAAO,QAC1CA,mBAAQ,OAAO,aACfA,mBAAQ,OAAO,SAAS;AAAA,EACtB,QAAQ,EAAE,WAAW,OAAO,QAAQ,QAAQ,OAAO,QAAQ,OAAO;AAAA,IAEpEA,mBAAQ,OAAO,OAAO;;MCtBX,eAAe,CAAC,SAAiB;AAC5C,SAAO,KAAK,QAAQ,wBAAwB;AAAA;;ACA9C,IAAI;AACJ,IAAI;yBAO4C;AAC9C,SAAO;AAAA;uBAiBqB,WAA2B;AACvD,eAAa;AAAA;oCAG4B,eAAyB;AAIlE,QAAM,WAAW,cAAc,OAAO,OAAK,EAAE,SAAS;AAEtD,MAAI,SAAS,QAAQ;AACnB,sBAAkB,IAAI,OACpB,IAAI,SAAS,IAAI,cAAc,KAAK,SACpC;AAAA,SAEG;AACL,sBAAkB;AAAA;AAAA;AAQtB,uBAAuB,MAAyC;AAO9D,MAAI,mBAAmB,OAAO,KAAK,YAAY,UAAU;AACvD,SAAK,UAAU,KAAK,QAAQ,QAAQ,iBAAiB;AAAA;AAGvD,SAAO;AAAA;0BAeP,UAAiC,IACjC,MAAM,QAAQ,KACE;AAChB,QAAM,SAASA,mBAAQ,aACrBC,aACE;AAAA,IACE,OAAO,IAAI,aAAa;AAAA,IACxB,QAAQD,mBAAQ,OAAO,QACrBA,mBAAQ,OAAO,kBACf,IAAI,aAAa,eAAeA,mBAAQ,OAAO,SAAS;AAAA,IAE1D,aAAa;AAAA,MACX,SAAS;AAAA;AAAA,IAEX,YAAY;AAAA,MACV,IAAIA,mBAAQ,WAAW,QAAQ;AAAA,QAC7B,QAAQ,IAAI,mBAAmB,UAAa,CAAC,IAAI;AAAA;AAAA;AAAA,KAIvD;AAIJ,gBAAc;AAEd,SAAO;AAAA;AAGT,aAAa;;yBCvGmC;AAC9C,SAAOA,mBAAQ,aAAa;AAAA,IAC1B,YAAY,CAAC,IAAIA,mBAAQ,WAAW,OAAO,EAAE,QAAQ,IAAIE;AAAA;AAAA;;yBC6CN;AAAA,EAGrD,YAAY,EAAE,UAA2B;AACvC,SAAK,SAAS;AAAA;AAAA,QAGV,IAAI,KAA6C;AACrD,UAAM,IAAI,KAAK,iBAAiB;AAChC,WAAO,MAAM,KAAK,OAAO,IAAI;AAAA;AAAA,QAGzB,IACJ,KACA,OACA,OAA8B,IACf;AACf,UAAM,IAAI,KAAK,iBAAiB;AAChC,UAAM,KAAK,OAAO,IAAI,GAAG,OAAO,KAAK;AAAA;AAAA,QAGjC,OAAO,KAA4B;AACvC,UAAM,IAAI,KAAK,iBAAiB;AAChC,UAAM,KAAK,OAAO,OAAO;AAAA;AAAA,EAMnB,iBAAiB,cAA8B;AAErD,UAAM,gBAAgB,OAAO,KAAK,cAAc,SAAS;AAIzD,QAAI,cAAc,SAAS,KAAK;AAC9B,aAAO;AAAA;AAGT,WAAOC,kBAAW,OAAO,OAAO,cAAc,OAAO;AAAA;AAAA;;sBC1F5B,IAAiB;AAAA,EAC5C,QAAc;AACZ;AAAA;AAAA,EAGF,OAAO,MAAuB;AAC5B,WAAO;AAAA;AAAA,EAGT,IAAI,MAAc;AAChB;AAAA;AAAA,EAGF,IAAI,MAAuB;AACzB,WAAO;AAAA;AAAA,EAGT,IAAI,MAAc,QAAmB;AACnC,WAAO;AAAA;AAAA;;mBCHe;AAAA,EA6ChB,YACN,OACA,kBACA,QACA,cACA;AA7Ce,0BAAiB;AAAA,MAChC,OAAO,KAAK;AAAA,MACZ,UAAU,KAAK;AAAA,MACf,QAAQ,KAAK;AAAA,MACb,MAAM,KAAK;AAAA;AAQI,2CAAkB;AAkCjC,QAAI,CAAC,KAAK,eAAe,eAAe,QAAQ;AAC9C,YAAM,IAAI,MAAM,wBAAwB;AAAA;AAE1C,SAAK,SAAS;AACd,SAAK,QAAQ;AACb,SAAK,aAAa;AAClB,SAAK,eAAe;AAAA;AAAA,SA3Bf,WACL,QACA,UAA+B,IACjB;AAGd,UAAM,QAAQ,OAAO,kBAAkB,0BAA0B;AACjE,UAAM,mBACJ,OAAO,kBAAkB,+BAA+B;AAC1D,UAAM,SAAU,SAAQ,UAAU,iBAAiB,MAAM;AAAA,MACvD,MAAM;AAAA;AAER,WAAO,IAAI,aAAa,OAAO,kBAAkB,QAAQ,QAAQ;AAAA;AAAA,EAwBnE,UAAU,UAAsC;AAC9C,WAAO;AAAA,MACL,WAAW,CAAC,OAAO,OAAoB;AACrC,cAAM,iBAAiB,KAAK,iBAAiB,UAAU,KAAK;AAG5D,uBAAe,GAAG,SAAS,CAAC,QAAe;AAEzC,eAAK,OAAO,MAAM;AAGlB,cAAI,OAAO,KAAK,iBAAiB,YAAY;AAC3C,iBAAK,aAAa;AAAA;AAAA;AAItB,eAAO,IAAI,mBAAmB;AAAA,UAC5B,QAAQ;AAAA;AAAA;AAAA;AAAA;AAAA,EAMR,iBAAiB,UAAkB,KAA+B;AACxE,WAAO,KAAK,eAAe,KAAK,OAAO,KAAK,MAAM,UAAU;AAAA;AAAA,EAGtD,eACN,UACA,YACM;AACN,WAAO,IAAIC,yBAAK;AAAA,MACd,WAAW;AAAA,MACX,KAAK;AAAA,MACL,OAAO,IAAIC,8BAAU,KAAK;AAAA;AAAA;AAAA,EAItB,kBACN,UACA,YACM;AACN,WAAO,IAAID,yBAAK;AAAA,MACd,WAAW;AAAA,MACX,KAAK;AAAA,MACL,OAAO,IAAIE,iCAAa,KAAK;AAAA;AAAA;AAAA,EAIzB,gBACN,UACA,YACM;AACN,WAAO,IAAIF,yBAAK;AAAA,MACd,WAAW;AAAA,MACX,KAAK;AAAA,MACL,OAAO,KAAK;AAAA;AAAA;AAAA,EAIR,cAAc,UAAwB;AAC5C,WAAO,IAAIA,yBAAK;AAAA,MACd,WAAW;AAAA,MACX,OAAO,IAAI;AAAA;AAAA;AAAA;;oBCpJU,KAAsB;AAC/C,MAAI;AAEF,QAAI,IAAI;AACR,WAAO;AAAA,UACP;AACA,WAAO;AAAA;AAAA;;ACcX,MAAM,sBAAsB,CAC1B,QACA,SACA,WACG;AACH,QAAM,mBAAmB,OAAO,QAAQ,SAAS;AAAA,IAC/C,YAAY,CAAC;AAAA,IACb,oBAAoB;AAAA;AAEtB,QAAM,eAAeG,oBAAa,YAAY;AAC9C,QAAM,6BAAa;AACnB,QAAM,OAAO,aAAa;AAE1B,OAAK,MACH,KAAK,UAAU,OACf,CAAC,GAAG,MAAM,OAAO,MAAM,YAAY,OAAO,IAAI;AAGhD,SAAO,KACL,GAAG,OAAO;AAGZ,6BAA2B,MAAM,KAAK;AAAA;4BAGa;AAAA,EAKnD,YACmB,QACA,QACT,WACR;AAHiB;AACA;AACT;AAPF,kBAAiB,IAAIA,oBAAa;AAEzB,uBAA8B;AAO7C,QAAI,UAAU,CAAC,WAAW;AACxB,YAAM,IAAI,MAAM;AAAA;AAAA;AAAA,EAIpB,UAAU,QAAgB;AACxB,QAAI,KAAK,QAAQ;AACf,YAAM,IAAI,MAAM;AAAA;AAElB,SAAK,SAAS;AACd,eAAW,cAAc,KAAK,aAAa;AACzC,UAAI;AACF;AAAA,eACO,OAAP;AACA,aAAK,OAAO,MAAM,kCAAkC;AAAA;AAAA;AAAA;AAAA,EAK1D,UAAU,UAAmD;AAC3D,QAAI,KAAK,QAAQ;AACf,aAAO,KAAK,OAAO,UAAU;AAAA;AAG/B,SAAK,YAAY,KAAK;AACtB,WAAO;AAAA,MACL,aAAa,MAAM;AACjB,cAAM,QAAQ,KAAK,YAAY,QAAQ;AACvC,YAAI,SAAS,GAAG;AACd,eAAK,YAAY,OAAO,OAAO;AAAA;AAAA;AAAA;AAAA;AAAA,EAQ/B,OAAO,UAAuC;AA5GxD;AA6GI,QAAI,KAAK,UAAU,KAAK,WAAW;AACjC,UAAI,UAAU;AACZ,eAAO,KAAK,OAAO,OAAO,MAAM,UAAU,KAAK;AAAA;AAEjD,aAAO,WAAK,OAAO,OAAO,WAAnB,mBAA2B,kBAAkB,KAAK;AAAA;AAG3D,WAAO,KAAK;AAAA;AAAA,EAGd,IAAI,KAAsB;AAvH5B;AAwHI,WAAO,iBAAK,OAAO,WAAZ,mBAAoB,IAAI,SAAxB,YAAgC;AAAA;AAAA,EAEzC,OAAiB;AA1HnB;AA2HI,WAAO,iBAAK,OAAO,WAAZ,mBAAoB,WAApB,YAA8B;AAAA;AAAA,EAEvC,IAAmB,KAAiB;AAClC,WAAO,KAAK,OAAO,MAAM,IAAI;AAAA;AAAA,EAE/B,YAA2B,KAA6B;AAhI1D;AAiII,WAAO,WAAK,OAAO,WAAZ,mBAAoB,YAAY;AAAA;AAAA,EAEzC,UAAU,KAAqB;AAC7B,WAAO,IAAI,sBAAsB,KAAK,QAAQ,MAAM;AAAA;AAAA,EAEtD,kBAAkB,KAAiC;AAtIrD;AAuII,QAAI,WAAK,OAAO,WAAZ,mBAAoB,IAAI,MAAM;AAChC,aAAO,IAAI,sBAAsB,KAAK,QAAQ,MAAM;AAAA;AAEtD,WAAO;AAAA;AAAA,EAET,eAAe,KAAuB;AACpC,WAAO,KAAK,OAAO,MAAM,eAAe;AAAA;AAAA,EAE1C,uBAAuB,KAAmC;AA/I5D;AAgJI,WAAO,WAAK,OAAO,WAAZ,mBAAoB,uBAAuB;AAAA;AAAA,EAEpD,UAAU,KAAqB;AAC7B,WAAO,KAAK,OAAO,MAAM,UAAU;AAAA;AAAA,EAErC,kBAAkB,KAAiC;AArJrD;AAsJI,WAAO,WAAK,OAAO,WAAZ,mBAAoB,kBAAkB;AAAA;AAAA,EAE/C,WAAW,KAAsB;AAC/B,WAAO,KAAK,OAAO,MAAM,WAAW;AAAA;AAAA,EAEtC,mBAAmB,KAAkC;AA3JvD;AA4JI,WAAO,WAAK,OAAO,WAAZ,mBAAoB,mBAAmB;AAAA;AAAA,EAEhD,UAAU,KAAqB;AAC7B,WAAO,KAAK,OAAO,MAAM,UAAU;AAAA;AAAA,EAErC,kBAAkB,KAAiC;AAjKrD;AAkKI,WAAO,WAAK,OAAO,WAAZ,mBAAoB,kBAAkB;AAAA;AAAA,EAE/C,eAAe,KAAuB;AACpC,WAAO,KAAK,OAAO,MAAM,eAAe;AAAA;AAAA,EAE1C,uBAAuB,KAAmC;AAvK5D;AAwKI,WAAO,WAAK,OAAO,WAAZ,mBAAoB,uBAAuB;AAAA;AAAA;AAKtD,IAAI;iCASoC,SAKpB;AA3LpB;AA4LE,QAAM,OAAOC,8BAAU,QAAQ;AAE/B,QAAM,gBAAgC,CAAC,WAAK,WAAL,YAAe,IACnD,OACA,IAAI,SAAQ,WAAW,OAAO,EAAE,KAAK,QAAQ,EAAE,MAAMC,qBAAY;AAGpE,QAAM,QAAQC,oBAAU;AAKxB,QAAM,EAAE,aAAa,MAAMC,wBAAY,MAAM;AAC7C,QAAM,SAAS,MAAMC,8BAAiB;AAAA,IACpC,cAAc,SAAS,IAAI,OAAK,EAAE,YAAY;AAAA;AAGhD,QAAMC,WAAS,IAAI,sBAAsB,QAAQ;AACjD,QAAM,EAAE,eAAe,MAAMC,wBAAW;AAAA,IACtC,YAAY,MAAM;AAAA,IAClB;AAAA,IACA,QAAQ,QAAQ;AAAA,IAChB,OAAO;AAAA,MACL,SAAS,YAAY;AACnB,gBAAQ,OAAO,KACb,wBAAwB,WAAW,IAAI,OAAK,EAAE,SAAS,KAAK;AAG9D,iBAAO,UAAUP,oBAAa,YAAY;AAAA;AAAA,MAE5C,YAAY,IAAI,QAAQ,aAAW;AACjC,YAAI,mBAAmB;AACrB;AAAA;AAEF,4BAAoB;AAGpB,YAAI,OAAO,KAAK;AACd,iBAAO,IAAI,kBAAkB;AAAA;AAAA;AAAA;AAAA;AAMrC,UAAQ,OAAO,KACb,sBAAsB,WAAW,IAAI,OAAK,EAAE,SAAS,KAAK;AAG5D,WAAO,UAAUA,oBAAa,YAAY;AAG1C,sBAAoB,QAAQ,YAAY,QAAQ;AAChD,WAAO,UAAU,MACf,oBAAoB,QAAQ,YAAY,QAAQ;AAGlD,SAAOM;AAAA;;mBC9NoC;AAAA,EAqGnC,YACW,QACR,aACA,UACT;AAHiB;AACR;AACA;AAAA;AAAA,SA/FJ,iBAAiB,KAAc,SAA0B;AAC9D,UAAM,kBAAkB,IAAI,KAAK,KAAK,QAAQ;AAC9C,UAAM,iBACJ,IAAI,YAAY,IAAI,WAAW,kBAC3B,IAAI,WACJ;AAEN,QAAI,IAAI,YAAY,SAAS;AAC3B,UAAI,IAAI,YAAY,oBAAoB,gBAAgB;AACtD,eAAO;AAAA;AAET,aAAO,IAAI,aAAa,KAAK,IAAI,aAAa;AAAA;AAGhD,UAAM,aAAa,IAAIE;AACvB,UAAM,gBAAgB,WAAW,OAAO;AACxC,QAAI,YAAY,iBAAiB,SAAS;AAE1C,qBAAiB;AACf,UAAI,YAAY,oBAAoB,SAAS;AAC7C,mBAAa;AACb,iBAAW;AAAA;AAGb,WAAO,IAAI,aAAa,KAAK,WAAW,QAAQ;AAAA;AAAA,SAgB3C,cAAc,KAAc,YAAsC;AAEvE,QAAI,IAAI,YAAY,SAAS;AAC3B,aAAO;AAAA,eACE,WAAW,OAAO,SAAS;AACpC,aAAO,IAAI,aAAa,KAAK,WAAW,QAAQ,IAAI;AAAA;AAGtD,qBAAiB;AACf,UAAI,YAAY,oBAAoB,SAAS;AAC7C,iBAAW;AAAA;AAGb,QAAI,YAAY,iBAAiB,SAAS;AAE1C,WAAO,IAAI,aAAa,KAAK,WAAW,QAAQ,IAAI;AAAA;AAAA,SAe/C,UAAU,KAAc,QAA8B;AAE3D,QAAI,IAAI,YAAY,SAAS;AAC3B,aAAO;AAAA,eACE,OAAO,SAAS;AACzB,aAAO,IAAI,aAAa,KAAK,QAAQ,IAAI;AAAA;AAG3C,UAAM,aAAa,IAAIA;AAEvB,qBAAiB;AACf,UAAI,YAAY,oBAAoB,SAAS;AAC7C,aAAO,oBAAoB,SAAS;AACpC,iBAAW;AAAA;AAGb,QAAI,YAAY,iBAAiB,SAAS;AAC1C,WAAO,iBAAiB,SAAS;AAEjC,WAAO,IAAI,aAAa,KAAK,WAAW,QAAQ,IAAI;AAAA;AAAA,EAStD,MAAmB,KAA4B;AAC7C,WAAO,KAAK,OAAO,MAAM;AAAA;AAAA;;AC1G7B,MAAM,mBAAgC,OAAO,OAAO;AAAA,EAClD,SAAS;AAAA,EACT,mBAAmB;AAAA;AAAA,EACnB,sBAAsB;AAAA;AAAA,EACtB,gBAAgB;AACd,WAAO;AAAA;AAAA,EAET,SAAS;AAAA;kBAMiC;AAAA,EAArC,cArCP;AAsCW,uBAAc;AACd,oBAAW;AAAA;AAAA,EAEpB,MAAmB,MAA6B;AAC9C,WAAO;AAAA;AAAA;;mBCnBkC;AAAA,EAK3C,YACmB,SACA,MACA,QACjB;AAHiB;AACA;AACA;AAAA;AAAA,SAPZ,iBAAiB,KAAc,KAAa,OAAyB;AAC1E,WAAO,IAAI,aAAa,KAAK,KAAK;AAAA;AAAA,MAShC,cAA2B;AAC7B,WAAO,KAAK,QAAQ;AAAA;AAAA,MAGlB,WAA6B;AAC/B,WAAO,KAAK,QAAQ;AAAA;AAAA,EAGtB,MAAmB,KAA4B;AAC7C,WAAO,QAAQ,KAAK,OAAQ,KAAK,SAAe,KAAK,QAAQ,MAAM;AAAA;AAAA;;eCfjD;AAAA,SAUb,OAAgB;AACrB,WAAO,IAAI;AAAA;AAAA,SAmBN,UACL,WACA,QACS;AACT,WAAO,aAAa,SAChB,aAAa,UAAU,WAAW,UAClC,aAAa,cAAc,WAAW;AAAA;AAAA,SAarC,oBAAoB,WAAoB,SAA4B;AACzE,WAAO,aAAa,iBAAiB,WAAW,QAAQ,GAAG;AAAA;AAAA,SAatD,kBAAkB,WAAoB,SAA0B;AACrE,WAAO,aAAa,iBAAiB,WAAW;AAAA;AAAA,SAa3C,UACL,WACA,KACA,OACS;AACT,UAAM,IAAI,OAAO,UAAU,aAAa,MAAM,UAAU,MAAM,QAAQ;AACtE,WAAO,aAAa,iBAAiB,WAAW,KAAK;AAAA;AAAA;;6BCtFrB,WAAgB,WAAkB;AACpE,SAAOd,aAAM,IAAI,QAAQ,GAAG;AAAA;;6BCA5B,MACsB;AACtB,SAAO;AAAA,IACL,YAAY;AAAA,MACV,UAAU;AAAA;AAAA;AAAA;;mCCEd,UACA,WACA;AACA,QAAM,aAAa,yBAAyB,UAAU;AACtD,QAAM,WAAWe,gCAAY;AAC7B,SAAO;AAAA;kCAUP,UACA,WACA;AACA,SAAO,oBACL,SAAS,OACT;AAAA,IACE,YAAY,yBAAyB,UAAU,CAAC,CAAC;AAAA,IACjD,kBAAkB;AAAA,KAEpB;AAAA;kCAWF,UACA,uBACqC;AACrC,QAAM,aAAa,SAAS,IAAI;AAChC,QAAM,qBACJ,OAAO,eAAe,YAAY,sBAAsB;AAC1D,QAAM,YAAY,OAAO,0BAA0B;AAEnD,QAAM,8BAA8B,YAChC,qBACA,yBAAyB;AAE7B,SAAO,8BACH,2BAA2B,cAC3B;AAAA;oCAUJ,kBAC4B;AAC5B,MAAI;AACF,UAAM;AAAA,MACJ;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,QACE,IAAI,IAAI;AAEZ,QAAI,aAAa,UAAU;AACzB,YAAM,IAAI,MAAM,oBAAoB;AAAA,eAC3B,CAAC,YAAY,CAAC,UAAU;AACjC,YAAM,IAAI,MAAM;AAAA,eACP,CAAC,SAAS,MAAM,cAAc;AACvC,YAAM,IAAI,MAAM;AAAA;AAGlB,UAAM,SAAqC;AAAA,MACzC,MAAM;AAAA,MACN;AAAA,MACA,MAAM;AAAA,MACN,MAAM,OAAO,QAAQ;AAAA,MACrB,UAAU,mBAAmB,SAAS,OAAO;AAAA;AAG/C,UAAM,MAAM,aAAa,IAAI;AAC7B,QAAI,KAAK;AACP,aAAO,MAAM;AAAA;AAGf,UAAM,QAAQ,aAAa,IAAI;AAC/B,QAAI,OAAO;AACT,aAAO,QAAQC,uBAAG;AAAA;AAGpB,WAAO;AAAA,WACA,GAAP;AACA,UAAM,IAAIC,kBACR,gDAAgD,KAChD;AAAA;AAAA;yCAYJ,aACG,WACH;AACA,QAAM,QAAQ,0BAA0B,UAAU;AAAA,IAChD,YAAY;AAAA,MACV,UAAU;AAAA;AAAA;AAId,MAAI;AACF,UAAM,iBAAiB,OAAO,aAAqB;AACjD,YAAM,MAAM,IAAI,oCAAoC,CAAC;AAAA;AAEvD,UAAM,QAAQ,IAAI,UAAU,IAAI;AAAA,YAChC;AACA,UAAM,MAAM;AAAA;AAAA;MASH,iBAAoC,OAAO,OAAO;AAAA,EAC7D,cAAc;AAAA,EACd,sBAAsB;AAAA,EACtB,oBAAoB;AAAA,EACpB,uBAAuB;AAAA;;+BCvJvB,MACsB;AACtB,SAAO;AAAA,IACL,YAAY,CAAC;AAAA;AAAA;;gCCMf,UACA,WACA;AACA,QAAM,aAAa,sBAAsB,UAAU;AACnD,QAAM,WAAWF,gCAAY;AAC7B,SAAO;AAAA;+BAUP,UACA,WACA;AACA,SAAO,oBACL,SAAS,OACT;AAAA,IACE,YAAY,sBAAsB,UAAU,CAAC,CAAC;AAAA,IAC9C,kBAAkB;AAAA,KAEpB;AAAA;+BAWF,UACA,uBACkC;AAClC,QAAM,aAAa,SAAS,IAAI;AAChC,QAAM,qBACJ,OAAO,eAAe,YAAY,sBAAsB;AAC1D,QAAM,YAAY,OAAO,0BAA0B;AAEnD,QAAM,8BAA8B,YAChC,qBACA,yBAAyB;AAE7B,SAAO,8BACH,wBAAwB,cACxB;AAAA;iCAQkC,kBAA0B;AAChE,QAAM,QAAQ;AACd,SAAO,MAAM;AAAA;AAGf,qCAAqC;AACnC,MAAI;AACF,WAAO,QAAQ,wBAAwB;AAAA,WAChC,GAAP;AACA,UAAM,IAAIG,sBAAe,4CAA4C;AAAA;AAAA;sCAWvE,aACG,WACH;AACA,QAAM,QAAQ,uBAAuB,UAAU;AAAA,IAC7C,YAAY;AAAA,MACV,UAAU;AAAA;AAAA;AAId,MAAI;AACF,UAAM,iBAAiB,OAAO,aAAqB;AACjD,YAAM,SAAS,MAAM,MAClB,KAAK,eACL,MAAM,WAAW,UACjB;AAEH,UAAI,SAAS,OAAO,GAAG,OAAO,MAAM,GAAG;AACrC;AAAA;AAGF,YAAM,MAAM,IAAI,sBAAsB,CAAC;AAAA;AAGzC,UAAM,QAAQ,IAAI,UAAU,IAAI;AAAA,YAChC;AACA,UAAM,MAAM;AAAA;AAAA;oCAWd,aACG,SACY;AACf,QAAM,QAAQ,uBAAuB;AAErC,MAAI;AACF,UAAM,eAAe,OAAO,aAAqB;AAC/C,YAAM,MAAM,IAAI,kCAAkC,CAAC;AAAA;AAGrD,UAAM,QAAQ,IAAI,QAAQ,IAAI;AAAA,YAC9B;AACA,UAAM,MAAM;AAAA;AAAA;MASH,cAAiC,OAAO,OAAO;AAAA,EAC1D,cAAc;AAAA,EACd,sBAAsB;AAAA,EACtB,oBAAoB;AAAA,EACpB,oBAAoB;AAAA,EACpB,sBAAsB;AAAA,EACtB,uBAAuB;AAAA;;oCC9IvB,UACA,WACA;AACA,QAAM,aAAa,0BAA0B,UAAU;AAGvD,MACG,WAAW,WAA4C,YACvD,WAAW,WAA4C,aACtD,YACF;AACA,UAAM,EAAE,aAAa,WAAW;AAChC,UAAM,YAAYC,iCAAK,QAAQ;AAE/B,qBAAc;AAAA;AAGhB,QAAM,WAAWJ,gCAAY;AAE7B,WAAS,OAAO,KAAK,GAAG,iBAAiB,CAAC,UAAe,aAAkB;AACzE,aAAS,IAAI,4BAA4B,MAAM;AAAA;AAAA;AAGjD,SAAO;AAAA;mCAUP,UACA,WACa;AACb,QAAM,aAAa,SAAS;AAG5B,MAAI,OAAO,WAAW,eAAe,UAAU;AAC7C,eAAW,aAAa,EAAE,UAAU,WAAW;AAAA;AAEjD,MAAI,aAAa,OAAO,UAAU,eAAe,UAAU;AACzD,cAAU,aAAa,EAAE,UAAU,UAAU;AAAA;AAG/C,QAAM,SAAsB,oBAC1B;AAAA,IACE,YAAY;AAAA,KAEd,YACA;AAAA,IACE,kBAAkB;AAAA,KAEpB;AAGF,SAAO;AAAA;kCAMgC,MAAoC;AAC3E,SAAO;AAAA,IACL,YAAY,4BAA4B;AAAA;AAAA;qCAQ1C,MAC8B;AAC9B,SAAO;AAAA,IACL,UAAU;AAAA;AAAA;MASD,mBAAsC,OAAO,OAAO;AAAA,EAC/D,cAAc;AAAA,EACd,oBAAoB;AAAA,EACpB,uBAAuB;AAAA;;AC/EzB,MAAM,mBAA8D;AAAA,EAClE,IAAI;AAAA,EACJ,kBAAkB;AAAA,EAClB,SAAS;AAAA,EACT,OAAO;AAAA,EACP,QAAQ;AAAA;8BAWR,UACA,WACA;AAzDF;AA0DE,QAAM,SAAyB,SAAS,UAAU;AAElD,SACE,6BAAiB,YAAjB,mBAA0B,aAAa,UAAU,eAAjD,YACAA,gCAAY,oBAAoB,SAAS,OAAO;AAAA;oCAUlD,aACG,WACY;AA1EjB;AA2EE,QAAM,SAAyB,SAAS,UAAU;AAElD,SAAO,6BAAiB,YAAjB,mBAA0B,yBAA1B,4BACL,UACA,GAAG;AAAA;kCAUL,aACG,SACY;AA3FjB;AA4FE,QAAM,SAAyB,SAAS,UAAU;AAElD,SAAO,oCAAuB,YAAjB,mBAA0B,uBAA1B,4BACX,UACA,GAAG;AAAA;4BASL,QACA,MACsB;AACtB,MAAI;AACF,WAAO,iBAAiB,QAAQ,mBAAmB;AAAA,WAC5C,GAAP;AACA,UAAM,IAAIE,kBACR,gDAAgD,qBAChD;AAAA;AAAA;8BAUJ,QACA,MACkC;AA7HpC;AA8HE,MAAI;AACF,WAAO,6BAAiB,YAAjB,mBAA0B,yBAA1B,4BAAiD;AAAA,WACjD,GAAP;AACA,UAAM,IAAIA,kBACR,kDAAkD,qBAClD;AAAA;AAAA;+BASJ,kBACA,QAC6B;AAC7B,MAAI,OAAO,WAAW,eAAe,WAAW,MAAM;AACpD,UAAM,IAAIA,kBACR;AAAA;AAIJ,MAAI;AACF,WAAO,iBAAiB,QAAQ,sBAAsB;AAAA,WAC/C,GAAP;AACA,UAAM,IAAIA,kBACR,0CAA0C;AAAA;AAAA;6BAU9C,YACA,QACsC;AACtC,MAAI,OAAO,eAAe,eAAe,eAAe,MAAM;AAC5D,WAAO;AAAA;AAGT,SAAO,OAAO,eAAe,YAAY,sBAAsB,SAC3D,sBAAsB,YAAsB,UAC5C;AAAA;;ACzIN,oBAAoB,UAA0B;AAC5C,SAAO,UAAU;AAAA;sBAuBU;AAAA,EAoBnB,YACW,QACA,SAAiB,qBACjB,SACjB;AAHiB;AACA;AACA;AAAA;AAAA,SAhBZ,WACL,QACA,SACiB;AACjB,UAAM,iBAAiB,OAAO,UAAU;AAExC,WAAO,IAAI,gBACT,gBACA,eAAe,kBAAkB,WACjC;AAAA;AAAA,EAiBJ,UAAU,UAAyC;AA5FrD;AA6FI,UAAM,QAAQ;AAEd,WAAO;AAAA,MACL,YAA2B;AACzB,eAAO,MAAM,YAAY;AAAA;AAAA,MAE3B,YAAY;AAAA,QACV,MAAM;AAAA,WACH,YAAM,YAAN,mBAAe;AAAA;AAAA;AAAA;AAAA,EAiBhB,gBAAgB,UAAsC;AAtHhE;AAuHI,UAAM,aAAa,KAAK,oBAAoB;AAE5C,QAAI,KAAK,cAAc,UAAU,OAAO,SAAS,YAAY;AAC3D,YAAM,iBACJ,WACA;AAEF,UAAI,mBAAmB,YAAY;AACjC,eAAO;AAAA;AAGT,YAAM,kBACH,iBAAsC,cAAtC,YAAmD;AAEtD,aAAOE,iCAAK,KAAK,iBAAiB,0CAAkB,GAAG;AAAA;AAGzD,UAAM,eAAgB,yCAAsC;AAG5D,QAAI,KAAK,kCAAkC,UAAU;AACnD,aAAO;AAAA;AAIT,WAAO,sCAAgB,GAAG,KAAK,SAAS;AAAA;AAAA,EAclC,cAAc,UAGpB;AACA,UAAM,eAAe,KAAK,OAAO,kBAC/B,GAAG,WAAW;AAGhB,UAAM,aAAa,KAAK,OAAO,UAAU;AACzC,UAAM,SAAS,sCAAgB;AAC/B,WAAO;AAAA,MACL;AAAA,MACA,YAAY,WAAW;AAAA;AAAA;AAAA,EAUnB,wBAAwB,UAA0C;AApL5E;AAqLI,UAAM,eAAe,WAAK,OACvB,kBAAkB,GAAG,WAAW,4BADd,mBAEjB;AAEJ,UAAM,aAAa,WAAK,OACrB,kBAAkB,kBADF,mBAEf;AAEJ,WAAOnB,aAAM,YAAY;AAAA;AAAA,EAGnB,sBAAsB,UAA2B;AAhM3D;AAiMI,UAAM,aAAa,WAAK,OAAO,mBAAmB,oBAA/B,YAAkD;AACrE,WACE,WAAK,OAAO,mBAAmB,GAAG,WAAW,8BAA7C,YACA;AAAA;AAAA,EAII,8BAAsC;AAxMhD;AAyMI,WAAO,WAAK,OAAO,kBAAkB,0BAA9B,YAAuD;AAAA;AAAA,EAcxD,oBACN,UACsC;AACtC,UAAM,EAAE,QAAQ,eAAe,KAAK,cAAc;AAElD,QAAI,iBAAiB,oBACnB,KAAK,OAAO,IAAI,eAChB,KAAK,OAAO,UAAU;AAGxB,QACE,OAAO,SAAS,cAChB,cAAc,kBACd,eAAe,aAAa,YAC5B;AACA,YAAM,IAAI,MACR;AAAA;AAQJ,QAAI,KAAK,kCAAkC,UAAU;AACnD,uBAAiBoB,YAAK,gBAAgB;AAAA;AAIxC,UAAM,aAAa,oBACjB,KAAK,OAAO,YAAY,GAAG,WAAW,yBACtC;AAGF,WAAO;AAAA,SAED,aAAa,KAAK;AAAA,SACnB;AAAA;AAAA;AAAA,EAYC,mBAAmB,UAA+B;AACxD,UAAM,EAAE,WAAW,KAAK,cAAc;AAEtC,WAAO;AAAA,SACF,KAAK,wBAAwB;AAAA,MAChC;AAAA,MACA,YAAY,KAAK,oBAAoB;AAAA;AAAA;AAAA,EAWjC,mBAAmB,UAA2C;AACpE,WAAO,qBAAqB,KAAK,cAAc,UAAU,QAAQ;AAAA;AAAA,EAS3D,qBAAqB,UAA+B;AAC1D,UAAM,eAAe,KAAK,gBAAgB;AAC1C,WAAO,eACH,mBAAmB,KAAK,cAAc,UAAU,QAAQ,gBACxD;AAAA;AAAA,QAUQ,YAAY,UAAiC;AACzD,UAAM,eAAe,IAAId,oBACvB,KAAK,mBAAmB;AAG1B,UAAM,eAAe,KAAK,gBAAgB;AAC1C,QAAI,gBAAgB,KAAK,sBAAsB,WAAW;AACxD,UAAI;AACF,cAAM,qBAAqB,cAAc;AAAA,eAClC,OAAP;AACA,cAAM,IAAI,MACR,wDAAwD,yBAAyB;AAAA;AAAA;AAKvF,QAAI;AACJ,QAAI,KAAK,kCAAkC,UAAU;AACnD,UAAI;AACF,0BAAkB,KAAK,mBAAmB;AAC1C,cAAM,mBAAmB,cAAc;AAAA,eAChC,OAAP;AACA,cAAM,IAAI,MACR,0EAA0E,qBAAqB;AAAA;AAAA;AAKrG,UAAM,0BAA0B,oBAC9B,IACA,KAAK,qBAAqB,WAC1B;AAGF,WAAO,qBAAqB,cAAc;AAAA;AAAA;;iCC3TN,GAAY;AAClD,QAAM,UAAW,uBAAW;AAE5B,SACE,OAAO,YAAY,qDACsB,KAAK,YAC5C,oBAAoB,KAAK;AAAA;;yBCsCC,QAA6B;AAC3D,MAAI,OAAO,OAAO,IAAI,cAAc,UAAU;AAE5C,UAAM,EAAE,MAAM,gBAAS,mBAAmB,OAAO,UAAU;AAE3D,WAAO,cAAc;AAAA,MACnB,YAAY;AAAA,MACZ,YAAY;AAAA;AAAA;AAIhB,QAAM,OAAO,OAAO,YAAY;AAChC,MACE,OAAO,SAAS,eAChB,OAAO,SAAS,YAChB,OAAO,SAAS,UAChB;AACA,UAAM,IAAI,MACR,6DAA6D,OAAO;AAAA;AAIxE,SAAO,cAAc;AAAA,IACnB,YAAY;AAAA,IACZ,YAAY,OAAO,kBAAkB;AAAA,IACrC,SAAS,OAAO,kBAAkB;AAAA;AAAA;yBAoBN,QAAyC;AACvE,QAAM,KAAK,OAAO,kBAAkB;AACpC,MAAI,CAAC,IAAI;AACP,WAAO;AAAA;AAGT,SAAO,cAAc;AAAA,IACnB,QAAQ,wBAAwB,2BAA2B,IAAI;AAAA,IAC/D,SAAS,2BAA2B,IAAI;AAAA,IACxC,gBAAgB,2BAA2B,IAAI;AAAA,IAC/C,gBAAgB,2BAA2B,IAAI;AAAA,IAC/C,aAAa,GAAG,mBAAmB;AAAA,IACnC,QAAQ,GAAG,kBAAkB;AAAA,IAC7B,mBAAmB,GAAG,mBAAmB;AAAA,IACzC,sBAAsB,GAAG,kBAAkB;AAAA;AAAA;wBAqB7C,QAC8C;AAC9C,QAAM,KAAK,OAAO,kBAAkB;AACpC,MAAI,CAAC,IAAI;AACP,WAAO;AAAA;AAGT,QAAM,SAA2C;AACjD,aAAW,OAAO,GAAG,QAAQ;AAC3B,QAAI,GAAG,IAAI,SAAS,OAAO;AACzB,aAAO,OAAO;AAAA,WACT;AACL,aAAO,OAAO,GAAG,eAAe;AAAA;AAAA;AAIpC,SAAO;AAAA;2BAkByB,QAA2C;AAC3E,QAAM,QAAQ,OAAO,YAAY;AACjC,MAAI,UAAU,MAAM;AAClB,UAAM,UAAU,OAAO,UAAU;AACjC,QAAI;AACJ,QAAI;AACF,iBAAW,IAAI,IAAI,SAAS;AAAA,aACrB,OAAP;AACA,YAAM,IAAI,MAAM,4BAA4B;AAAA;AAG9C,WAAO,EAAE,aAAa,EAAE;AAAA;AAG1B,QAAM,KAAK,OAAO,kBAAkB;AACpC,MAAI,CAAC,IAAI;AACP,WAAO;AAAA;AAGT,QAAM,oBAAoB,GAAG,IAAI;AAEjC,QAAM,MAAM;AAAA,IACV,aAAa;AAAA;AAGf,SAAO,cAAc;AAAA;AAGvB,oCACE,QACA,KAC+B;AAC/B,QAAM,QAAQ,OAAO,YAAY;AACjC,MAAI,UAAU,UAAa,kBAAkB,QAAQ;AACnD,WAAO;AAAA;AAET,QAAM,IAAI,MAAM,4CAA4C,OAAO;AAAA;AAGrE,iCACE,aAC0B;AA/N5B;AAgOE,MAAI,gBAAgB,QAAW;AAC7B,WAAO;AAAA;AAGT,MAAI,CAAC,kBAAkB,cAAc;AACnC,UAAM,IAAI,MACR,4CAA4C,OAAO;AAAA;AAIvD,QAAM,gBACJ,OAAO,gBAAgB,WAAW,CAAC,eAAe;AAEpD,QAAM,wBACJ,qDAAe,IACb,aAAW,IAAIe,oBAAU,SAAS,EAAE,QAAQ,MAAM,YAAY,aADhE,YAEK;AAEP,SAAO,CAAC,QAAQ,aAAa;AAC3B,WAAO,SACL,MACA,sBAAsB,KAAK,aAAW,QAAQ,MAAM,0BAAU;AAAA;AAAA;AAKpE,2BAA2B,OAAwC;AACjE,SAAO,OAAO,UAAU,YAAY,cAAc;AAAA;AAGpD,uBAAuB,OAA+B;AACpD,MAAI,CAAC,MAAM,QAAQ,QAAQ;AACzB,WAAO;AAAA;AAET,aAAW,KAAK,OAAO;AACrB,QAAI,OAAO,MAAM,UAAU;AACzB,aAAO;AAAA;AAAA;AAGX,SAAO;AAAA;AAGT,uBAAyC,KAAW;AAClD,SAAO,OAAO,YACZ,OAAO,QAAQ,KAAK,OAAO,CAAC,GAAG,OAAO,MAAM;AAAA;AAIhD,4BAA4B,OAAiD;AAC3E,QAAM,QAAQ,MAAM,MAAM;AAC1B,MAAI,MAAM,WAAW,GAAG;AACtB,WAAO,EAAE,MAAM,SAAS,MAAM,IAAI;AAAA;AAEpC,MAAI,MAAM,WAAW,GAAG;AACtB,WAAO,EAAE,MAAM,MAAM,IAAI,MAAM,SAAS,MAAM,IAAI;AAAA;AAEpD,QAAM,IAAI,MACR,kCAAkC;AAAA;;ACxQtC,0BAA0B,SAAmC;AAC3D,QAAM,YAAY,IAAI;AACtB,QAAM,gCAAgB;AAEtB,eAAa,IAAqB,GAAe;AAC/C,QAAI,UAAU,IAAI,KAAK;AACrB;AAAA;AAEF,cAAU,IAAI;AACd,cAAU,KAAK;AAEf,eAAW,YAAa,EAAU,SAAS;AACzC,YAAM,SAAS,QAAQ,MAAM;AAC7B,UAAI,QAAQ;AACV,YAAI,UAAU;AAAA;AAAA;AAAA;AAKpB,MAAI,QAAQ,IAAI;AAEhB,SAAO;AAAA;uBAmBqB,SAAqB,cAA0B;AAzD7E;AA0DE,MAAI,QAAQ,KAAK;AACf,UAAM,YAAY,iBAAiB;AACnC,QAAI,YAAY;AAEhB,UAAM,UAAU,MAAM;AACpB,UAAI,CAAC,WAAW;AACd,oBAAY;AACZ;AAAA;AAAA;AAIJ,eAAW,KAAK,WAAW;AACzB,cAAE,QAAF,mBAAO,kBAAkB;AAAA;AAAA;AAAA;AAK/B,MAAM,gCAAgC;uBAmBpC,SACA,cACG;AAhGL;AAiGE,MAAI,CAAC,QAAQ,KAAK;AAChB,WAAO;AAAA;AAIT,MAAI,gBAAS,IAAI,SAAZ,mBAAmB,iCAAgC;AACtD,eAAW,YAAY,iBAAiB,UAAU;AAChD,qBAAS,QAAT,mBAAc,kBAAkB,UAAQ;AACtC,aAAK,iCAAiC;AAAA;AAAA;AAI1C,YAAQ,IAAI,OAAO;AAAA,SACd,QAAQ,IAAI;AAAA,OACd,gCAAgC;AAAA;AAAA;AAKrC,QAAM,QAAQ,QAAQ,IAAI,KAAK;AAC/B,QAAM,QAAQ,cAAQ,IAAI,KAAK,WAAjB,YAA2B;AAGzC,UAAQ,IAAI,kBAAkB,UAAQ;AACpC,SAAK,SAAS;AAAA;AAGhB,SAAO;AAAA;;sBCnDP,UAA+B,IACV;AA1EvB;AA2EE,QAAM,kBACJ,cAAQ,oBAAR,YAA2B,QAAQ,IAAI,aAAa;AAEtD,QAAM,SAAU,SAAQ,UAAU,iBAAiB,MAAM;AAAA,IACvD,MAAM;AAAA;AAGR,SAAO,CAAC,OAAc,KAAc,KAAe,SAAuB;AACxE,UAAM,aAAa,cAAc;AACjC,QAAI,QAAQ,mBAAmB,cAAc,KAAK;AAChD,aAAO,MAAM;AAAA;AAGf,QAAI,IAAI,aAAa;AAGnB,WAAK;AACL;AAAA;AAGF,UAAM,OAA0B;AAAA,MAC9B,OAAOC,sBAAe,OAAO,EAAE,cAAc;AAAA,MAC7C,SAAS,EAAE,QAAQ,IAAI,QAAQ,KAAK,IAAI;AAAA,MACxC,UAAU,EAAE;AAAA;AAGd,QAAI,OAAO,YAAY,KAAK;AAAA;AAAA;AAIhC,uBAAuB,OAAsB;AAE3C,QAAM,wBAAwB,CAAC,cAAc;AAC7C,aAAW,SAAS,uBAAuB;AACzC,UAAM,aAAc,MAAc;AAClC,QACE,OAAO,eAAe,YACrB,cAAa,OAAO,cACrB,cAAc,OACd,cAAc,KACd;AACA,aAAO;AAAA;AAAA;AAKX,UAAQ,MAAM;AAAA,SACPC,wBAAiB;AACpB,aAAO;AAAA,SACJN,kBAAW;AACd,aAAO;AAAA,SACJO,2BAAoB;AACvB,aAAO;AAAA,SACJC,uBAAgB;AACnB,aAAO;AAAA,SACJC,qBAAc;AACjB,aAAO;AAAA,SACJC,qBAAc;AACjB,aAAO;AAEP;AAIJ,SAAO;AAAA;;2BChHyC;AAEhD,SAAO,CAAC,UAAmB,UAAoB,UAAwB;AACrE,aAAS,OAAO,KAAK;AAAA;AAAA;;+BCFa,QAAiC;AACrE,QAAM,eAAgB,WAAU,iBAAiB,MAAM;AAAA,IACrD,MAAM;AAAA;AAGR,SAAOC,2BAAO,YAAY;AAAA,IACxB,QAAQ;AAAA,MACN,MAAM,SAAiB;AACrB,qBAAa,KAAK,QAAQ;AAAA;AAAA;AAAA;AAAA;;kCCYhC,UAAqC,IACZ;AACzB,QAAM,cAA2B,QAAQ,cACrC,QAAQ,cACR,MAAM,QAAQ,QAAQ,EAAE,QAAQ;AAEpC,SAAO,OAAO,UAAmB,UAAoB,SAAuB;AAC1E,QAAI;AACF,YAAM,SAAS,MAAM;AACrB,eAAS,OAAO,KAAK,OAAO,IAAI,KAAK;AAAA,aAC9B,KAAP;AACA,WAAK;AAAA;AAAA;AAAA;;ACnCX,MAAM,qBAAqB,KAAK,KAAK,KAAK,KAAK;AAE/C,MAAM,oBAAoB;0BAWxB,KACA,QACa;AACb,mCAAQ,KAAK;AAEb,SAAOC,gBAAK,aAAa;AAAA;iCAazB,KACA,eACA,QACsB;AA1DxB;AA2DE,mCAAQ,KAAK;AAEb,MAAI;AAEJ,MAAI,8DAA6B,cAAa;AAC5C,kBAAc,MAAM,wBAClB,cAAc,YAAY,UAC1B;AAAA,SAEG;AACL,qCAAQ,KAAK;AAEb,kBAAc;AAAA,MACZ,KAAK,qDAAe,gBAAf,mBAA4B;AAAA,MACjC,MAAM,qDAAe,gBAAf,mBAA4B;AAAA;AAAA;AAItC,MAAI,CAAC,YAAY,OAAO,CAAC,YAAY,MAAM;AACzC,UAAM,IAAI,MAAM;AAAA;AAGlB,SAAOC,iBAAM,aAAa,aAAa;AAAA;AAGzC,uCAAuC,UAAkB,QAAiB;AACxE,QAAM,aAAa,MAAMC,uBAAG,WAAW;AACvC,MAAI;AACJ,MAAI,YAAY;AACd,eAAWvB,qBACT;AAEF,UAAMuB,uBAAG,UAAUC,qBAAQ;AAAA,SACtB;AACL,eAAWxB,qBAAY;AAAA;AAGzB,MAAI,OAAO;AACX,MAAI,MAAMuB,uBAAG,WAAW,WAAW;AACjC,UAAM,OAAO,MAAMA,uBAAG,KAAK;AAC3B,UAAM,QAAQ,KAAK,QAAQ,KAAK;AAChC,QAAI,KAAK,YAAY,QAAQ,oBAAoB;AAC/C,aAAO,MAAMA,uBAAG,SAAS;AAAA;AAAA;AAI7B,MAAI,MAAM;AACR,qCAAQ,KAAK;AACb,WAAO;AAAA,MACL,KAAK;AAAA,MACL;AAAA;AAAA;AAIJ,mCAAQ,KAAK;AACb,QAAM,UAAU,MAAM,kBAAkB;AACxC,QAAMA,uBAAG,UAAU,UAAU,QAAQ,OAAO,QAAQ,KAAK;AACzD,SAAO;AAAA;AAGT,iCAAiC,UAAkB;AACjD,QAAM,aAAa;AAAA,IACjB;AAAA,MACE,MAAM;AAAA,MACN,OAAO;AAAA;AAAA;AAIX,QAAM,OAAO;AAAA,IACX;AAAA,MACE,MAAM;AAAA,MACN,OAAO;AAAA;AAAA,IAET;AAAA,MACE,MAAM;AAAA,MACN,OAAO;AAAA;AAAA,IAET;AAAA,MACE,MAAM;AAAA,MACN,OAAO;AAAA;AAAA,IAET;AAAA,MACE,MAAM;AAAA,MACN,IAAI;AAAA;AAAA,IAEN;AAAA,MACE,MAAM;AAAA,MACN,IAAI;AAAA;AAAA;AAKR,MAAI,CAAC,KAAK,KAAK,CAAC,EAAE,OAAO,SAAS,UAAU,YAAY,OAAO,WAAW;AACxE,SAAK,KACH,kBAAkB,KAAK,YACnB;AAAA,MACE,MAAM;AAAA,MACN,IAAI;AAAA,QAEN;AAAA,MACE,MAAM;AAAA,MACN,OAAO;AAAA;AAAA;AAKjB,QAAM,SAAS;AAAA,IACb,WAAW;AAAA,IACX,SAAS;AAAA,IACT,MAAM;AAAA,IACN,YAAY;AAAA,MACV;AAAA,QACE,MAAM;AAAA,QACN,aAAa;AAAA,QACb,kBAAkB;AAAA,QAClB,gBAAgB;AAAA,QAChB,iBAAiB;AAAA,QACjB,kBAAkB;AAAA;AAAA,MAEpB;AAAA,QACE,MAAM;AAAA,QACN,YAAY;AAAA,QACZ,YAAY;AAAA,QACZ,aAAa;AAAA,QACb,cAAc;AAAA;AAAA,MAEhB;AAAA,QACE,MAAM;AAAA,QACN,UAAU;AAAA;AAAA;AAAA;AAKhB,SAAO,IAAI,QAAuC,CAAC,SAAS,WAC1D,QAAQ,cAAc,SACpB,YACA,QACA,CAAC,KAAY,WAA8C;AACzD,QAAI,KAAK;AACP,aAAO;AAAA,WACF;AACL,cAAQ,EAAE,KAAK,OAAO,SAAS,MAAM,OAAO;AAAA;AAAA;AAAA;;MC7JzC,eAAe;AAE5B,MAAM,eAAe;yBAEqC;AAAA,EAexD,YAAY,WAAuB;AACjC,SAAK,UAAU;AACf,SAAK,SAAS;AACd,SAAK,yBAAyB;AAAA;AAAA,EAGhC,WAAW,QAAgC;AACzC,UAAM,gBAAgB,OAAO,kBAAkB;AAC/C,QAAI,CAAC,eAAe;AAClB,aAAO;AAAA;AAGT,UAAM,cAAc,gBAAgB;AACpC,QAAI,YAAY,YAAY;AAC1B,WAAK,OACH,OAAO,YAAY,eAAe,WAC9B,SAAS,YAAY,YAAY,MACjC,YAAY;AAAA;AAEpB,QAAI,YAAY,YAAY;AAC1B,WAAK,OAAO,YAAY;AAAA;AAG1B,UAAM,cAAc,gBAAgB;AACpC,QAAI,aAAa;AACf,WAAK,cAAc;AAAA;AAGrB,UAAM,aAAa,eAAe;AAClC,QAAI,YAAY;AACd,WAAK,aAAa;AAAA;AAGpB,UAAM,gBAAgB,kBAAkB;AACxC,QAAI,eAAe;AACjB,WAAK,gBAAgB;AAAA;AAGvB,WAAO;AAAA;AAAA,EAGT,QAAQ,MAA8B;AACpC,SAAK,OAAO;AACZ,WAAO;AAAA;AAAA,EAGT,QAAQ,MAA8B;AACpC,SAAK,OAAO;AACZ,WAAO;AAAA;AAAA,EAGT,UAAU,QAAgC;AACxC,SAAK,SAAS;AACd,WAAO;AAAA;AAAA,EAGT,iBAAiB,UAAyC;AACxD,SAAK,gBAAgB;AACrB,WAAO;AAAA;AAAA,EAGT,WAAW,SAA2C;AACpD,SAAK,cAAc;AACnB,WAAO;AAAA;AAAA,EAGT,OAAO,SAAqC;AAC1C,SAAK,aAAa;AAClB,WAAO;AAAA;AAAA,EAGT,UAAU,MAAc,QAAgC;AACtD,SAAK,QAAQ,KAAK,CAAC,MAAM;AACzB,WAAO;AAAA;AAAA,EAGT,yBACE,uBACA;AACA,SAAK,wBAAwB;AAC7B,WAAO;AAAA;AAAA,EAGT,gBAAgB,cAAmC;AACjD,SAAK,eAAe;AACpB,WAAO;AAAA;AAAA,EAGT,6BAA6B;AAC3B,SAAK,yBAAyB;AAC9B,WAAO;AAAA;AAAA,QAGH,QAA8B;AA3JtC;AA4JI,UAAM,MAAME;AACZ,UAAM,EAAE,MAAM,MAAM,QAAQ,aAAa,eAAe,kBACtD,KAAK;AAEP,QAAI,IAAIC,2BAAO;AACf,QAAI,aAAa;AACf,UAAI,IAAIC,yBAAK;AAAA;AAEf,QAAI,IAAIC;AACR,QAAI,IACD,YAAK,0BAAL,YAA8BC,uBAA8B;AAE/D,eAAW,CAAC,MAAM,UAAU,KAAK,SAAS;AACxC,UAAI,IAAI,MAAM;AAAA;AAEhB,QAAI,IAAI;AAER,QAAI,KAAK,cAAc;AACrB,UAAI,IAAI,KAAK;AAAA;AAGf,QAAI,KAAK,wBAAwB;AAC/B,UAAI,IAAIC;AAAA;AAGV,UAAM,SAAsB,gBACxB,MAAM,kBAAkB,KAAK,eAAe,UAC5C,iBAAiB,KAAK;AAC1B,UAAM,kBAAkBC,8BAAU,QAAQ;AAE1C,kBAAc,KAAK,QAAQ,MACzB,gBAAgB,KAAK,CAAC,MAAW;AAC/B,UAAI;AAAG,gBAAQ,MAAM;AAAA;AAIzB,WAAO,IAAI,QAAQ,CAAC,SAAS,WAAW;AACtC,kCAA4B,GAAY;AACtC,eAAO;AACP,eAAO;AAAA;AAGT,aAAO,GAAG,SAAS;AAEnB,aAAO,OAAO,MAAM,MAAM,MAAM;AAC9B,eAAO,IAAI,SAAS;AACpB,eAAO,KAAK,gBAAgB,QAAQ;AACpC,gBAAQ;AAAA;AAAA;AAAA;AAAA,EAKN,aAAa;AAhNvB;AAiNI,WAAO;AAAA,MACL,MAAM,WAAK,SAAL,YAAa;AAAA,MACnB,MAAM,WAAK,SAAL,YAAa;AAAA,MACnB,QAAQ,WAAK,WAAL,YAAe;AAAA,MACvB,aAAa,KAAK;AAAA,MAClB,eAAe,KAAK;AAAA,MACpB,eAAe;AAAA,QACb,uBAAuB;AAAA,UACrB,aAAa;AAAA,UACb,YAAY,mBAAmB,KAAK;AAAA;AAAA,QAMtC,2BAA2B;AAAA,QAC3B,yBAAyB;AAAA,QACzB,2BAA2B;AAAA,QAC3B,oBAAoB;AAAA;AAAA;AAAA;AAAA;4BAO1B,YAC4C;AAC5C,QAAM,SACJL,2BAAO,sBAAsB;AAI/B,SAAO,gBAAgB,CAAC,UAAU;AAKlC,SAAO,OAAO;AAEd,MAAI,YAAY;AACd,eAAW,CAAC,KAAK,UAAU,OAAO,QAAQ,aAAa;AACrD,UAAI,UAAU,OAAO;AACnB,eAAO,OAAO;AAAA,aACT;AACL,eAAO,OAAO;AAAA;AAAA;AAAA;AAKpB,SAAO;AAAA;;0BCnO2D;AAAA,EAyC1D,YACW,iBACA,iBACjB;AAFiB;AACA;AAAA;AAAA,SAjCZ,WAAW,QAAgB,SAAiC;AAzCrE;AA0CI,UAAM,WAAW,yCAAS,aAAT,YAAqB;AACtC,UAAM,kBAAkB,OAAO,UAAU;AAEzC,UAAM,EAAE,aAAa,MAAM,aAAa,iBAAiB,gBACvD,OAAO,UAAU;AAEnB,UAAM,WAAW,OAAO,IAAI,mBAAmB,UAAU;AAGzD,QAAI,OAAO;AACX,QAAI,SAAS,MAAM;AAIjB,aAAO;AAAA,eACE,SAAS,WAAW;AAC7B,aAAO;AAAA;AAET,QAAI,KAAK,SAAS,MAAM;AACtB,aAAO,IAAI;AAAA;AAGb,UAAM,kBAAkB,GAAG,cAAc,QAAQ;AAEjD,WAAO,IAAI,oBACT,kBAAkB,UAClB,kBAAkB;AAAA;AAAA,QAShB,WAAW,UAAmC;AAClD,WAAO,GAAG,KAAK,mBAAmB;AAAA;AAAA,QAG9B,mBAAmB,UAAmC;AAC1D,WAAO,GAAG,KAAK,mBAAmB;AAAA;AAAA;;4BCpDH,SAAiB,OAAiB;AACnE,QAAM,MACJ,OAAO,4BAA4B,cAC/B,UACA;AAEN,SAAO1B,qBAAY,IAAI,QAAQ,GAAG,sBAAsB,MAAM,GAAG;AAAA;8BAa9B,MAAc,MAAsB;AACvE,QAAM,aAAaA,qBAAY,MAAM;AAErC,MAAI,CAACgC,sBAAY,MAAM,aAAa;AAClC,UAAM,IAAIf,uBACR;AAAA;AAIJ,SAAO;AAAA;;ACbF,8BAA0C;AAAA,EAU/C,YACmB,aACA,MACjB;AAFiB;AACA;AAAA;AAAA,QAGb,KAAK,KAA8B;AACvC,UAAM,WAAW,MAAM,KAAK,QAAQ;AACpC,WAAO,SAAS;AAAA;AAAA,QAGZ,QACJ,KACA,SAC0B;AAE1B,UAAM,EAAE,WAAW,4BAAW;AAE9B,UAAM,WAAWgB,iCAAqB;AAEtC,QAAI;AACJ,QAAI;AACF,iBAAW,MAAMC,0BAAM,UAAU;AAAA,WAC5BC,mCAAuB,KAAK,YAAY;AAAA,WAOvC,UAAU,EAAE;AAAA;AAAA,aAEX,GAAP;AACA,YAAM,IAAI,MAAM,kBAAkB,QAAQ;AAAA;AAI5C,QAAI,SAAS,MAAM,SAAS,WAAW,KAAK;AAC1C,aAAO;AAAA,QACL,QAAQ,YAAY,OAAO,KAAK,MAAM,SAAS;AAAA;AAAA;AAInD,UAAM,UAAU,GAAG,4BAA4B,aAAa,SAAS,UAAU,SAAS;AACxF,QAAI,SAAS,WAAW,KAAK;AAC3B,YAAM,IAAIjB,qBAAc;AAAA;AAE1B,UAAM,IAAI,MAAM;AAAA;AAAA,QAGZ,SACJ,KACA,SAC2B;AAC3B,UAAM,EAAE,MAAM,QAAQ,WAAW,4BAAW;AAM5C,UAAM,uBAAuB,MAAMgB,0BACjCE,+BAAmB,MACnBD,mCAAuB,KAAK,YAAY;AAE1C,QAAI,CAAC,qBAAqB,IAAI;AAC5B,YAAM,UAAU,4BAA4B,QAAQ,qBAAqB,UAAU,qBAAqB;AACxG,UAAI,qBAAqB,WAAW,KAAK;AACvC,cAAM,IAAIjB,qBAAc;AAAA;AAE1B,YAAM,IAAI,MAAM;AAAA;AAGlB,UAAM,YAAa,OAAM,qBAAqB,QAAQ,MAAM,GAAG;AAC/D,QAAI,QAAQ,SAAS,WAAW;AAC9B,YAAM,IAAIH;AAAA;AAGZ,UAAM,uBAAuB,MAAMmB,0BAAMG,gCAAoB,MAAM;AAAA,SAC9DF,mCAAuB,KAAK,YAAY,QAAQ;AAAA,QACjD,QAAQ;AAAA;AAAA,SAQN,UAAU,EAAE;AAAA;AAElB,QAAI,CAAC,qBAAqB,IAAI;AAC5B,YAAM,UAAU,4BAA4B,QAAQ,qBAAqB,UAAU,qBAAqB;AACxG,UAAI,qBAAqB,WAAW,KAAK;AACvC,cAAM,IAAIjB,qBAAc;AAAA;AAE1B,YAAM,IAAI,MAAM;AAAA;AAMlB,QAAI;AACJ,UAAM,OAAO,IAAI,IAAI,KAAK,aAAa,IAAI;AAC3C,QAAI,MAAM;AACR,gBAAU,KAAK,MAAM,KAAK,OAAO,SAAS,MAAM,IAAI;AAAA;AAGtD,WAAO,MAAM,KAAK,KAAK,oBAAoB,eAAe;AAAA,MACxD,QAAQ,qBAAqB;AAAA,MAC7B,MAAM;AAAA,MACN;AAAA,MACA;AAAA;AAAA;AAAA,QAIE,OAAO,KAAa,SAAkD;AAC1E,UAAM,UAAU,IAAI,IAAI;AAExB,UAAM,OAAO,QAAQ,aAAa,IAAI;AACtC,UAAM,UAAU,QAAQ,IAAIL,oBAAU,KAAK,QAAQ,QAAQ;AAM3D,YAAQ,aAAa,OAAO;AAE5B,UAAM,OAAO,MAAM,KAAK,SAAS,QAAQ,YAAY;AAAA,MACnD,MAAM,mCAAS;AAAA,MACf,QAAQ,mCAAS;AAAA,MACjB,QAAQ,OAAM,UAAU,QAAQ,MAAM,KAAK;AAAA;AAE7C,UAAM,QAAQ,MAAM,KAAK;AAEzB,WAAO;AAAA,MACL,MAAM,KAAK;AAAA,MACX,OAAO,MAAM,IAAI;AAAS,QACxB,KAAK,KAAK,YAAY,WAAW;AAAA,UAC/B,KAAK,IAAI,KAAK;AAAA,UACd,MAAM;AAAA;AAAA,QAER,SAAS,KAAK;AAAA;AAAA;AAAA;AAAA,EAKpB,WAAW;AACT,UAAM,EAAE,MAAM,UAAU,KAAK,YAAY;AACzC,WAAO,cAAc,eAAe,QAAQ;AAAA;AAAA;;AA5JzC,eACE,UAAyB,CAAC,EAAE,QAAQ,0BAA0B;AACnE,QAAM,eAAeyB,4BAAgB,WAAW;AAChD,SAAO,aAAa,MAAM,OAAO,IAAI,iBAAe;AAClD,UAAM,SAAS,IAAI,gBAAe,aAAa,EAAE;AACjD,UAAM,YAAY,CAAC,QAAa,IAAI,SAAS,YAAY,OAAO;AAChE,WAAO,EAAE,QAAQ;AAAA;AAAA;;ACHhB,kCAA8C;AAAA,EAYnD,YACmB,aACA,MACjB;AAFiB;AACA;AAEjB,UAAM,EAAE,MAAM,OAAO,UAAU,gBAAgB,YAAY;AAE3D,QAAI,CAAC,SAAS,YAAY,CAAC,aAAa;AACtC,YAAM,IAAI,MACR,8BAA8B;AAAA;AAAA;AAAA,QAK9B,KAAK,KAA8B;AACvC,UAAM,WAAW,MAAM,KAAK,QAAQ;AACpC,WAAO,SAAS;AAAA;AAAA,QAGZ,QACJ,KACA,SAC0B;AAjF9B;AAkFI,UAAM,EAAE,MAAM,WAAW,4BAAW;AACpC,UAAM,eAAeC,qCAAyB,KAAK,KAAK,YAAY;AACpE,UAAM,iBAAiBC,uCAA2B,KAAK,YAAY;AAEnE,QAAI;AACJ,QAAI;AACF,iBAAW,MAAMN,0BAAM,aAAa,YAAY;AAAA,QAC9C,SAAS;AAAA,aACJ,eAAe;AAAA,aACd,QAAQ,EAAE,iBAAiB;AAAA;AAAA,WAQ7B,UAAU,EAAE;AAAA;AAAA,aAEX,GAAP;AACA,YAAM,IAAI,MAAM,kBAAkB,QAAQ;AAAA;AAG5C,QAAI,SAAS,WAAW,KAAK;AAC3B,YAAM,IAAInB;AAAA;AAGZ,QAAI,SAAS,IAAI;AACf,aAAO;AAAA,QACL,QAAQ,YAAY,OAAO,KAAK,MAAM,SAAS;AAAA,QAC/C,MAAM,eAAS,QAAQ,IAAI,YAArB,YAAgC;AAAA;AAAA;AAI1C,UAAM,UAAU,GAAG,4BAA4B,iBAAiB,SAAS,UAAU,SAAS;AAC5F,QAAI,SAAS,WAAW,KAAK;AAC3B,YAAM,IAAIG,qBAAc;AAAA;AAE1B,UAAM,IAAI,MAAM;AAAA;AAAA,QAGZ,SACJ,KACA,SAC2B;AAC3B,UAAM,EAAE,aAAauB,gCAAY;AAEjC,UAAM,sBAAsB,MAAM,KAAK,uBAAuB;AAC9D,QAAI,oCAAS,SAAQ,QAAQ,SAAS,qBAAqB;AACzD,YAAM,IAAI1B;AAAA;AAGZ,UAAM,cAAc,MAAM2B,oCACxB,KACA,KAAK,YAAY;AAEnB,UAAM,2BAA2B,MAAMR,0BACrC,aACAM,uCAA2B,KAAK,YAAY;AAE9C,QAAI,CAAC,yBAAyB,IAAI;AAChC,YAAM,UAAU,4BAA4B,QAAQ,yBAAyB,UAAU,yBAAyB;AAChH,UAAI,yBAAyB,WAAW,KAAK;AAC3C,cAAM,IAAItB,qBAAc;AAAA;AAE1B,YAAM,IAAI,MAAM;AAAA;AAGlB,WAAO,MAAM,KAAK,KAAK,oBAAoB,eAAe;AAAA,MACxD,QAAQ,yBAAyB;AAAA,MACjC,SAAS;AAAA,MACT,MAAM;AAAA,MACN,QAAQ,mCAAS;AAAA;AAAA;AAAA,QAIf,OAAO,KAAa,SAAkD;AAC1E,UAAM,EAAE,aAAauB,gCAAY;AACjC,UAAM,UAAU,IAAI5B,oBAAU;AAM9B,UAAM,UAAU8B,eAAQ,IAAI,QAAQ,UAAU,KAAK;AAEnD,UAAM,OAAO,MAAM,KAAK,SAAS,SAAS;AAAA,MACxC,MAAM,mCAAS;AAAA,MACf,QAAQ,UAAQ,QAAQ,MAAM;AAAA;AAEhC,UAAM,QAAQ,MAAM,KAAK;AAEzB,WAAO;AAAA,MACL,MAAM,KAAK;AAAA,MACX,OAAO,MAAM,IAAI;AAAS,QACxB,KAAK,KAAK,YAAY,WAAW;AAAA,UAC/B,KAAK,IAAI,KAAK;AAAA,UACd,MAAM;AAAA;AAAA,QAER,SAAS,KAAK;AAAA;AAAA;AAAA;AAAA,EAKpB,WAAW;AACT,UAAM,EAAE,MAAM,OAAO,UAAU,gBAAgB,KAAK,YAAY;AAChE,QAAI,SAAS,QAAQ;AACrB,QAAI,CAAC,QAAQ;AACX,eAAS,QAAQ,YAAY;AAAA;AAE/B,WAAO,kBAAkB,eAAe;AAAA;AAAA,QAG5B,uBAAuB,KAA8B;AACjE,UAAM,EAAE,UAAU,MAAM,UAAU,OAAO,SAAS,QAAQF,gCAAY;AAEtE,QAAI,SAAS;AACb,QAAI,CAAC,QAAQ;AACX,eAAS,MAAMG,sCAA0B,KAAK,KAAK,YAAY;AAAA;AAGjE,UAAM,WAAW,aAAa;AAE9B,UAAM,gBAAgB,WAClB,GAAG,KAAK,YAAY,OAAO,2BAA2B,WAAW,oBAAoB,WACrF,GAAG,KAAK,YAAY,OAAO,uBAAuB,iBAAiB;AAEvE,UAAM,kBAAkB,MAAMV,0BAC5B,eACAM,uCAA2B,KAAK,YAAY;AAE9C,QAAI,CAAC,gBAAgB,IAAI;AACvB,YAAM,UAAU,mCAAmC,kBAAkB,gBAAgB,UAAU,gBAAgB;AAC/G,UAAI,gBAAgB,WAAW,KAAK;AAClC,cAAM,IAAItB,qBAAc;AAAA;AAE1B,YAAM,IAAI,MAAM;AAAA;AAGlB,UAAM,UAAU,MAAM,gBAAgB;AACtC,QAAI,UAAU;AACZ,UACE,WACA,QAAQ,UACR,QAAQ,OAAO,SAAS,KACxB,QAAQ,OAAO,GAAG,MAClB;AACA,eAAO,QAAQ,OAAO,GAAG,KAAK,UAAU,GAAG;AAAA;AAAA,WAExC;AACL,UACE,WACA,QAAQ,UACR,QAAQ,OAAO,SAAS,KACxB,QAAQ,OAAO,GAAG,IAClB;AACA,eAAO,QAAQ,OAAO,GAAG,GAAG,UAAU,GAAG;AAAA;AAAA;AAI7C,UAAM,IAAI,MAAM,gCAAgC;AAAA;AAAA;;AAlM7C,mBACE,UAAyB,CAAC,EAAE,QAAQ,0BAA0B;AACnE,QAAM,eAAeoB,4BAAgB,WAAW;AAChD,SAAO,aAAa,UAAU,OAAO,IAAI,iBAAe;AACtD,UAAM,SAAS,IAAI,oBAAmB,aAAa;AAAA,MACjD;AAAA;AAEF,UAAM,YAAY,CAAC,QAAa,IAAI,SAAS,YAAY,OAAO;AAChE,WAAO,EAAE,QAAQ;AAAA;AAAA;;ACChB,+BAA2C;AAAA,EAehD,YACmB,aACA,MAIjB;AALiB;AACA;AAKjB,QAAI,CAAC,YAAY,OAAO,cAAc,CAAC,YAAY,OAAO,YAAY;AACpE,YAAM,IAAI,MACR,uBAAuB,YAAY;AAAA;AAAA;AAAA,QAKnC,KAAK,KAA8B;AACvC,UAAM,WAAW,MAAM,KAAK,QAAQ;AACpC,WAAO,SAAS;AAAA;AAAA,QAGZ,QACJ,KACA,SAC0B;AA9F9B;AA+FI,UAAM,cAAc,MAAM,KAAK,KAAK,oBAAoB,eAAe;AAAA,MACrE;AAAA;AAEF,UAAM,QAAQO,kCACZ,KACA,KAAK,YAAY,QACjB;AAGF,QAAI;AACJ,QAAI;AACF,iBAAW,MAAMX,0BAAM,OAAO;AAAA,QAC5B,SAAS;AAAA,aACJ,2CAAa;AAAA,aACZ,oCAAS,SAAQ,EAAE,iBAAiB,QAAQ;AAAA,UAChD,QAAQ;AAAA;AAAA,QAQV,QAAQ,mCAAS;AAAA;AAAA,aAEZ,GAAP;AACA,YAAM,IAAI,MAAM,kBAAkB,QAAQ;AAAA;AAG5C,QAAI,SAAS,WAAW,KAAK;AAC3B,YAAM,IAAInB;AAAA;AAGZ,QAAI,SAAS,IAAI;AACf,aAAO;AAAA,QACL,QAAQ,YAAY,OAAO,KAAK,MAAM,SAAS;AAAA,QAC/C,MAAM,eAAS,QAAQ,IAAI,YAArB,YAAgC;AAAA;AAAA;AAI1C,QAAI,UAAU,GAAG,4BAA4B,UAAU,SAAS,UAAU,SAAS;AACnF,QAAI,SAAS,WAAW,KAAK;AAC3B,YAAM,IAAIG,qBAAc;AAAA;AAM1B,QACE,SAAS,WAAW,OACpB,SAAS,QAAQ,IAAI,6BAA6B,KAClD;AACA,iBAAW;AAAA;AAGb,UAAM,IAAI,MAAM;AAAA;AAAA,QAGZ,SACJ,KACA,SAC2B;AAC3B,UAAM,cAAc,MAAM,KAAK,eAAe;AAC9C,UAAM,YAAY,YAAY,OAAO,OAAO;AAE5C,QAAI,oCAAS,SAAQ,QAAQ,SAAS,WAAW;AAC/C,YAAM,IAAIH;AAAA;AAGZ,UAAM,EAAE,aAAa0B,gCAAY;AACjC,UAAM,EAAE,YAAY,MAAM,KAAK,KAAK,oBAAoB,eAAe;AAAA,MACrE;AAAA;AAGF,WAAO,KAAK,WACV,YAAY,KAAK,aACjB,WACA,UAOA,EAAE,SAAS,QAAQ,mCAAS,UAC5B;AAAA;AAAA,QAIE,OAAO,KAAa,SAAkD;AAC1E,UAAM,cAAc,MAAM,KAAK,eAAe;AAC9C,UAAM,YAAY,YAAY,OAAO,OAAO;AAE5C,QAAI,oCAAS,SAAQ,QAAQ,SAAS,WAAW;AAC/C,YAAM,IAAI1B;AAAA;AAGZ,UAAM,EAAE,aAAa0B,gCAAY;AACjC,UAAM,EAAE,YAAY,MAAM,KAAK,KAAK,oBAAoB,eAAe;AAAA,MACrE;AAAA;AAGF,UAAM,QAAQ,MAAM,KAAK,SACvB,KACA,YAAY,KAAK,WACjB,YAAY,KAAK,aACjB,WACA,UACA,EAAE,SAAS,QAAQ,mCAAS;AAG9B,WAAO,EAAE,OAAO,MAAM;AAAA;AAAA,EAGxB,WAAW;AACT,UAAM,EAAE,MAAM,UAAU,KAAK,YAAY;AACzC,WAAO,eAAe,eAAe,QAAQ;AAAA;AAAA,QAGjC,WACZ,YACA,KACA,SACA,MACA,SAC2B;AAE3B,UAAM,UAAU,MAAM,KAAK,cACzB,WACG,QAAQ,oBAAoB,WAC5B,QAAQ,UAAU,IAAI,QACzB;AAGF,WAAO,MAAM,KAAK,KAAK,oBAAoB,eAAe;AAAA,MAGxD,QAAQ,QAAQ;AAAA,MAChB;AAAA,MACA,MAAM;AAAA,MACN,QAAQ,mCAAS;AAAA;AAAA;AAAA,QAIP,SACZ,KACA,UACA,YACA,KACA,OACA,MAC+B;AAC/B,uBAAmB,MAAsB;AAGvC,YAAM,UAAU,IAAI,IAAI;AACxB,YAAM,OAAO,QAAQ,SAAS,MAAM,KAAK,MAAM,GAAG,GAAG,KAAK;AAC1D,cAAQ,WAAW,GAAG,QAAQ;AAC9B,aAAO,QAAQ;AAAA;AAGjB,UAAM,UAAU,IAAI5B,oBAAU,MAAM,QAAQ,QAAQ;AAGpD,UAAM,gBAAgC,MAAM,KAAK,UAC/C,SAAS,QAAQ,UAAU,IAAI,uBAC/B;AAIF,QAAI,CAAC,cAAc,WAAW;AAC5B,YAAM,WAAW,cAAc,KAAK,OAClC,UACE,KAAK,SAAS,UACd,KAAK,QACL,KAAK,OACL,QAAQ,MAAM,KAAK;AAGvB,aAAO,SAAS,IAAI;AAAS,QAC3B,KAAK,UAAU,KAAK;AAAA,QACpB,SAAS,YAAY;AACnB,gBAAM,OAAuB,MAAM,KAAK,UAAU,KAAK,KAAM;AAC7D,iBAAO,OAAO,KAAK,KAAK,SAAS;AAAA;AAAA;AAAA;AAMvC,UAAM,OAAO,MAAM,KAAK,WAAW,YAAY,KAAK,IAAI,MAAM;AAAA,MAC5D,QAAQ,UAAQ,QAAQ,MAAM;AAAA;AAEhC,UAAM,QAAQ,MAAM,KAAK;AAEzB,WAAO,MAAM,IAAI;AAAS,MACxB,KAAK,UAAU,KAAK;AAAA,MACpB,SAAS,KAAK;AAAA;AAAA;AAAA,QAIJ,eAAe,KAG1B;AACD,UAAM,SAAS4B,gCAAY;AAC3B,UAAM,EAAE,KAAK,cAAc;AAM3B,UAAM,EAAE,YAAY,MAAM,KAAK,KAAK,oBAAoB,eAAe;AAAA,MACrE;AAAA;AAGF,UAAM,OAAuB,MAAM,KAAK,UACtC,GAAG,KAAK,YAAY,OAAO,oBAAoB,aAC/C,EAAE;AAIJ,UAAM,SAA2B,MAAM,KAAK,UAC1C,KAAK,aAAa,QAAQ,aAAa,IAAI,OAAO,KAAK,mBACvD,EAAE;AAGJ,WAAO,EAAE,MAAM;AAAA;AAAA,QAGH,cACZ,KACA,MACmB;AACnB,UAAM,cAAc,IAAI;AAExB,UAAM,WAAW,MAAMP,0BAAM,aAAa;AAE1C,QAAI,CAAC,SAAS,IAAI;AAChB,YAAM,UAAU,sBAAsB,gBAAgB,SAAS,UAAU,SAAS;AAClF,UAAI,SAAS,WAAW,KAAK;AAC3B,cAAM,IAAIhB,qBAAc;AAAA;AAE1B,YAAM,IAAI,MAAM;AAAA;AAGlB,WAAO;AAAA;AAAA,QAGK,UAAU,KAAmB,MAAiC;AAC1E,UAAM,WAAW,MAAM,KAAK,cAAc,KAAK;AAC/C,WAAO,MAAM,SAAS;AAAA;AAAA;;AAhSnB,gBACE,UAAyB,CAAC,EAAE,QAAQ,0BAA0B;AACnE,QAAM,eAAeoB,4BAAgB,WAAW;AAChD,QAAM,sBACJQ,6CAAiC,iBAAiB;AACpD,SAAO,aAAa,OAAO,OAAO,IAAI,iBAAe;AACnD,UAAM,SAAS,IAAI,iBAAgB,aAAa;AAAA,MAC9C;AAAA,MACA;AAAA;AAEF,UAAM,YAAY,CAAC,QAAa,IAAI,SAAS,YAAY,OAAO;AAChE,WAAO,EAAE,QAAQ;AAAA;AAAA;;ACjDvB,MAAM,qBAAqB;qCAGiB,MAAsB;AAChE,SAAO,KAAK,QAAQ,oBAAoB;AAAA;;ACuBnC,+BAA2C;AAAA,EAYhD,YACmB,aACA,MACjB;AAFiB;AACA;AAAA;AAAA,QAGb,KAAK,KAA8B;AACvC,UAAM,WAAW,MAAM,KAAK,QAAQ;AACpC,WAAO,SAAS;AAAA;AAAA,QAGZ,QACJ,KACA,SAC0B;AAvE9B;AAwEI,UAAM,EAAE,MAAM,WAAW,4BAAW;AACpC,UAAM,WAAW,MAAMC,kCAAsB,KAAK,KAAK,YAAY;AAEnE,QAAI;AACJ,QAAI;AACF,iBAAW,MAAMb,0BAAM,UAAU;AAAA,QAC/B,SAAS;AAAA,aACJc,oCAAwB,KAAK,YAAY,QAAQ;AAAA,aAChD,QAAQ,EAAE,iBAAiB;AAAA;AAAA,WAQ7B,UAAU,EAAE;AAAA;AAAA,aAEX,GAAP;AACA,YAAM,IAAI,MAAM,kBAAkB,QAAQ;AAAA;AAG5C,QAAI,SAAS,WAAW,KAAK;AAC3B,YAAM,IAAIjC;AAAA;AAGZ,QAAI,SAAS,IAAI;AACf,aAAO;AAAA,QACL,QAAQ,YAAY,OAAO,KAAK,MAAM,SAAS;AAAA,QAC/C,MAAM,eAAS,QAAQ,IAAI,YAArB,YAAgC;AAAA;AAAA;AAI1C,UAAM,UAAU,GAAG,4BAA4B,aAAa,SAAS,UAAU,SAAS;AACxF,QAAI,SAAS,WAAW,KAAK;AAC3B,YAAM,IAAIG,qBAAc;AAAA;AAE1B,UAAM,IAAI,MAAM;AAAA;AAAA,QAGZ,SACJ,KACA,SAC2B;AAC3B,UAAM,EAAE,MAAM,WAAW,4BAAW;AACpC,UAAM,EAAE,KAAK,WAAW,aAAauB,gCAAY;AAKjD,UAAM,wBAAwB,MAAMP,0BAClC,IAAI,IACF,GAAG,KAAK,YAAY,OAAO,uBAAuB,mBAChD,cAEF,YACFc,oCAAwB,KAAK,YAAY;AAE3C,QAAI,CAAC,sBAAsB,IAAI;AAC7B,YAAM,MAAM,4BAA4B,QAAQ,sBAAsB,UAAU,sBAAsB;AACtG,UAAI,sBAAsB,WAAW,KAAK;AACxC,cAAM,IAAI9B,qBAAc;AAAA;AAE1B,YAAM,IAAI,MAAM;AAAA;AAElB,UAAM,4BAA4B,MAAM,sBAAsB;AAG9D,UAAM,SAAS,OAAO,0BAA0B;AAIhD,UAAM,mBAAmB,IAAI;AAC7B,qBAAiB,IAAI,YAAY;AACjC,QAAI,CAAC,CAAC,UAAU;AACd,uBAAiB,IAAI,QAAQ;AAAA;AAE/B,UAAM,wBAAwB,MAAMgB,0BAClC,IAAI,IACF,GAAG,KAAK,YAAY,OAAO,uBAAuB,mBAChD,iCACsB,iBAAiB,cACzC,YACF;AAAA,SACKc,oCAAwB,KAAK,YAAY;AAAA,SAOxC,UAAU,EAAE;AAAA;AAGpB,QAAI,CAAC,sBAAsB,IAAI;AAC7B,YAAM,UAAU,qCAAqC,QAAQ,sBAAsB,UAAU,sBAAsB;AACnH,UAAI,sBAAsB,WAAW,KAAK;AACxC,cAAM,IAAI9B,qBAAc;AAAA;AAE1B,YAAM,IAAI,MAAM;AAAA;AAGlB,UAAM,YAAa,OAAM,sBAAsB,QAAQ,GAAG;AAE1D,QAAI,QAAQ,SAAS,WAAW;AAC9B,YAAM,IAAIH;AAAA;AAIZ,UAAM,wBAAwB,MAAMmB,0BAClC,GAAG,KAAK,YAAY,OAAO,uBAAuB,mBAChD,qCAC0B,UAC5B;AAAA,SACKc,oCAAwB,KAAK,YAAY;AAAA,SAOxC,UAAU,EAAE;AAAA;AAGpB,QAAI,CAAC,sBAAsB,IAAI;AAC7B,YAAM,UAAU,sCAAsC,QAAQ,sBAAsB,UAAU,sBAAsB;AACpH,UAAI,sBAAsB,WAAW,KAAK;AACxC,cAAM,IAAI9B,qBAAc;AAAA;AAE1B,YAAM,IAAI,MAAM;AAAA;AAGlB,WAAO,MAAM,KAAK,KAAK,oBAAoB,eAAe;AAAA,MACxD,QAAQ,sBAAsB;AAAA,MAC9B,SAAS;AAAA,MACT,MAAM;AAAA,MACN,QAAQ,mCAAS;AAAA;AAAA;AAAA,QAIf,OAAO,KAAa,SAAkD;AAC1E,UAAM,EAAE,aAAauB,gCAAY;AACjC,UAAM,UAAU,IAAI5B,oBAAU;AAM9B,UAAM,UAAU8B,eAAQ,IAAI,QAAQ,UAAU,KAAK;AAEnD,UAAM,OAAO,MAAM,KAAK,SAAS,SAAS;AAAA,MACxC,MAAM,mCAAS;AAAA,MACf,QAAQ,mCAAS;AAAA,MACjB,QAAQ,UAAQ,QAAQ,MAAM,4BAA4B;AAAA;AAE5D,UAAM,QAAQ,MAAM,KAAK;AAEzB,WAAO;AAAA,MACL,MAAM,KAAK;AAAA,MACX,OAAO,MAAM,IAAI;AAAS,QACxB,KAAK,KAAK,YAAY,WAAW,EAAE,KAAK,IAAI,KAAK,QAAQ,MAAM;AAAA,QAC/D,SAAS,KAAK;AAAA;AAAA;AAAA;AAAA,EAKpB,WAAW;AACT,UAAM,EAAE,MAAM,UAAU,KAAK,YAAY;AACzC,WAAO,eAAe,eAAe,QAAQ;AAAA;AAAA;;AAlM1C,gBACE,UAAyB,CAAC,EAAE,QAAQ,0BAA0B;AACnE,QAAM,eAAeL,4BAAgB,WAAW;AAChD,SAAO,aAAa,OAAO,OAAO,IAAI,iBAAe;AACnD,UAAM,SAAS,IAAI,iBAAgB,aAAa;AAAA,MAC9C;AAAA;AAEF,UAAM,YAAY,CAAC,QAAa,IAAI,SAAS,YAAY,OAAO;AAChE,WAAO,EAAE,QAAQ;AAAA;AAAA;;ACjBvB,MAAMW,aAAW,CACf,KACA,WACqD;AACrD,MAAI,EAAE,MAAM,aAAa,IAAI,IAAI;AAMjC,aAAW,SAAS,OAAO;AAE3B,MAAI;AACJ,MAAI;AAOJ,MAAI,OAAO,kBAAkB;AAC3B,QAAI,SAAS,QAAQ,OAAO,GAAG;AAC7B,YAAM,IAAI,MACR,kCAAkC;AAAA;AAGtC,KAAC,UAAU,SAAS,MAAM;AAC1B,eAAW,SAAS,OAAO,OAAO,SAAS;AAAA,SACtC;AACL,QAAI,KAAK,QAAQ,OAAO,GAAG;AACzB,YAAM,IAAI,MACR,4CAA4C;AAAA;AAGhD,KAAC,UAAU,KAAK,MAAM;AACtB,WAAO,KAAK,OAAO,OAAO,SAAS;AAAA;AAIrC,MAAI,OAAO,SAAS,iBAAiB;AAEnC,UAAM,QAAQ,KAAK,MAAM;AACzB,QAAI,CAAC,OAAO;AACV,YAAM,IAAI,MACR,wDAAwD;AAAA;AAG5D,aAAS,MAAM;AAAA,SACV;AACL,aAAS;AAAA;AAGX,SAAO;AAAA,IACL,MAAM;AAAA,IACN;AAAA,IACA;AAAA;AAAA;AASG,8BAA0C;AAAA,EAuB/C,YACmB,aACA,MAIjB;AALiB;AACA;AAAA;AAAA,SAUJ,iBACb,aAC8C;AAC9C,QAAI,CAAC,aAAa;AAChB,aAAO;AAAA;AAGT,UAAM,cAAc,YAAY,OAAO;AACvC,UAAM,kBAAkB,YAAY,OAAO;AAC3C,QAAI;AAEJ,QAAI,eAAe,iBAAiB;AAClC,4BAAsB,IAAIC,gBAAY;AAAA,QACpC;AAAA,QACA;AAAA;AAAA;AAIJ,UAAM,UAAU,YAAY,OAAO;AACnC,QAAI,SAAS;AACX,aAAO,IAAIC,wBAAI,8BAA8B;AAAA,QAC3C,mBAAmB;AAAA,QACnB,QAAQ;AAAA,UACN,iBAAiB;AAAA,UACjB,SAAS;AAAA;AAAA;AAAA;AAKf,WAAO;AAAA;AAAA,QAGH,KAAK,KAA8B;AACvC,UAAM,WAAW,MAAM,KAAK,QAAQ;AACpC,WAAO,SAAS;AAAA;AAAA,QAGZ,QACJ,KACA,SAC0B;AAhL9B;AAiLI,QAAI;AACF,YAAM,EAAE,MAAM,QAAQ,WAAWF,WAAS,KAAK,KAAK,YAAY;AAChE,8BAAI,OAAO,OAAO,EAAE;AAEpB,UAAI;AACJ,UAAI,mCAAS,MAAM;AACjB,iBAAS;AAAA,UACP,QAAQ;AAAA,UACR,KAAK;AAAA,UACL,aAAa,QAAQ;AAAA;AAAA,aAElB;AACL,iBAAS;AAAA,UACP,QAAQ;AAAA,UACR,KAAK;AAAA;AAAA;AAIT,YAAM,UAAU,KAAK,KAAK,GAAG,UAAU;AACvC,+CAAS,WAAT,mBAAiB,iBAAiB,SAAS,MAAM,QAAQ;AACzD,YAAM,SAAS,MAAMG,+BAAW,QAAQ;AACxC,YAAM,OAAQ,OAAM,QAAQ,WAAW;AAEvC,aAAO;AAAA,QACL,QAAQ,YAAY;AAAA,QACpB;AAAA;AAAA,aAEK,GAAP;AACA,UAAI,EAAE,eAAe,KAAK;AACxB,cAAM,IAAIrC;AAAA;AAGZ,YAAM,IAAIL,sBAAe,mCAAmC;AAAA;AAAA;AAAA,QAI1D,SACJ,KACA,SAC2B;AAxN/B;AAyNI,QAAI;AACF,YAAM,EAAE,MAAM,QAAQ,WAAWuC,WAAS,KAAK,KAAK,YAAY;AAChE,YAAM,aAAyB;AAC/B,YAAM,YAAY;AAClB,UAAI;AACJ,UAAI;AACJ,SAAG;AACD,gCAAI,OAAO,OAAO,EAAE;AACpB,cAAM,UAAU,KAAK,KAAK,GAAG,cAAc;AAAA,UACzC,QAAQ;AAAA,UACR,mBAAmB;AAAA,UACnB,QAAQ;AAAA;AAEV,iDAAS,WAAT,mBAAiB,iBAAiB,SAAS,MAAM,QAAQ;AACzD,iBAAS,MAAM,QAAQ;AACvB,YAAI,OAAO,UAAU;AACnB,iBAAO,SAAS,QAAQ,cAAY;AAClC,uBAAW,KAAK;AAAA;AAAA;AAGpB,4BAAoB,OAAO;AAAA,eACpB;AAET,eAAS,IAAI,GAAG,IAAI,WAAW,QAAQ,KAAK;AAC1C,cAAM,SAAS,KAAK,KAAK,GAAG,UAAU;AAAA,UACpC,QAAQ;AAAA,UACR,KAAK,OAAO,WAAW,GAAG;AAAA;AAE5B,kBAAU,KAAK;AAAA,UACb,MAAM,OAAO;AAAA,UACb,MAAM,OAAO,WAAW,GAAG;AAAA;AAAA;AAI/B,aAAO,MAAM,KAAK,KAAK,oBAAoB,kBAAkB;AAAA,aACtD,GAAP;AACA,YAAM,IAAIvC,sBAAe,wCAAwC;AAAA;AAAA;AAAA,QAI/D,SAAkC;AACtC,UAAM,IAAI,MAAM;AAAA;AAAA,EAGlB,WAAW;AACT,UAAM,kBAAkB,KAAK,YAAY,OAAO;AAChD,WAAO,cAAc,KAAK,YAAY,OAAO,eAAe,QAC1D;AAAA;AAAA;;AAnKC,eACE,UAAyB,CAAC,EAAE,QAAQ,0BAA0B;AACnE,QAAM,eAAe4B,4BAAgB,WAAW;AAEhD,SAAO,aAAa,MAAM,OAAO,IAAI,iBAAe;AAClD,UAAM,QAAQ,gBAAe,iBAAiB;AAE9C,UAAM,KAAK,IAAIe,OAAG;AAAA,MAChB,YAAY;AAAA,MACZ,aAAa;AAAA,MACb,UAAU,YAAY,OAAO;AAAA,MAC7B,kBAAkB,YAAY,OAAO;AAAA;AAEvC,UAAM,SAAS,IAAI,gBAAe,aAAa;AAAA,MAC7C;AAAA,MACA;AAAA;AAEF,UAAM,YAAY,CAAC,QACjB,IAAI,KAAK,SAAS,YAAY,OAAO;AACvC,WAAO,EAAE,QAAQ;AAAA;AAAA;;ACvFhB,8BAA0C;AAAA,QAwCzC,KAAK,KAA8B;AACvC,UAAM,WAAW,MAAM,KAAK,QAAQ;AACpC,WAAO,SAAS;AAAA;AAAA,QAGZ,QACJ,KACA,SAC0B;AAjF9B;AAkFI,QAAI;AACJ,QAAI;AACF,iBAAW,MAAMnB,0BAAM,KAAK;AAAA,QAC1B,SAAS;AAAA,aACH,oCAAS,SAAQ,EAAE,iBAAiB,QAAQ;AAAA;AAAA,QAQlD,QAAQ,mCAAS;AAAA;AAAA,aAEZ,GAAP;AACA,YAAM,IAAI,MAAM,kBAAkB,QAAQ;AAAA;AAG5C,QAAI,SAAS,WAAW,KAAK;AAC3B,YAAM,IAAInB;AAAA;AAGZ,QAAI,SAAS,IAAI;AACf,aAAO;AAAA,QACL,QAAQ,YAAY,OAAO,KAAK,MAAM,SAAS;AAAA,QAC/C,MAAM,eAAS,QAAQ,IAAI,YAArB,YAAgC;AAAA;AAAA;AAI1C,UAAM,UAAU,kBAAkB,QAAQ,SAAS,UAAU,SAAS;AACtE,QAAI,SAAS,WAAW,KAAK;AAC3B,YAAM,IAAIG,qBAAc;AAAA;AAE1B,UAAM,IAAI,MAAM;AAAA;AAAA,QAGZ,WAAsC;AAC1C,UAAM,IAAI,MAAM;AAAA;AAAA,QAGZ,SAAkC;AACtC,UAAM,IAAI,MAAM;AAAA;AAAA,EAGlB,WAAW;AACT,WAAO;AAAA;AAAA;;AA9FJ,eAaE,UAAyB,CAAC,EAAE,aAAa;AA9ClD;AA+CI,QAAM,aACJ,mBACG,uBAAuB,6BAD1B,mBAEI,IAAI,iBAAe;AACnB,UAAM,QAAQ,YAAY,uBAAuB;AACjD,UAAM,YAAY,QACd,CAAC,QAAa;AACZ,YAAM,aAAaP,iCAAK,MAAM,UAAU,IAAI;AAC5C,aAAO,MAAM,KAAK,iBAChB,WAAW,WAAW;AAAA,QAG1B,CAAC,SAAc;AACnB,UAAM,OAAO,YAAY,UAAU;AACnC,QAAI,KAAK,WAAW,OAAO;AACzB,YAAM,SAAS,KAAK,MAAM;AAC1B,aAAO,CAAC,QAAa,IAAI,KAAK,SAAS,WAAW,UAAU;AAAA;AAE9D,WAAO,CAAC,QAAa,IAAI,SAAS,QAAQ,UAAU;AAAA,SAjBxD,YAkBQ;AAEV,QAAM,SAAS,IAAI;AACnB,QAAM,YAAY,CAAC,QAAa,WAAW,KAAK,OAAK,EAAE;AACvD,SAAO,CAAC,EAAE,QAAQ;AAAA;;ACzCtB,MAAM,0BAA0B,MAAO,KAAK;4BAMY;AAAA,EAItD,YAA6B,QAAgB;AAAhB;AAHZ,mBAAqC;AACrC,8CAA6C;AAAA;AAAA,EAI9D,SAAS,OAAsC;AAC7C,SAAK,QAAQ,KAAK;AAAA;AAAA,QAGd,KAAK,KAA8B;AACvC,UAAM,SAAS,IAAI,IAAI;AAEvB,eAAW,EAAE,WAAW,YAAY,KAAK,SAAS;AAChD,UAAI,UAAU,SAAS;AACrB,eAAO,OAAO,KAAK;AAAA;AAAA;AAIvB,UAAM,IAAIM,uBACR,iBAAiB;AAAA;AAAA,QAMf,QACJ,KACA,SAC0B;AAhE9B;AAiEI,UAAM,SAAS,IAAI,IAAI;AAEvB,eAAW,EAAE,WAAW,YAAY,KAAK,SAAS;AAChD,UAAI,UAAU,SAAS;AACrB,YAAI,OAAO,SAAS;AAClB,iBAAO,OAAO,QAAQ,KAAK;AAAA;AAE7B,cAAM,MAAM,KAAK;AACjB,cAAM,aAAa,WAAK,eAAe,IAAI,YAAxB,YAAmC;AACtD,YAAI,MAAM,aAAa,yBAAyB;AAC9C,eAAK,eAAe,IAAI,QAAQ;AAChC,eAAK,OAAO,KACV,0CAA0C;AAAA;AAK9C,cAAM,SAAS,MAAM,OAAO,KAAK;AACjC,eAAO;AAAA,UACL,QAAQ,YAAY;AAAA;AAAA;AAAA;AAK1B,UAAM,IAAIA,uBAAgB,iBAAiB;AAAA;AAAA,QAGvC,SACJ,KACA,SAC2B;AAC3B,UAAM,SAAS,IAAI,IAAI;AAEvB,eAAW,EAAE,WAAW,YAAY,KAAK,SAAS;AAChD,UAAI,UAAU,SAAS;AACrB,eAAO,MAAM,OAAO,SAAS,KAAK;AAAA;AAAA;AAItC,UAAM,IAAIA,uBAAgB,iBAAiB;AAAA;AAAA,QAGvC,OAAO,KAAa,SAAkD;AAC1E,UAAM,SAAS,IAAI,IAAI;AAEvB,eAAW,EAAE,WAAW,YAAY,KAAK,SAAS;AAChD,UAAI,UAAU,SAAS;AACrB,eAAO,MAAM,OAAO,OAAO,KAAK;AAAA;AAAA;AAIpC,UAAM,IAAIA,uBAAgB,iBAAiB;AAAA;AAAA,EAG7C,WAAW;AACT,WAAO,wBAAwB,KAAK,QAAQ,IAAI,OAAK,EAAE,QAAQ,KAAK;AAAA;AAAA;;AC1FxE,MAAM,iBAAiBqC;AAEvB,MAAMC,aAAWC,eAAUC;yBAKiC;AAAA,EAG1D,YACmB,QACA,SACA,SACD,MACC,QACjB;AALiB;AACA;AACA;AACD;AACC;AAPX,gBAAO;AASb,QAAI,SAAS;AACX,UAAI,CAAC,QAAQ,SAAS,MAAM;AAC1B,aAAK,WAAW;AAAA;AAElB,UAAI,QAAQ,WAAW,MAAM;AAC3B,cAAM,IAAI,UACR,4DAA4D;AAAA;AAAA;AAKlE,SAAK,OAAO;AAAA;AAAA,EAIN,WAAW;AACjB,QAAI,KAAK,MAAM;AACb,YAAM,IAAI,MAAM;AAAA;AAElB,SAAK,OAAO;AAAA;AAAA,QAGR,QAAyC;AAC7C,SAAK;AAEL,UAAM,QAAQ;AACd,UAAM,SAAS,IAAI;AAEnB,WAAO,GAAG,SAAS,CAAC,UAAgC;AAClD,UAAI,MAAM,SAAS,aAAa;AAC9B,cAAM;AACN;AAAA;AAKF,YAAM,eAAe,4BAA4B,MAAM;AAEvD,UAAI,KAAK,SAAS;AAChB,YAAI,CAAC,aAAa,WAAW,KAAK,UAAU;AAC1C,gBAAM;AACN;AAAA;AAAA;AAIJ,YAAM,OAAO,aAAa,MAAM,KAAK,QAAQ;AAC7C,UAAI,KAAK,QAAQ;AACf,YAAI,CAAC,KAAK,OAAO,MAAM,EAAE,MAAM,MAAM,WAAW;AAC9C,gBAAM;AACN;AAAA;AAAA;AAIJ,YAAM,UAAU,IAAI,QAAgB,OAAM,YAAW;AACnD,cAAMF,WAAS,OAAOG,iCAAa;AAAA;AAGrC,YAAM,KAAK;AAAA,QACT;AAAA,QACA,SAAS,MAAM;AAAA;AAGjB,YAAM;AAAA;AAGR,UAAMH,WAAS,KAAK,QAAQ;AAE5B,WAAO;AAAA;AAAA,QAGH,UAA6B;AACjC,QAAI,CAAC,KAAK,SAAS;AACjB,WAAK;AAEL,aAAO,KAAK;AAAA;AAKd,UAAM,SAAS,MAAM,KAAK;AAE1B,QAAI;AACF,YAAM,OAAO,MAAM,IAAI,QAAgB,OAAM,YAAW;AACtD,cAAMA,WACJI,wBAAI,OAAO,EAAE,KAAK,UAAU,CAAC,MAC7BD,iCAAa;AAAA;AAGjB,aAAOE,gBAAS,KAAK;AAAA,cACrB;AACA,YAAMrC,uBAAG,OAAO;AAAA;AAAA;AAAA,QAId,IAAI,SAAuD;AA7InE;AA8II,SAAK;AAEL,UAAM,MACJ,yCAAS,cAAT,YACC,MAAMA,uBAAG,QAAQsC,iCAAa,KAAK,KAAK,SAAS;AAIpD,UAAM,QAAQ,KAAK,UAAU,KAAK,QAAQ,MAAM,KAAK,SAAS;AAE9D,QAAI,cAAiC;AAErC,UAAMN,WACJ,KAAK,QACLI,wBAAI,QAAQ;AAAA,MACV;AAAA,MACA,KAAK;AAAA,MACL,QAAQ,CAAC,MAAM,SAAS;AAEtB,YAAI,aAAa;AACf,iBAAO;AAAA;AAKT,cAAM,eAAe,4BAA4B;AACjD,YAAI,KAAK,WAAW,CAAC,aAAa,WAAW,KAAK,UAAU;AAC1D,iBAAO;AAAA;AAET,YAAI,KAAK,QAAQ;AACf,gBAAM,YAAY,KAAK,MAAM,KAAK,MAAM,OAAO,KAAK;AACpD,cAAI;AACF,mBAAO,KAAK,OAAO,WAAW,EAAE,MAAM,KAAK;AAAA,mBACpC,OAAP;AACA,0BAAc;AACd,mBAAO;AAAA;AAAA;AAGX,eAAO;AAAA;AAAA;AAKb,QAAI,aAAa;AAGf,UAAI,qCAAU,YAAW;AACvB,cAAMpC,uBAAG,OAAO,KAAK,MAAM,MAAM;AAAA;AAAA;AAEnC,YAAM;AAAA;AAGR,WAAO;AAAA;AAAA;;yBCpKiD;AAAA,EAG1D,YACmB,QACA,SACA,SACD,MACC,QACjB;AALiB;AACA;AACA;AACD;AACC;AAPX,gBAAO;AASb,QAAI,SAAS;AACX,UAAI,CAAC,QAAQ,SAAS,MAAM;AAC1B,aAAK,WAAW;AAAA;AAElB,UAAI,QAAQ,WAAW,MAAM;AAC3B,cAAM,IAAI,UACR,4DAA4D;AAAA;AAAA;AAKlE,SAAK,OAAO;AAAA;AAAA,EAIN,WAAW;AACjB,QAAI,KAAK,MAAM;AACb,YAAM,IAAI,MAAM;AAAA;AAElB,SAAK,OAAO;AAAA;AAAA,EAIN,aAAa,MAAsB;AACzC,WAAO,KAAK,MAAM,KAAK,QAAQ;AAAA;AAAA,EAGzB,iBAAiB,OAAuB;AAnElD;AAoEI,QAAI,KAAK,SAAS;AAChB,UAAI,CAAC,MAAM,KAAK,WAAW,KAAK,UAAU;AACxC,eAAO;AAAA;AAAA;AAGX,QAAI,KAAK,QAAQ;AACf,aAAO,KAAK,OAAO,KAAK,aAAa,MAAM,OAAO;AAAA,QAChD,MACG,YAAM,KAAuC,qBAA7C,YACD,MAAM,KAAK;AAAA;AAAA;AAGjB,WAAO;AAAA;AAAA,QAGH,QAAyC;AAC7C,SAAK;AAEL,UAAM,QAAQ;AAEd,UAAM,KAAK,OACR,KAAKuC,6BAAS,SACd,GAAG,SAAS,CAAC,UAAiB;AAC7B,UAAI,MAAM,SAAS,aAAa;AAC9B,cAAM;AACN;AAAA;AAGF,UAAI,KAAK,iBAAiB,QAAQ;AAChC,cAAM,KAAK;AAAA,UACT,MAAM,KAAK,aAAa,MAAM;AAAA,UAC9B,SAAS,MAAM,MAAM;AAAA;AAAA,aAElB;AACL,cAAM;AAAA;AAAA,OAGT;AAEH,WAAO;AAAA;AAAA,QAGH,UAA6B;AACjC,SAAK;AAEL,QAAI,CAAC,KAAK,SAAS;AACjB,aAAO,KAAK;AAAA;AAGd,UAAM,UAAUC,6BAAS;AACzB,UAAM,KAAK,OACR,KAAKD,6BAAS,SACd,GAAG,SAAS,CAAC,UAAiB;AAC7B,UAAI,MAAM,SAAS,UAAU,KAAK,iBAAiB,QAAQ;AACzD,gBAAQ,OAAO,OAAO,EAAE,MAAM,KAAK,aAAa,MAAM;AAAA,aACjD;AACL,cAAM;AAAA;AAAA,OAGT;AACH,YAAQ;AAER,WAAO;AAAA;AAAA,QAGH,IAAI,SAAuD;AArInE;AAsII,SAAK;AAEL,UAAM,MACJ,yCAAS,cAAT,YACC,MAAMvC,uBAAG,QAAQsC,iCAAa,KAAK,KAAK,SAAS;AAEpD,UAAM,KAAK,OACR,KAAKC,6BAAS,SACd,GAAG,SAAS,OAAO,UAAiB;AAGnC,UAAI,MAAM,SAAS,UAAU,KAAK,iBAAiB,QAAQ;AACzD,cAAM,YAAY,KAAK,aAAa,MAAM;AAC1C,cAAM,UAAUD,iCAAa,QAAQ;AACrC,YAAI,SAAS;AACX,gBAAMtC,uBAAG,OAAOsC,iCAAa,KAAK,KAAK;AAAA;AAEzC,cAAM,KAAKtC,uBAAG,kBAAkBsC,iCAAa,KAAK,KAAK;AAAA,aAClD;AACL,cAAM;AAAA;AAAA,OAGT;AAEH,WAAO;AAAA;AAAA;;AC/HX,MAAM,WAAWL,eAAUC;4BAKoC;AAAA,EAG7D,YACmB,QACA,SACD,MAChB;AAHiB;AACA;AACD;AALV,gBAAO;AAOb,SAAK,OAAO;AAAA;AAAA,EAIN,WAAW;AACjB,QAAI,KAAK,MAAM;AACb,YAAM,IAAI,MAAM;AAAA;AAElB,SAAK,OAAO;AAAA;AAAA,QAGR,QAAyC;AAC7C,SAAK;AAEL,UAAM,QAAQ;AAEd,aAAS,IAAI,GAAG,IAAI,KAAK,OAAO,QAAQ,KAAK;AAC3C,UAAI,CAAC,KAAK,OAAO,GAAG,KAAK,SAAS,MAAM;AACtC,cAAM,KAAK;AAAA,UACT,MAAM,KAAK,OAAO,GAAG;AAAA,UACrB,SAAS,MAAML,+BAAW,KAAK,OAAO,GAAG;AAAA;AAAA;AAAA;AAK/C,WAAO;AAAA;AAAA,QAGH,UAA0C;AAC9C,UAAM,SAAS,MAAM,KAAK;AAE1B,QAAI;AACF,YAAM,OAAO,MAAM,IAAI,QAAgB,OAAM,YAAW;AACtD,cAAM,SACJO,wBAAI,OAAO,EAAE,KAAK,UAAU,CAAC,MAC7BD,iCAAa;AAAA;AAGjB,aAAOE,gBAAS,KAAK;AAAA,cACrB;AACA,YAAMrC,uBAAG,OAAO;AAAA;AAAA;AAAA,QAId,IAAI,SAAuD;AAxFnE;AAyFI,SAAK;AAEL,UAAM,MACJ,yCAAS,cAAT,YACC,MAAMA,uBAAG,QAAQsC,iCAAa,KAAK,KAAK,SAAS;AAEpD,aAAS,IAAI,GAAG,IAAI,KAAK,OAAO,QAAQ,KAAK;AAC3C,UAAI,CAAC,KAAK,OAAO,GAAG,KAAK,SAAS,MAAM;AACtC,cAAM,SACJ,KAAK,OAAO,GAAG,MACftC,uBAAG,kBACDsC,iCAAa,KAAK,KAAKG,sBAAS,KAAK,OAAO,GAAG;AAAA;AAAA;AAMvD,WAAO;AAAA;AAAA;;qCC9EoE;AAAA,EAQ7E,YAA6B,SAAiB;AAAjB;AAAA;AAAA,SAPtB,OAAO,SAA6D;AA7B7E;AA8BI,WAAO,IAAI,+BACT,cAAQ,OAAO,kBAAkB,gCAAjC,YACEC,uBAAG;AAAA;AAAA,QAMH,eACJ,SAC2B;AAxC/B;AAyCI,WAAO,IAAI,mBACT,QAAQ,QACR,cAAQ,YAAR,YAAmB,IACnB,KAAK,SACL,QAAQ,MACR,QAAQ;AAAA;AAAA,QAIN,eACJ,SAC2B;AApD/B;AAqDI,WAAO,IAAI,mBACT,QAAQ,QACR,cAAQ,YAAR,YAAmB,IACnB,KAAK,SACL,QAAQ,MACR,QAAQ;AAAA;AAAA,QAIN,kBACJ,SAC2B;AAC3B,WAAO,IAAI,sBAAsB,SAAS,KAAK,SAAS;AAAA;AAAA;;AClC5D,MAAM,kBAAkB;AAExB,MAAM,WAAW,CACf,QACkD;AAClD,QAAM,EAAE,MAAM,aAAa,IAAI,IAAI;AAEnC,MAAI,SAAS,iBAAiB;AAC5B,UAAM,IAAI,MAAM,wBAAwB;AAAA;AAG1C,QAAM,GAAG,WAAW,OAAO,SAAS,MAAM;AAC1C,SAAO;AAAA,IACL;AAAA,IACA;AAAA,IACA,KAAK,IAAI,KAAK;AAAA;AAAA;AASX,kCAA8C;AAAA,EA2BnD,YACmB,aACA,SACjB;AAFiB;AACA;AAAA;AAAA,QAGb,KAAK,KAA8B;AACvC,QAAI;AACF,YAAM,EAAE,QAAQ,QAAQ,SAAS;AAEjC,aAAO,MAAMb,+BACX,KAAK,QAAQ,OAAO,QAAQ,KAAK,KAAK;AAAA,aAEjC,OAAP;AACA,YAAM,IAAI,MAAM,gCAAgC,QAAQ;AAAA;AAAA;AAAA,QAItD,QACJ,KACA,UAC0B;AAE1B,UAAM,SAAS,MAAM,KAAK,KAAK;AAC/B,WAAO,EAAE,QAAQ,YAAY;AAAA;AAAA,QAGzB,WAAsC;AAC1C,UAAM,IAAI,MAAM;AAAA;AAAA,QAGZ,SAAkC;AACtC,UAAM,IAAI,MAAM;AAAA;AAAA,EAGlB,WAAW;AACT,UAAM,MAAM,KAAK,YAAY;AAC7B,WAAO,kBAAkB,0BAA0B,QAAQ;AAAA;AAAA;;AA/DxD,mBACE,UAAyB,CAAC,EAAE,QAAQ,aAAa;AACtD,MAAI,CAAC,OAAO,IAAI,2BAA2B;AACzC,WAAO;AAAA;AAET,QAAM,YAAYc,2CAChB,OAAO,UAAU;AAEnB,MAAIC;AACJ,MAAI,CAAC,UAAU,eAAe,CAAC,UAAU,YAAY;AACnD,WAAO,KACL;AAEF,gBAAU,IAAIC;AAAA,SACT;AACL,gBAAU,IAAIA,gBAAQ;AAAA,MACpB,aAAa;AAAA,QACX,cAAc,UAAU,eAAe;AAAA,QACvC,aAAa,UAAU,cAAc;AAAA;AAAA;AAAA;AAI3C,QAAM,SAAS,IAAI,oBAAmB,WAAWD;AACjD,QAAM,YAAY,CAAC,QAAa,IAAI,SAAS;AAC7C,SAAO,CAAC,EAAE,QAAQ;AAAA;;iBC/BE;AAAA,SAIf,OAAO,SAAuC;AACnD,UAAM,EAAE,QAAQ,QAAQ,cAAc;AACtC,UAAM,MAAM,IAAI,sBAAsB;AACtC,UAAM,sBAAsB,+BAA+B,OAAO;AAAA,MAChE;AAAA;AAGF,eAAW,WAAW,gCAAa,IAAI;AACrC,YAAM,SAAS,QAAQ,EAAE,QAAQ,QAAgB;AAEjD,iBAAW,SAAS,QAAQ;AAC1B,YAAI,SAAS;AAAA;AAAA;AAIjB,WAAO;AAAA;AAAA,SASF,QAAQ,SAA4B;AACzC,UAAM,EAAE,QAAQ,QAAQ,YAAY,OAAO;AAC3C,WAAO,WAAW,OAAO;AAAA,MACvB;AAAA,MACA;AAAA,MACA,WAAW,UAAU,OAAO;AAAA,QAC1B,eAAe;AAAA,QACf,mBAAmB;AAAA,QACnB,gBAAgB;AAAA,QAChB,gBAAgB;AAAA,QAChB,mBAAmB;AAAA,QACnB,eAAe;AAAA,QACf,eAAe;AAAA;AAAA;AAAA;AAAA;;AChDhB,mBAAU;AAAA,EACP,YACW,QAKjB;AALiB;AAgLX,kBAAS;AAAO,MACtB,UAAU,KAAK,OAAO;AAAA,MACtB,UAAU,KAAK,OAAO;AAAA;AAGhB,6BAAoB,MAAwB;AAClD,UAAI,eAAe;AAEnB,aAAO,WAAS;AAlOpB;AAmOM,YAAI,iBAAiB,MAAM,OAAO;AAChC,yBAAe,MAAM;AACrB,qBAAK,OAAO,WAAZ,mBAAoB,KAAK,MAAM;AAAA;AAEjC,cAAM,QAAQ,MAAM,QAChB,GAAG,KAAK,MAAO,MAAM,SAAS,MAAM,QAAS,UAC7C,MAAM;AACV,mBAAK,OAAO,WAAZ,mBAAoB,MAAM,WAAW,MAAM,gBAAgB;AAAA;AAAA;AAAA;AAAA,QAzLzD,IAAI,SAA2D;AAjDvE;AAkDI,UAAM,EAAE,KAAK,aAAa;AAC1B,eAAK,OAAO,WAAZ,mBAAoB,KAAK,oBAAoB,gBAAgB;AAE7D,WAAOE,wBAAI,IAAI,MAAE9C,wBAAI,KAAK;AAAA;AAAA,QAGtB,UAAU,SAIE;AA5DpB;AA6DI,UAAM,EAAE,KAAK,KAAK,WAAW;AAC7B,eAAK,OAAO,WAAZ,mBAAoB,KAClB,4BAA4B,cAAc,cAAc;AAE1D,WAAO8C,wBAAI,UAAU,MAAE9C,wBAAI,KAAK,QAAQ;AAAA;AAAA,QAGpC,OAAO,SAKO;AAzEtB;AA0EI,UAAM,EAAE,KAAK,SAAS,QAAQ,cAAc;AAC5C,eAAK,OAAO,WAAZ,mBAAoB,KAClB,gCAAgC,eAAe;AAGjD,WAAO8C,wBAAI,OAAO,MAAE9C,wBAAI,KAAK,SAAS,QAAQ;AAAA;AAAA,QAI1C,MAAM,SAMM;AAzFpB;AA0FI,UAAM,EAAE,KAAK,KAAK,KAAK,OAAO,eAAe;AAC7C,eAAK,OAAO,WAAZ,mBAAoB,KAAK,qBAAqB,WAAW;AACzD,WAAO8C,wBAAI,MAAM;AAAA,UACf9C;AAAA,YACAF;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA,cAAc;AAAA,MACd,OAAO,wBAAS;AAAA,MAChB;AAAA,MACA,YAAY,KAAK;AAAA,MACjB,SAAS;AAAA,QACP,cAAc;AAAA;AAAA,MAEhB,QAAQ,KAAK;AAAA;AAAA;AAAA,QAKX,cAAc,SAGY;AAC9B,UAAM,EAAE,KAAK,WAAW,UAAU;AAClC,WAAOgD,wBAAI,cAAc,MAAE9C,wBAAI,KAAK,UAAU;AAAA;AAAA,QAM1C,MAAM,SAA0D;AAzHxE;AA0HI,UAAM,EAAE,KAAK,SAAS,aAAa;AACnC,eAAK,OAAO,WAAZ,mBAAoB,KAClB,mBAAmB,8BAA8B;AAEnD,UAAM8C,wBAAI,MAAM;AAAA,UACd9C;AAAA,YACAF;AAAA,MACA;AAAA,MACA;AAAA,MACA,YAAY,KAAK;AAAA,MACjB,SAAS,EAAE,cAAc;AAAA,MACzB,QAAQ,KAAK;AAAA;AAAA;AAAA,QAIX,KAAK,SAAiE;AAzI9E;AA0II,UAAM,EAAE,KAAK,gBAAgB,aAAa;AAC1C,eAAK,OAAO,WAAZ,mBAAoB,KAAK,4BAA4B;AAErD,WAAOgD,wBAAI,KAAK;AAAA,UACd9C;AAAA,MACA;AAAA,MACA;AAAA;AAAA;AAAA,QAKE,MAAM,SAMa;AA3J3B;AA4JI,UAAM,EAAE,KAAK,QAAQ,MAAM,QAAQ,cAAc;AACjD,eAAK,OAAO,WAAZ,mBAAoB,KAClB,mBAAmB,iBAAiB,6BAA6B;AAInE,WAAO8C,wBAAI,MAAM;AAAA,UACf9C;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA;AAAA;AAAA,QAIE,KAAK,SAA0C;AA5KvD;AA6KI,UAAM,EAAE,KAAK,WAAW;AACxB,eAAK,OAAO,WAAZ,mBAAoB,KAClB,oCAAoC,cAAc;AAEpD,WAAO8C,wBAAI,KAAK;AAAA,UACd9C;AAAA,MACA;AAAA,YACAF;AAAA,MACA,YAAY,KAAK;AAAA,MACjB,SAAS;AAAA,QACP,cAAc;AAAA;AAAA,MAEhB;AAAA,MACA,QAAQ,KAAK;AAAA;AAAA;AAAA,QAKX,WAAW,SAGa;AAC5B,UAAM,EAAE,KAAK,QAAQ;AACrB,WAAOgD,wBAAI,WAAW,MAAE9C,wBAAI,KAAK,KAAK;AAAA;AAAA,QAIlC,WAAW,SAAwD;AACvE,UAAM,EAAE,KAAK,QAAQ;AACrB,WAAO8C,wBAAI,WAAW,MAAE9C,wBAAI,KAAK;AAAA;AAAA,QAI7B,IAAI,SAGsB;AAC9B,UAAM,EAAE,KAAK,QAAQ;AACrB,WAAO8C,wBAAI,IAAI;AAAA,UACb9C;AAAA,MACA;AAAA,MACA,KAAK,oBAAO;AAAA;AAAA;AAAA;;AAwBT,IAAA,WAAW,CAAC,YAIb;AACJ,QAAM,EAAE,UAAU,UAAU,WAAW;AACvC,SAAO,IAAI,KAAI,EAAE,UAAU,UAAU;AAAA;;8BC5NJ,SAAqC;AACxE,SAAO,IAAI,mBAAmB;AAAA;;uCCQc,SAclB;AAC1B,QAAM,SAAS+C;AACf,QAAM,EAAE,OAAO,gBAAgB,gBAAgB;AAE/C,SAAO,IAAI,MAAM,MAAM,mBAAmB,EAAE;AAC5C,SAAO,IAAI;AAEX,SAAO;AAAA;;AChCT,uBAA+C;AAAA,EAA/C,cAtBA;AAuBkB,wCAAwC;AAAA;AAAA,QAElD,WAAW;AACf,WAAO,EAAE,OAAO;AAAA;AAAA,QAGZ,eAAe;AAAA;AAAA;yBASiC;AAAA,SAI/C,OAAqB;AAC1B,WAAO,IAAI;AAAA;AAAA,SAGN,WAAW,QAAgB,SAA6B;AAC7D,UAAM,EAAE,WAAW;AAEnB,UAAM,OAAO,OAAO,uBAAuB;AAC3C,QAAI,6BAAM,QAAQ;AAChB,aAAO,IAAI,mBAAmB,KAAK,IAAI,SAAO,IAAI,UAAU;AAAA;AAE9D,QAAI,QAAQ,IAAI,aAAa,eAAe;AAC1C,YAAM,IAAI,MACR;AAAA;AAKJ,UAAM,sBAAsBC,SAAI,aAAa,OAAO,KAAK;AACzD,QAAI,oBAAoB,MAAM,QAAW;AACvC,YAAM,IAAI,MAAM;AAAA;AAElB,WAAO,KACL;AAEF,WAAO,IAAI,mBAAmB,CAAC,oBAAoB;AAAA;AAAA,EAG7C,YAAY,SAAmB;AACrC,QAAI,CAAC,QAAQ,QAAQ;AACnB,YAAM,IAAI,MACR;AAAA;AAIJ,SAAK,mBAAmB,IAAIC,UAAK,SAC/B,QAAQ,IAAI,OAAKD,SAAI,MAAM,EAAE,KAAK,OAAO;AAE3C,SAAK,aAAa,KAAK,iBAAiB,MAAM;AAAA;AAAA,QAG1C,WAAuC;AAC3C,UAAM,MAAME,SAAI,KAAK,EAAE,KAAK,sBAAsB,KAAK,YAAY;AAAA,MACjE,WAAW;AAAA;AAGb,WAAO,EAAE,OAAO;AAAA;AAAA,QAGZ,aAAa,OAA8B;AAC/C,QAAI;AACF,eAAI,OAAO,OAAO,KAAK;AAAA,aAChB,GAAP;AACA,YAAM,IAAIzD,2BAAoB;AAAA;AAAA;AAAA;;4BChE0B;AAAA,EAG5D,YAAY,SAAmC;AAC7C,SAAK,eAAe,QAAQ;AAAA;AAAA,QAGxB,aAAa,SAA8B;AAC/C,UAAM;AAAA,MACJ;AAAA,MACA;AAAA,MACA;AAAA,MACA,YAAY,IAAIvB;AAAA,MAChB,YAAY;AAAA,MACZ;AAAA,MACA,UAAU;AAAA,MACV,YAAY;AAAA,QACV;AAGJ,QAAI;AACF,YAAM,KAAK,aAAa;AAAA,aACjB,GAAP;AACA,YAAM,IAAIiB,sBACR,qGACA;AAAA;AAIJ,QAAI,WAAW;AACb,YAAM,IAAI,QAAc,CAAC,SAAS,WAAW;AAC3C,aAAK,aAAa,KAAK,WAAW,IAAI,CAAC,KAAK,WAAW;AACrD,cAAI;AAAK,mBAAO,OAAO;AACvB,iBAAO,KAAK,WAAW,EAAE,KAAK;AAC9B,iBAAO,GAAG,OAAO,MAAM;AACvB,iBAAO,GAAG,SAAS,CAAC,WAAiB,OAAO;AAC5C,iBAAO;AAAA;AAAA;AAAA;AAKb,UAAM,cAA2B;AACjC,QAAI,QAAQ,UAAU,QAAQ,QAAQ;AAMpC,kBAAY,OAAO,GAAG,QAAQ,YAAY,QAAQ;AAAA;AAIpD,UAAM,UAAmC;AACzC,eAAW,gBAAgB,OAAO,OAAO,YAAY;AACnD,cAAQ,gBAAgB;AAAA;AAI1B,UAAM,QAAkB;AACxB,eAAW,CAAC,SAAS,iBAAiB,OAAO,QAAQ,YAAY;AAG/D,YAAM,cAAc,MAAMa,uBAAG,SAAS;AACtC,YAAM,KAAK,GAAG,eAAe;AAAA;AAI/B,UAAM,MAAM;AACZ,eAAW,CAAC,KAAK,UAAU,OAAO,QAAQ,UAAU;AAClD,UAAI,KAAK,GAAG,OAAO;AAAA;AAGrB,UAAM,CAAC,EAAE,OAAO,OAAO,YAAY,gBACjC,MAAM,KAAK,aAAa,IAAI,WAAW,MAAM,WAAW;AAAA,MACtD;AAAA,MACA,YAAY;AAAA,QACV,YAAY;AAAA,QACZ;AAAA;AAAA,SAEE,aAAa,EAAE,YAAY,eAAe;AAAA,MAC9C,YAAY;AAAA,MACZ;AAAA,SACG;AAAA;AAGP,QAAI,OAAO;AACT,YAAM,IAAI,MACR,0DAA0D;AAAA;AAI9D,QAAI,eAAe,GAAG;AACpB,YAAM,IAAI,MACR,mDAAmD;AAAA;AAAA;AAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;"}