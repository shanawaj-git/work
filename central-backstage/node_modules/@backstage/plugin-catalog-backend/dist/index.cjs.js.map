{"version":3,"file":"index.cjs.js","sources":["../src/api/deprecatedResult.ts","../src/api/processingResult.ts","../src/ingestion/CatalogRules.ts","../src/modules/codeowners/lib/resolve.ts","../src/modules/codeowners/lib/scm.ts","../src/modules/codeowners/lib/read.ts","../src/modules/codeowners/CodeOwnersProcessor.ts","../src/modules/core/AnnotateLocationEntityProcessor.ts","../src/modules/core/AnnotateScmSlugEntityProcessor.ts","../src/modules/core/BuiltinKindsEntityProcessor.ts","../src/modules/core/FileReaderProcessor.ts","../src/modules/core/LocationEntityProcessor.ts","../src/modules/core/PlaceholderProcessor.ts","../src/modules/core/UrlReaderProcessor.ts","../src/modules/util/parse.ts","../src/search/DefaultCatalogCollatorFactory.ts","../src/search/DefaultCatalogCollator.ts","../src/util/conversion.ts","../src/processing/util.ts","../src/processing/ProcessorOutputCollector.ts","../src/processing/ProcessorCacheManager.ts","../src/processing/DefaultCatalogProcessingOrchestrator.ts","../src/processing/refresh.ts","../src/service/request/basicEntityFilter.ts","../src/service/request/common.ts","../src/service/request/parseEntityFilterParams.ts","../src/service/request/parseEntityPaginationParams.ts","../src/service/request/parseEntityTransformParams.ts","../src/service/util.ts","../src/service/request/parseEntityFacetParams.ts","../src/service/createRouter.ts","../src/modules/core/ConfigLocationEntityProvider.ts","../src/modules/core/DefaultLocationStore.ts","../src/ingestion/LocationAnalyzer.ts","../src/database/conversion.ts","../src/util/metrics.ts","../src/database/metrics.ts","../src/database/util.ts","../src/database/DefaultProcessingDatabase.ts","../src/database/migrations.ts","../src/processing/TaskPipeline.ts","../src/processing/DefaultCatalogProcessingEngine.ts","../src/service/DefaultLocationService.ts","../src/service/DefaultEntitiesCatalog.ts","../src/stitching/buildEntitySearch.ts","../src/stitching/util.ts","../src/stitching/Stitcher.ts","../src/service/DefaultRefreshService.ts","../src/service/AuthorizedRefreshService.ts","../src/processing/connectEntityProviders.ts","../src/permissions/rules/util.ts","../src/permissions/rules/hasAnnotation.ts","../src/permissions/rules/isEntityKind.ts","../src/permissions/rules/isEntityOwner.ts","../src/permissions/rules/hasLabel.ts","../src/permissions/rules/createPropertyRule.ts","../src/permissions/rules/hasMetadata.ts","../src/permissions/rules/hasSpec.ts","../src/permissions/rules/index.ts","../src/service/AuthorizedEntitiesCatalog.ts","../src/service/AuthorizedLocationService.ts","../src/service/CatalogBuilder.ts","../src/permissions/conditionExports.ts"],"sourcesContent":["/*\n * Copyright 2020 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { InputError, NotFoundError } from '@backstage/errors';\nimport { Entity } from '@backstage/catalog-model';\nimport { CatalogProcessorResult } from './processor';\nimport { EntityRelationSpec, LocationSpec } from './common';\n\n// NOTE: This entire file is deprecated and should be eventually removed along with the `result` export\n\n/**\n * @public\n * @deprecated import the processingResult symbol instead and use its fields\n */\nexport function notFoundError(\n  atLocation: LocationSpec,\n  message: string,\n): CatalogProcessorResult {\n  return {\n    type: 'error',\n    location: atLocation,\n    error: new NotFoundError(message),\n  };\n}\n\n/**\n * @public\n * @deprecated import the processingResult symbol instead and use its fields\n */\nexport function inputError(\n  atLocation: LocationSpec,\n  message: string,\n): CatalogProcessorResult {\n  return {\n    type: 'error',\n    location: atLocation,\n    error: new InputError(message),\n  };\n}\n\n/**\n * @public\n * @deprecated import the processingResult symbol instead and use its fields\n */\nexport function generalError(\n  atLocation: LocationSpec,\n  message: string,\n): CatalogProcessorResult {\n  return { type: 'error', location: atLocation, error: new Error(message) };\n}\n\n/**\n * @public\n * @deprecated import the processingResult symbol instead and use its fields\n */\nexport function location(\n  newLocation: LocationSpec,\n  _optional?: boolean,\n): CatalogProcessorResult {\n  return { type: 'location', location: newLocation };\n}\n\n/**\n * @public\n * @deprecated import the processingResult symbol instead and use its fields\n */\nexport function entity(\n  atLocation: LocationSpec,\n  newEntity: Entity,\n): CatalogProcessorResult {\n  return { type: 'entity', location: atLocation, entity: newEntity };\n}\n\n/**\n * @public\n * @deprecated import the processingResult symbol instead and use its fields\n */\nexport function relation(spec: EntityRelationSpec): CatalogProcessorResult {\n  return { type: 'relation', relation: spec };\n}\n","/*\n * Copyright 2020 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { InputError, NotFoundError } from '@backstage/errors';\nimport { Entity } from '@backstage/catalog-model';\nimport { CatalogProcessorResult } from './processor';\nimport { EntityRelationSpec, LocationSpec } from './common';\n\n/**\n * Factory functions for the standard processing result types.\n *\n * @public\n */\nexport const processingResult = Object.freeze({\n  notFoundError(\n    atLocation: LocationSpec,\n    message: string,\n  ): CatalogProcessorResult {\n    return {\n      type: 'error',\n      location: atLocation,\n      error: new NotFoundError(message),\n    };\n  },\n\n  inputError(\n    atLocation: LocationSpec,\n    message: string,\n  ): CatalogProcessorResult {\n    return {\n      type: 'error',\n      location: atLocation,\n      error: new InputError(message),\n    };\n  },\n\n  generalError(\n    atLocation: LocationSpec,\n    message: string,\n  ): CatalogProcessorResult {\n    return { type: 'error', location: atLocation, error: new Error(message) };\n  },\n\n  location(newLocation: LocationSpec): CatalogProcessorResult {\n    return { type: 'location', location: newLocation };\n  },\n\n  entity(atLocation: LocationSpec, newEntity: Entity): CatalogProcessorResult {\n    return { type: 'entity', location: atLocation, entity: newEntity };\n  },\n\n  relation(spec: EntityRelationSpec): CatalogProcessorResult {\n    return { type: 'relation', relation: spec };\n  },\n} as const);\n","/*\n * Copyright 2020 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Config } from '@backstage/config';\nimport { Entity } from '@backstage/catalog-model';\nimport path from 'path';\nimport { LocationSpec } from '../api';\n\n/**\n * Rules to apply to catalog entities.\n *\n * An undefined list of matchers means match all, an empty list of matchers means match none.\n *\n * @public\n */\nexport type CatalogRule = {\n  allow: Array<{\n    kind: string;\n  }>;\n  locations?: Array<{\n    target?: string;\n    type: string;\n  }>;\n};\n\n/**\n * Decides whether an entity from a given location is allowed to enter the\n * catalog, according to some rule set.\n *\n * @public\n */\nexport type CatalogRulesEnforcer = {\n  isAllowed(entity: Entity, location: LocationSpec): boolean;\n};\n\n/**\n * Implements the default catalog rule set, consuming the config keys\n * `catalog.rules` and `catalog.locations.[].rules`.\n *\n * @public\n */\nexport class DefaultCatalogRulesEnforcer implements CatalogRulesEnforcer {\n  /**\n   * Default rules used by the catalog.\n   *\n   * Denies any location from specifying user or group entities.\n   */\n  static readonly defaultRules: CatalogRule[] = [\n    {\n      allow: ['Component', 'API', 'Location'].map(kind => ({ kind })),\n    },\n  ];\n\n  /**\n   * Loads catalog rules from config.\n   *\n   * This reads `catalog.rules` and defaults to the default rules if no value is present.\n   * The value of the config should be a list of config objects, each with a single `allow`\n   * field which in turn is a list of entity kinds to allow.\n   *\n   * If there is no matching rule to allow an ingested entity, it will be rejected by the catalog.\n   *\n   * It also reads in rules from `catalog.locations`, where each location can have a list\n   * of rules for that specific location, specified in a `rules` field.\n   *\n   * For example:\n   *\n   * ```yaml\n   * catalog:\n   *   rules:\n   *   - allow: [Component, API]\n   *\n   *   locations:\n   *   - type: url\n   *     target: https://github.com/org/repo/blob/master/users.yaml\n   *     rules:\n   *       - allow: [User, Group]\n   *   - type: url\n   *     target: https://github.com/org/repo/blob/master/systems.yaml\n   *     rules:\n   *       - allow: [System]\n   * ```\n   */\n  static fromConfig(config: Config) {\n    const rules = new Array<CatalogRule>();\n\n    if (config.has('catalog.rules')) {\n      const globalRules = config.getConfigArray('catalog.rules').map(sub => ({\n        allow: sub.getStringArray('allow').map(kind => ({ kind })),\n      }));\n      rules.push(...globalRules);\n    } else {\n      rules.push(...DefaultCatalogRulesEnforcer.defaultRules);\n    }\n\n    if (config.has('catalog.locations')) {\n      const locationRules = config\n        .getConfigArray('catalog.locations')\n        .flatMap(locConf => {\n          if (!locConf.has('rules')) {\n            return [];\n          }\n          const type = locConf.getString('type');\n          const target = resolveTarget(type, locConf.getString('target'));\n\n          return locConf.getConfigArray('rules').map(ruleConf => ({\n            allow: ruleConf.getStringArray('allow').map(kind => ({ kind })),\n            locations: [{ type, target }],\n          }));\n        });\n\n      rules.push(...locationRules);\n    }\n\n    return new DefaultCatalogRulesEnforcer(rules);\n  }\n\n  constructor(private readonly rules: CatalogRule[]) {}\n\n  /**\n   * Checks wether a specific entity/location combination is allowed\n   * according to the configured rules.\n   */\n  isAllowed(entity: Entity, location: LocationSpec) {\n    for (const rule of this.rules) {\n      if (!this.matchLocation(location, rule.locations)) {\n        continue;\n      }\n\n      if (this.matchEntity(entity, rule.allow)) {\n        return true;\n      }\n    }\n\n    return false;\n  }\n\n  private matchLocation(\n    location: LocationSpec,\n    matchers?: { target?: string; type: string }[],\n  ): boolean {\n    if (!matchers) {\n      return true;\n    }\n\n    for (const matcher of matchers) {\n      if (matcher.type !== location?.type) {\n        continue;\n      }\n      if (matcher.target && matcher.target !== location?.target) {\n        continue;\n      }\n      return true;\n    }\n\n    return false;\n  }\n\n  private matchEntity(entity: Entity, matchers?: { kind: string }[]): boolean {\n    if (!matchers) {\n      return true;\n    }\n\n    for (const matcher of matchers) {\n      if (entity?.kind?.toLowerCase() !== matcher.kind.toLowerCase()) {\n        continue;\n      }\n\n      return true;\n    }\n\n    return false;\n  }\n}\n\nfunction resolveTarget(type: string, target: string): string {\n  if (type !== 'file') {\n    return target;\n  }\n\n  return path.resolve(target);\n}\n","/*\n * Copyright 2020 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport * as codeowners from 'codeowners-utils';\nimport { CodeOwnersEntry } from 'codeowners-utils';\nimport { filter, get, head, pipe, reverse } from 'lodash/fp';\n\nconst USER_PATTERN = /^@.*/;\nconst GROUP_PATTERN = /^@.*\\/.*/;\nconst EMAIL_PATTERN = /^.*@.*\\..*$/;\n\nexport function resolveCodeOwner(\n  contents: string,\n  pattern = '*',\n): string | undefined {\n  const owners = codeowners.parse(contents);\n\n  return pipe(\n    filter((e: CodeOwnersEntry) => e.pattern === pattern),\n    reverse,\n    head,\n    get('owners'),\n    head,\n    normalizeCodeOwner,\n  )(owners);\n}\n\nexport function normalizeCodeOwner(owner: string) {\n  if (owner.match(GROUP_PATTERN)) {\n    return owner.split('/')[1];\n  } else if (owner.match(USER_PATTERN)) {\n    return `User:${owner.substring(1)}`;\n  } else if (owner.match(EMAIL_PATTERN)) {\n    return owner.split('@')[0];\n  }\n\n  return owner;\n}\n","/*\n * Copyright 2020 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nconst CODEOWNERS = 'CODEOWNERS';\n\nexport const scmCodeOwnersPaths: Record<string, string[]> = {\n  // https://mibexsoftware.atlassian.net/wiki/spaces/CODEOWNERS/pages/222822413/Usage\n  bitbucket: [CODEOWNERS, `.bitbucket/${CODEOWNERS}`],\n\n  // https://docs.gitlab.com/ee/user/project/code_owners.html#how-to-set-up-code-owners\n  gitlab: [CODEOWNERS, `.gitlab/${CODEOWNERS}`, `docs/${CODEOWNERS}`],\n\n  // https://docs.github.com/en/github/creating-cloning-and-archiving-repositories/about-code-owners#codeowners-file-location\n  github: [CODEOWNERS, `.github/${CODEOWNERS}`, `docs/${CODEOWNERS}`],\n};\n","/*\n * Copyright 2020 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { UrlReader } from '@backstage/backend-common';\nimport { NotFoundError } from '@backstage/errors';\nimport { ScmIntegration } from '@backstage/integration';\nimport 'core-js/features/promise'; // NOTE: This can be removed when ES2021 is implemented\nimport { resolveCodeOwner } from './resolve';\nimport { scmCodeOwnersPaths } from './scm';\n\nexport async function readCodeOwners(\n  reader: UrlReader,\n  sourceUrl: string,\n  codeownersPaths: string[],\n): Promise<string | undefined> {\n  const readOwnerLocation = async (path: string): Promise<string> => {\n    const url = `${sourceUrl}${path}`;\n\n    if (reader.readUrl) {\n      const data = await reader.readUrl(url);\n      const buffer = await data.buffer();\n      return buffer.toString();\n    }\n    const data = await reader.read(url);\n    return data.toString();\n  };\n\n  const candidates = codeownersPaths.map(readOwnerLocation);\n\n  return Promise.any(candidates).catch((aggregateError: AggregateError) => {\n    const hardError = aggregateError.errors.find(\n      error => !(error instanceof NotFoundError),\n    );\n\n    if (hardError) {\n      throw hardError;\n    }\n\n    return undefined;\n  });\n}\n\nexport async function findCodeOwnerByTarget(\n  reader: UrlReader,\n  targetUrl: string,\n  scmIntegration: ScmIntegration,\n): Promise<string | undefined> {\n  const codeownersPaths = scmCodeOwnersPaths[scmIntegration?.type ?? ''];\n\n  const sourceUrl = scmIntegration?.resolveUrl({\n    url: '/',\n    base: targetUrl,\n  });\n\n  if (!sourceUrl || !codeownersPaths) {\n    return undefined;\n  }\n\n  const contents = await readCodeOwners(reader, sourceUrl, codeownersPaths);\n\n  if (!contents) {\n    return undefined;\n  }\n\n  const owner = resolveCodeOwner(contents);\n\n  return owner;\n}\n","/*\n * Copyright 2020 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { UrlReader } from '@backstage/backend-common';\nimport { Entity } from '@backstage/catalog-model';\nimport { Config } from '@backstage/config';\nimport {\n  ScmIntegrationRegistry,\n  ScmIntegrations,\n} from '@backstage/integration';\nimport { Logger } from 'winston';\nimport { CatalogProcessor, LocationSpec } from '../../api';\nimport { findCodeOwnerByTarget } from './lib';\n\nconst ALLOWED_KINDS = ['API', 'Component', 'Domain', 'Resource', 'System'];\nconst ALLOWED_LOCATION_TYPES = ['url'];\n\n/** @public */\nexport class CodeOwnersProcessor implements CatalogProcessor {\n  private readonly integrations: ScmIntegrationRegistry;\n  private readonly logger: Logger;\n  private readonly reader: UrlReader;\n\n  static fromConfig(\n    config: Config,\n    options: { logger: Logger; reader: UrlReader },\n  ) {\n    const integrations = ScmIntegrations.fromConfig(config);\n\n    return new CodeOwnersProcessor({\n      ...options,\n      integrations,\n    });\n  }\n\n  constructor(options: {\n    integrations: ScmIntegrationRegistry;\n    logger: Logger;\n    reader: UrlReader;\n  }) {\n    this.integrations = options.integrations;\n    this.logger = options.logger;\n    this.reader = options.reader;\n  }\n\n  getProcessorName(): string {\n    return 'CodeOwnersProcessor';\n  }\n\n  async preProcessEntity(\n    entity: Entity,\n    location: LocationSpec,\n  ): Promise<Entity> {\n    // Only continue if the owner is not set\n    if (\n      !entity ||\n      !ALLOWED_KINDS.includes(entity.kind) ||\n      !ALLOWED_LOCATION_TYPES.includes(location.type) ||\n      (entity.spec && entity.spec.owner)\n    ) {\n      return entity;\n    }\n\n    const scmIntegration = this.integrations.byUrl(location.target);\n    if (!scmIntegration) {\n      return entity;\n    }\n\n    const owner = await findCodeOwnerByTarget(\n      this.reader,\n      location.target,\n      scmIntegration,\n    );\n\n    if (!owner) {\n      this.logger.debug(\n        `CodeOwnerProcessor could not resolve owner for ${location.target}`,\n      );\n      return entity;\n    }\n\n    return {\n      ...entity,\n      spec: { ...entity.spec, owner },\n    };\n  }\n}\n","/*\n * Copyright 2020 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  ANNOTATION_EDIT_URL,\n  ANNOTATION_LOCATION,\n  ANNOTATION_ORIGIN_LOCATION,\n  ANNOTATION_SOURCE_LOCATION,\n  ANNOTATION_VIEW_URL,\n  Entity,\n  stringifyLocationRef,\n} from '@backstage/catalog-model';\nimport { ScmIntegrationRegistry } from '@backstage/integration';\nimport { identity, merge, pickBy } from 'lodash';\nimport {\n  CatalogProcessor,\n  CatalogProcessorEmit,\n  LocationSpec,\n} from '../../api';\n\n/** @public */\nexport class AnnotateLocationEntityProcessor implements CatalogProcessor {\n  constructor(\n    private readonly options: {\n      integrations: ScmIntegrationRegistry;\n    },\n  ) {}\n\n  getProcessorName(): string {\n    return 'AnnotateLocationEntityProcessor';\n  }\n\n  async preProcessEntity(\n    entity: Entity,\n    location: LocationSpec,\n    _: CatalogProcessorEmit,\n    originLocation: LocationSpec,\n  ): Promise<Entity> {\n    const { integrations } = this.options;\n    let viewUrl;\n    let editUrl;\n    let sourceLocation;\n\n    if (location.type === 'url') {\n      const scmIntegration = integrations.byUrl(location.target);\n\n      viewUrl = location.target;\n      editUrl = scmIntegration?.resolveEditUrl(location.target);\n\n      const sourceUrl = scmIntegration?.resolveUrl({\n        url: './',\n        base: location.target,\n      });\n\n      if (sourceUrl) {\n        sourceLocation = stringifyLocationRef({\n          type: 'url',\n          target: sourceUrl,\n        });\n      }\n    }\n\n    return merge(\n      {\n        metadata: {\n          annotations: pickBy(\n            {\n              [ANNOTATION_LOCATION]: stringifyLocationRef(location),\n              [ANNOTATION_ORIGIN_LOCATION]:\n                stringifyLocationRef(originLocation),\n              [ANNOTATION_VIEW_URL]: viewUrl,\n              [ANNOTATION_EDIT_URL]: editUrl,\n              [ANNOTATION_SOURCE_LOCATION]: sourceLocation,\n            },\n            identity,\n          ),\n        },\n      },\n      entity,\n    );\n  }\n}\n","/*\n * Copyright 2021 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nimport { Entity } from '@backstage/catalog-model';\nimport { Config } from '@backstage/config';\nimport {\n  ScmIntegrationRegistry,\n  ScmIntegrations,\n} from '@backstage/integration';\nimport parseGitUrl from 'git-url-parse';\nimport { identity, merge, pickBy } from 'lodash';\nimport { CatalogProcessor, LocationSpec } from '../../api';\n\nconst GITHUB_ACTIONS_ANNOTATION = 'github.com/project-slug';\n\n/** @public */\nexport class AnnotateScmSlugEntityProcessor implements CatalogProcessor {\n  constructor(\n    private readonly opts: { scmIntegrationRegistry: ScmIntegrationRegistry },\n  ) {}\n\n  getProcessorName(): string {\n    return 'AnnotateScmSlugEntityProcessor';\n  }\n\n  static fromConfig(config: Config): AnnotateScmSlugEntityProcessor {\n    return new AnnotateScmSlugEntityProcessor({\n      scmIntegrationRegistry: ScmIntegrations.fromConfig(config),\n    });\n  }\n\n  async preProcessEntity(\n    entity: Entity,\n    location: LocationSpec,\n  ): Promise<Entity> {\n    if (entity.kind !== 'Component' || location.type !== 'url') {\n      return entity;\n    }\n\n    const scmIntegration = this.opts.scmIntegrationRegistry.byUrl(\n      location.target,\n    );\n\n    if (!scmIntegration || scmIntegration.type !== 'github') {\n      return entity;\n    }\n\n    const gitUrl = parseGitUrl(location.target);\n    let githubProjectSlug =\n      entity.metadata.annotations?.[GITHUB_ACTIONS_ANNOTATION];\n\n    if (!githubProjectSlug) {\n      githubProjectSlug = `${gitUrl.owner}/${gitUrl.name}`;\n    }\n\n    return merge(\n      {\n        metadata: {\n          annotations: pickBy(\n            {\n              [GITHUB_ACTIONS_ANNOTATION]: githubProjectSlug,\n            },\n            identity,\n          ),\n        },\n      },\n      entity,\n    );\n  }\n}\n","/*\n * Copyright 2020 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  ApiEntity,\n  apiEntityV1alpha1Validator,\n  ComponentEntity,\n  componentEntityV1alpha1Validator,\n  DomainEntity,\n  domainEntityV1alpha1Validator,\n  Entity,\n  getCompoundEntityRef,\n  GroupEntity,\n  groupEntityV1alpha1Validator,\n  locationEntityV1alpha1Validator,\n  parseEntityRef,\n  RELATION_API_CONSUMED_BY,\n  RELATION_API_PROVIDED_BY,\n  RELATION_CHILD_OF,\n  RELATION_CONSUMES_API,\n  RELATION_DEPENDENCY_OF,\n  RELATION_DEPENDS_ON,\n  RELATION_HAS_MEMBER,\n  RELATION_HAS_PART,\n  RELATION_MEMBER_OF,\n  RELATION_OWNED_BY,\n  RELATION_OWNER_OF,\n  RELATION_PARENT_OF,\n  RELATION_PART_OF,\n  RELATION_PROVIDES_API,\n  ResourceEntity,\n  resourceEntityV1alpha1Validator,\n  SystemEntity,\n  systemEntityV1alpha1Validator,\n  UserEntity,\n  userEntityV1alpha1Validator,\n} from '@backstage/catalog-model';\nimport {\n  CatalogProcessor,\n  CatalogProcessorEmit,\n  LocationSpec,\n  processingResult,\n} from '../../api';\n\n/** @public */\nexport class BuiltinKindsEntityProcessor implements CatalogProcessor {\n  private readonly validators = [\n    apiEntityV1alpha1Validator,\n    componentEntityV1alpha1Validator,\n    resourceEntityV1alpha1Validator,\n    groupEntityV1alpha1Validator,\n    locationEntityV1alpha1Validator,\n    userEntityV1alpha1Validator,\n    systemEntityV1alpha1Validator,\n    domainEntityV1alpha1Validator,\n  ];\n\n  getProcessorName(): string {\n    return 'BuiltinKindsEntityProcessor';\n  }\n\n  async validateEntityKind(entity: Entity): Promise<boolean> {\n    for (const validator of this.validators) {\n      const results = await validator.check(entity);\n      if (results) {\n        return true;\n      }\n    }\n\n    return false;\n  }\n\n  async postProcessEntity(\n    entity: Entity,\n    _location: LocationSpec,\n    emit: CatalogProcessorEmit,\n  ): Promise<Entity> {\n    const selfRef = getCompoundEntityRef(entity);\n\n    /*\n     * Utilities\n     */\n\n    function doEmit(\n      targets: string | string[] | undefined,\n      context: { defaultKind?: string; defaultNamespace: string },\n      outgoingRelation: string,\n      incomingRelation: string,\n    ): void {\n      if (!targets) {\n        return;\n      }\n      for (const target of [targets].flat()) {\n        const targetRef = parseEntityRef(target, context);\n        emit(\n          processingResult.relation({\n            source: selfRef,\n            type: outgoingRelation,\n            target: {\n              kind: targetRef.kind,\n              namespace: targetRef.namespace,\n              name: targetRef.name,\n            },\n          }),\n        );\n        emit(\n          processingResult.relation({\n            source: {\n              kind: targetRef.kind,\n              namespace: targetRef.namespace,\n              name: targetRef.name,\n            },\n            type: incomingRelation,\n            target: selfRef,\n          }),\n        );\n      }\n    }\n\n    /*\n     * Emit relations for the Component kind\n     */\n\n    if (entity.kind === 'Component') {\n      const component = entity as ComponentEntity;\n      doEmit(\n        component.spec.owner,\n        { defaultKind: 'Group', defaultNamespace: selfRef.namespace },\n        RELATION_OWNED_BY,\n        RELATION_OWNER_OF,\n      );\n      doEmit(\n        component.spec.subcomponentOf,\n        { defaultKind: 'Component', defaultNamespace: selfRef.namespace },\n        RELATION_PART_OF,\n        RELATION_HAS_PART,\n      );\n      doEmit(\n        component.spec.providesApis,\n        { defaultKind: 'API', defaultNamespace: selfRef.namespace },\n        RELATION_PROVIDES_API,\n        RELATION_API_PROVIDED_BY,\n      );\n      doEmit(\n        component.spec.consumesApis,\n        { defaultKind: 'API', defaultNamespace: selfRef.namespace },\n        RELATION_CONSUMES_API,\n        RELATION_API_CONSUMED_BY,\n      );\n      doEmit(\n        component.spec.dependsOn,\n        { defaultNamespace: selfRef.namespace },\n        RELATION_DEPENDS_ON,\n        RELATION_DEPENDENCY_OF,\n      );\n      doEmit(\n        component.spec.system,\n        { defaultKind: 'System', defaultNamespace: selfRef.namespace },\n        RELATION_PART_OF,\n        RELATION_HAS_PART,\n      );\n    }\n\n    /*\n     * Emit relations for the API kind\n     */\n\n    if (entity.kind === 'API') {\n      const api = entity as ApiEntity;\n      doEmit(\n        api.spec.owner,\n        { defaultKind: 'Group', defaultNamespace: selfRef.namespace },\n        RELATION_OWNED_BY,\n        RELATION_OWNER_OF,\n      );\n      doEmit(\n        api.spec.system,\n        { defaultKind: 'System', defaultNamespace: selfRef.namespace },\n        RELATION_PART_OF,\n        RELATION_HAS_PART,\n      );\n    }\n\n    /*\n     * Emit relations for the Resource kind\n     */\n\n    if (entity.kind === 'Resource') {\n      const resource = entity as ResourceEntity;\n      doEmit(\n        resource.spec.owner,\n        { defaultKind: 'Group', defaultNamespace: selfRef.namespace },\n        RELATION_OWNED_BY,\n        RELATION_OWNER_OF,\n      );\n      doEmit(\n        resource.spec.dependsOn,\n        { defaultNamespace: selfRef.namespace },\n        RELATION_DEPENDS_ON,\n        RELATION_DEPENDENCY_OF,\n      );\n      doEmit(\n        resource.spec.dependencyOf,\n        { defaultNamespace: selfRef.namespace },\n        RELATION_DEPENDENCY_OF,\n        RELATION_DEPENDS_ON,\n      );\n      doEmit(\n        resource.spec.system,\n        { defaultKind: 'System', defaultNamespace: selfRef.namespace },\n        RELATION_PART_OF,\n        RELATION_HAS_PART,\n      );\n    }\n\n    /*\n     * Emit relations for the User kind\n     */\n\n    if (entity.kind === 'User') {\n      const user = entity as UserEntity;\n      doEmit(\n        user.spec.memberOf,\n        { defaultKind: 'Group', defaultNamespace: selfRef.namespace },\n        RELATION_MEMBER_OF,\n        RELATION_HAS_MEMBER,\n      );\n    }\n\n    /*\n     * Emit relations for the Group kind\n     */\n\n    if (entity.kind === 'Group') {\n      const group = entity as GroupEntity;\n      doEmit(\n        group.spec.parent,\n        { defaultKind: 'Group', defaultNamespace: selfRef.namespace },\n        RELATION_CHILD_OF,\n        RELATION_PARENT_OF,\n      );\n      doEmit(\n        group.spec.children,\n        { defaultKind: 'Group', defaultNamespace: selfRef.namespace },\n        RELATION_PARENT_OF,\n        RELATION_CHILD_OF,\n      );\n      doEmit(\n        group.spec.members,\n        { defaultKind: 'User', defaultNamespace: selfRef.namespace },\n        RELATION_HAS_MEMBER,\n        RELATION_MEMBER_OF,\n      );\n    }\n\n    /*\n     * Emit relations for the System kind\n     */\n\n    if (entity.kind === 'System') {\n      const system = entity as SystemEntity;\n      doEmit(\n        system.spec.owner,\n        { defaultKind: 'Group', defaultNamespace: selfRef.namespace },\n        RELATION_OWNED_BY,\n        RELATION_OWNER_OF,\n      );\n      doEmit(\n        system.spec.domain,\n        { defaultKind: 'Domain', defaultNamespace: selfRef.namespace },\n        RELATION_PART_OF,\n        RELATION_HAS_PART,\n      );\n    }\n\n    /*\n     * Emit relations for the Domain kind\n     */\n\n    if (entity.kind === 'Domain') {\n      const domain = entity as DomainEntity;\n      doEmit(\n        domain.spec.owner,\n        { defaultKind: 'Group', defaultNamespace: selfRef.namespace },\n        RELATION_OWNED_BY,\n        RELATION_OWNER_OF,\n      );\n    }\n\n    return entity;\n  }\n}\n","/*\n * Copyright 2020 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport fs from 'fs-extra';\nimport g from 'glob';\nimport path from 'path';\nimport { promisify } from 'util';\nimport {\n  CatalogProcessor,\n  CatalogProcessorEmit,\n  CatalogProcessorParser,\n  LocationSpec,\n  processingResult,\n} from '../../api';\n\nconst glob = promisify(g);\n\n/** @public */\nexport class FileReaderProcessor implements CatalogProcessor {\n  getProcessorName(): string {\n    return 'FileReaderProcessor';\n  }\n\n  async readLocation(\n    location: LocationSpec,\n    optional: boolean,\n    emit: CatalogProcessorEmit,\n    parser: CatalogProcessorParser,\n  ): Promise<boolean> {\n    if (location.type !== 'file') {\n      return false;\n    }\n\n    try {\n      const fileMatches = await glob(location.target);\n\n      if (fileMatches.length > 0) {\n        for (const fileMatch of fileMatches) {\n          const data = await fs.readFile(fileMatch);\n\n          // The normalize converts to native slashes; the glob library returns\n          // forward slashes even on windows\n          for await (const parseResult of parser({\n            data: data,\n            location: {\n              type: 'file',\n              target: path.normalize(fileMatch),\n            },\n          })) {\n            emit(parseResult);\n          }\n        }\n      } else if (!optional) {\n        const message = `${location.type} ${location.target} does not exist`;\n        emit(processingResult.notFoundError(location, message));\n      }\n    } catch (e) {\n      const message = `${location.type} ${location.target} could not be read, ${e}`;\n      emit(processingResult.generalError(location, message));\n    }\n\n    return true;\n  }\n}\n","/*\n * Copyright 2020 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Entity, LocationEntity } from '@backstage/catalog-model';\nimport { ScmIntegrationRegistry } from '@backstage/integration';\nimport path from 'path';\nimport {\n  processingResult,\n  CatalogProcessor,\n  CatalogProcessorEmit,\n  LocationSpec,\n} from '../../api';\n\nexport function toAbsoluteUrl(\n  integrations: ScmIntegrationRegistry,\n  base: LocationSpec,\n  target: string,\n): string {\n  try {\n    if (base.type === 'file') {\n      if (target.startsWith('.')) {\n        return path.join(path.dirname(base.target), target);\n      }\n      return target;\n    }\n    return integrations.resolveUrl({ url: target, base: base.target });\n  } catch (e) {\n    return target;\n  }\n}\n\n/** @public */\nexport type LocationEntityProcessorOptions = {\n  integrations: ScmIntegrationRegistry;\n};\n\n/** @public */\nexport class LocationEntityProcessor implements CatalogProcessor {\n  constructor(private readonly options: LocationEntityProcessorOptions) {}\n\n  getProcessorName(): string {\n    return 'LocationEntityProcessor';\n  }\n\n  async postProcessEntity(\n    entity: Entity,\n    location: LocationSpec,\n    emit: CatalogProcessorEmit,\n  ): Promise<Entity> {\n    if (entity.kind === 'Location') {\n      const locationEntity = entity as LocationEntity;\n\n      const type = locationEntity.spec.type || location.type;\n      if (type === 'file' && location.target.endsWith(path.sep)) {\n        emit(\n          processingResult.inputError(\n            location,\n            `LocationEntityProcessor cannot handle ${type} type location with target ${location.target} that ends with a path separator`,\n          ),\n        );\n      }\n\n      const targets = new Array<string>();\n      if (locationEntity.spec.target) {\n        targets.push(locationEntity.spec.target);\n      }\n      if (locationEntity.spec.targets) {\n        targets.push(...locationEntity.spec.targets);\n      }\n\n      for (const maybeRelativeTarget of targets) {\n        const target = toAbsoluteUrl(\n          this.options.integrations,\n          location,\n          maybeRelativeTarget,\n        );\n        emit(processingResult.location({ type, target }));\n      }\n    }\n\n    return entity;\n  }\n}\n","/*\n * Copyright 2020 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { UrlReader } from '@backstage/backend-common';\nimport { Entity } from '@backstage/catalog-model';\nimport { JsonValue } from '@backstage/types';\nimport { ScmIntegrationRegistry } from '@backstage/integration';\nimport yaml from 'yaml';\nimport { CatalogProcessor, LocationSpec } from '../../api';\n\n/** @public */\nexport type PlaceholderResolverRead = (url: string) => Promise<Buffer>;\n\n/** @public */\nexport type PlaceholderResolverResolveUrl = (\n  url: string,\n  base: string,\n) => string;\n\n/** @public */\nexport type PlaceholderResolverParams = {\n  key: string;\n  value: JsonValue;\n  baseUrl: string;\n  read: PlaceholderResolverRead;\n  resolveUrl: PlaceholderResolverResolveUrl;\n};\n\n/** @public */\nexport type PlaceholderResolver = (\n  params: PlaceholderResolverParams,\n) => Promise<JsonValue>;\n\n/** @public */\nexport type PlaceholderProcessorOptions = {\n  resolvers: Record<string, PlaceholderResolver>;\n  reader: UrlReader;\n  integrations: ScmIntegrationRegistry;\n};\n\n/**\n * Traverses raw entity JSON looking for occurrences of $-prefixed placeholders\n * that it then fills in with actual data.\n * @public\n */\nexport class PlaceholderProcessor implements CatalogProcessor {\n  constructor(private readonly options: PlaceholderProcessorOptions) {}\n\n  getProcessorName(): string {\n    return 'PlaceholderProcessor';\n  }\n\n  async preProcessEntity(\n    entity: Entity,\n    location: LocationSpec,\n  ): Promise<Entity> {\n    const process = async (data: any): Promise<[any, boolean]> => {\n      if (!data || !(data instanceof Object)) {\n        // Scalars can't have placeholders\n        return [data, false];\n      }\n\n      if (Array.isArray(data)) {\n        // We're an array - process all entries recursively\n        const items = await Promise.all(data.map(item => process(item)));\n        return items.every(([, changed]) => !changed)\n          ? [data, false]\n          : [items.map(([item]) => item), true];\n      }\n\n      const keys = Object.keys(data);\n      if (!keys.some(k => k.startsWith('$'))) {\n        // We're an object but no placeholders at this level - process all\n        // entries recursively\n        const entries = await Promise.all(\n          Object.entries(data).map(([k, v]) =>\n            process(v).then(vp => [k, vp] as const),\n          ),\n        );\n        return entries.every(([, [, changed]]) => !changed)\n          ? [data, false]\n          : [Object.fromEntries(entries.map(([k, [v]]) => [k, v])), true];\n      } else if (keys.length !== 1) {\n        // This was an object that had more than one key, some of which were\n        // dollar prefixed. We only handle the case where there is exactly one\n        // such key; anything else is left alone.\n        return [data, false];\n      }\n\n      const resolverKey = keys[0].substr(1);\n      const resolverValue = data[keys[0]];\n      const resolver = this.options.resolvers[resolverKey];\n      if (!resolver || typeof resolverValue !== 'string') {\n        // If there was no such placeholder resolver or if the value was not a\n        // string, we err on the side of safety and assume that this is\n        // something that's best left alone. For example, if the input contains\n        // JSONSchema, there may be \"$ref\": \"#/definitions/node\" nodes in the\n        // document.\n        return [data, false];\n      }\n\n      const read = async (url: string): Promise<Buffer> => {\n        if (this.options.reader.readUrl) {\n          const response = await this.options.reader.readUrl(url);\n          const buffer = await response.buffer();\n          return buffer;\n        }\n        return this.options.reader.read(url);\n      };\n\n      const resolveUrl = (url: string, base: string): string =>\n        this.options.integrations.resolveUrl({\n          url,\n          base,\n        });\n\n      return [\n        await resolver({\n          key: resolverKey,\n          value: resolverValue,\n          baseUrl: location.target,\n          read,\n          resolveUrl,\n        }),\n        true,\n      ];\n    };\n\n    const [result] = await process(entity);\n    return result;\n  }\n}\n\n/*\n * Resolvers\n */\n\nexport async function yamlPlaceholderResolver(\n  params: PlaceholderResolverParams,\n): Promise<JsonValue> {\n  const text = await readTextLocation(params);\n\n  let documents: yaml.Document.Parsed[];\n  try {\n    documents = yaml.parseAllDocuments(text).filter(d => d);\n  } catch (e) {\n    throw new Error(\n      `Placeholder \\$${params.key} failed to parse YAML data at ${params.value}, ${e}`,\n    );\n  }\n\n  if (documents.length !== 1) {\n    throw new Error(\n      `Placeholder \\$${params.key} expected to find exactly one document of data at ${params.value}, found ${documents.length}`,\n    );\n  }\n\n  const document = documents[0];\n\n  if (document.errors?.length) {\n    throw new Error(\n      `Placeholder \\$${params.key} found an error in the data at ${params.value}, ${document.errors[0]}`,\n    );\n  }\n\n  return document.toJSON();\n}\n\nexport async function jsonPlaceholderResolver(\n  params: PlaceholderResolverParams,\n): Promise<JsonValue> {\n  const text = await readTextLocation(params);\n\n  try {\n    return JSON.parse(text);\n  } catch (e) {\n    throw new Error(\n      `Placeholder \\$${params.key} failed to parse JSON data at ${params.value}, ${e}`,\n    );\n  }\n}\n\nexport async function textPlaceholderResolver(\n  params: PlaceholderResolverParams,\n): Promise<JsonValue> {\n  return await readTextLocation(params);\n}\n\n/*\n * Helpers\n */\n\nasync function readTextLocation(\n  params: PlaceholderResolverParams,\n): Promise<string> {\n  const newUrl = relativeUrl(params);\n\n  try {\n    const data = await params.read(newUrl);\n    return data.toString('utf-8');\n  } catch (e) {\n    throw new Error(\n      `Placeholder \\$${params.key} could not read location ${params.value}, ${e}`,\n    );\n  }\n}\n\nfunction relativeUrl({\n  key,\n  value,\n  baseUrl,\n  resolveUrl,\n}: PlaceholderResolverParams): string {\n  if (typeof value !== 'string') {\n    throw new Error(\n      `Placeholder \\$${key} expected a string value parameter, in the form of an absolute URL or a relative path`,\n    );\n  }\n\n  try {\n    return resolveUrl(value, baseUrl);\n  } catch (e) {\n    // The only remaining case that isn't support is a relative file path that should be\n    // resolved using a relative file location. Accessing local file paths can lead to\n    // path traversal attacks and access to any file on the host system. Implementing this\n    // would require additional security measures.\n    throw new Error(\n      `Placeholder \\$${key} could not form a URL out of ${baseUrl} and ${value}, ${e}`,\n    );\n  }\n}\n","/*\n * Copyright 2020 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { UrlReader } from '@backstage/backend-common';\nimport { Entity } from '@backstage/catalog-model';\nimport { assertError } from '@backstage/errors';\nimport parseGitUrl from 'git-url-parse';\nimport limiterFactory from 'p-limit';\nimport { Logger } from 'winston';\nimport {\n  CatalogProcessor,\n  CatalogProcessorCache,\n  CatalogProcessorEmit,\n  CatalogProcessorEntityResult,\n  CatalogProcessorParser,\n  CatalogProcessorResult,\n  LocationSpec,\n  processingResult,\n} from '../../api';\n\nconst CACHE_KEY = 'v1';\n\n// WARNING: If you change this type, you likely need to bump the CACHE_KEY as well\ntype CacheItem = {\n  etag: string;\n  value: {\n    type: 'entity';\n    entity: Entity;\n    location: LocationSpec;\n  }[];\n};\n\n/** @public */\nexport class UrlReaderProcessor implements CatalogProcessor {\n  constructor(\n    private readonly options: {\n      reader: UrlReader;\n      logger: Logger;\n    },\n  ) {}\n\n  getProcessorName() {\n    return 'url-reader';\n  }\n\n  async readLocation(\n    location: LocationSpec,\n    optional: boolean,\n    emit: CatalogProcessorEmit,\n    parser: CatalogProcessorParser,\n    cache: CatalogProcessorCache,\n  ): Promise<boolean> {\n    if (location.type !== 'url') {\n      return false;\n    }\n\n    const cacheItem = await cache.get<CacheItem>(CACHE_KEY);\n\n    try {\n      const { response, etag: newEtag } = await this.doRead(\n        location.target,\n        cacheItem?.etag,\n      );\n\n      const parseResults: CatalogProcessorResult[] = [];\n      for (const item of response) {\n        for await (const parseResult of parser({\n          data: item.data,\n          location: { type: location.type, target: item.url },\n        })) {\n          parseResults.push(parseResult);\n          emit(parseResult);\n        }\n      }\n\n      const isOnlyEntities = parseResults.every(r => r.type === 'entity');\n      if (newEtag && isOnlyEntities) {\n        await cache.set<CacheItem>(CACHE_KEY, {\n          etag: newEtag,\n          value: parseResults as CatalogProcessorEntityResult[],\n        });\n      }\n    } catch (error) {\n      assertError(error);\n      const message = `Unable to read ${location.type}, ${error}`;\n      if (error.name === 'NotModifiedError' && cacheItem) {\n        for (const parseResult of cacheItem.value) {\n          emit(parseResult);\n        }\n      } else if (error.name === 'NotFoundError') {\n        if (!optional) {\n          emit(processingResult.notFoundError(location, message));\n        }\n      } else {\n        emit(processingResult.generalError(location, message));\n      }\n    }\n\n    return true;\n  }\n\n  private async doRead(\n    location: string,\n    etag?: string,\n  ): Promise<{ response: { data: Buffer; url: string }[]; etag?: string }> {\n    // Does it contain globs? I.e. does it contain asterisks or question marks\n    // (no curly braces for now)\n    const { filepath } = parseGitUrl(location);\n    if (filepath?.match(/[*?]/)) {\n      const limiter = limiterFactory(5);\n      const response = await this.options.reader.search(location, { etag });\n      const output = response.files.map(async file => ({\n        url: file.url,\n        data: await limiter(file.content),\n      }));\n      return { response: await Promise.all(output), etag: response.etag };\n    }\n\n    // Otherwise do a plain read, prioritizing readUrl if available\n    if (this.options.reader.readUrl) {\n      const data = await this.options.reader.readUrl(location, { etag });\n      return {\n        response: [{ url: location, data: await data.buffer() }],\n        etag: data.etag,\n      };\n    }\n\n    const data = await this.options.reader.read(location);\n    return { response: [{ url: location, data }] };\n  }\n}\n","/*\n * Copyright 2020 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Entity, stringifyLocationRef } from '@backstage/catalog-model';\nimport lodash from 'lodash';\nimport yaml from 'yaml';\nimport {\n  CatalogProcessorParser,\n  CatalogProcessorResult,\n  LocationSpec,\n  processingResult,\n} from '../../api';\n\n/** @public */\nexport function* parseEntityYaml(\n  data: Buffer,\n  location: LocationSpec,\n): Iterable<CatalogProcessorResult> {\n  let documents: yaml.Document.Parsed[];\n  try {\n    documents = yaml.parseAllDocuments(data.toString('utf8')).filter(d => d);\n  } catch (e) {\n    const loc = stringifyLocationRef(location);\n    const message = `Failed to parse YAML at ${loc}, ${e}`;\n    yield processingResult.generalError(location, message);\n    return;\n  }\n\n  for (const document of documents) {\n    if (document.errors?.length) {\n      const loc = stringifyLocationRef(location);\n      const message = `YAML error at ${loc}, ${document.errors[0]}`;\n      yield processingResult.generalError(location, message);\n    } else {\n      const json = document.toJSON();\n      if (lodash.isPlainObject(json)) {\n        yield processingResult.entity(location, json as Entity);\n      } else if (json === null) {\n        // Ignore null values, these happen if there is an empty document in the\n        // YAML file, for example if --- is added to the end of the file.\n      } else {\n        const message = `Expected object at root, got ${typeof json}`;\n        yield processingResult.generalError(location, message);\n      }\n    }\n  }\n}\n\nexport const defaultEntityDataParser: CatalogProcessorParser =\n  async function* defaultEntityDataParser({ data, location }) {\n    for (const e of parseEntityYaml(data, location)) {\n      yield e;\n    }\n  };\n","/*\n * Copyright 2022 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  PluginEndpointDiscovery,\n  TokenManager,\n} from '@backstage/backend-common';\nimport {\n  CatalogApi,\n  CatalogClient,\n  GetEntitiesRequest,\n} from '@backstage/catalog-client';\nimport {\n  Entity,\n  stringifyEntityRef,\n  UserEntity,\n} from '@backstage/catalog-model';\nimport { Config } from '@backstage/config';\nimport { DocumentCollatorFactory } from '@backstage/plugin-search-common';\nimport {\n  catalogEntityReadPermission,\n  CatalogEntityDocument,\n} from '@backstage/plugin-catalog-common';\nimport { Readable } from 'stream';\n\n/** @public */\nexport type DefaultCatalogCollatorFactoryOptions = {\n  discovery: PluginEndpointDiscovery;\n  tokenManager: TokenManager;\n  locationTemplate?: string;\n  filter?: GetEntitiesRequest['filter'];\n  batchSize?: number;\n  catalogClient?: CatalogApi;\n};\n\n/** @public */\nexport class DefaultCatalogCollatorFactory implements DocumentCollatorFactory {\n  public readonly type: string = 'software-catalog';\n  public readonly visibilityPermission = catalogEntityReadPermission;\n\n  private locationTemplate: string;\n  private filter?: GetEntitiesRequest['filter'];\n  private batchSize: number;\n  private readonly catalogClient: CatalogApi;\n  private tokenManager: TokenManager;\n\n  static fromConfig(\n    _config: Config,\n    options: DefaultCatalogCollatorFactoryOptions,\n  ) {\n    return new DefaultCatalogCollatorFactory(options);\n  }\n\n  private constructor(options: DefaultCatalogCollatorFactoryOptions) {\n    const {\n      batchSize,\n      discovery,\n      locationTemplate,\n      filter,\n      catalogClient,\n      tokenManager,\n    } = options;\n\n    this.locationTemplate =\n      locationTemplate || '/catalog/:namespace/:kind/:name';\n    this.filter = filter;\n    this.batchSize = batchSize || 500;\n    this.catalogClient =\n      catalogClient || new CatalogClient({ discoveryApi: discovery });\n    this.tokenManager = tokenManager;\n  }\n\n  async getCollator(): Promise<Readable> {\n    return Readable.from(this.execute());\n  }\n\n  private applyArgsToFormat(\n    format: string,\n    args: Record<string, string>,\n  ): string {\n    let formatted = format;\n    for (const [key, value] of Object.entries(args)) {\n      formatted = formatted.replace(`:${key}`, value);\n    }\n    return formatted.toLowerCase();\n  }\n\n  private isUserEntity(entity: Entity): entity is UserEntity {\n    return entity.kind.toLocaleUpperCase('en-US') === 'USER';\n  }\n\n  private getDocumentText(entity: Entity): string {\n    let documentText = entity.metadata.description || '';\n    if (this.isUserEntity(entity)) {\n      if (entity.spec?.profile?.displayName && documentText) {\n        // combine displayName and description\n        const displayName = entity.spec?.profile?.displayName;\n        documentText = displayName.concat(' : ', documentText);\n      } else {\n        documentText = entity.spec?.profile?.displayName || documentText;\n      }\n    }\n    return documentText;\n  }\n\n  private async *execute(): AsyncGenerator<CatalogEntityDocument> {\n    const { token } = await this.tokenManager.getToken();\n    let entitiesRetrieved = 0;\n    let moreEntitiesToGet = true;\n\n    // Offset/limit pagination is used on the Catalog Client in order to\n    // limit (and allow some control over) memory used by the search backend\n    // at index-time.\n    while (moreEntitiesToGet) {\n      const entities = (\n        await this.catalogClient.getEntities(\n          {\n            filter: this.filter,\n            limit: this.batchSize,\n            offset: entitiesRetrieved,\n          },\n          { token },\n        )\n      ).items;\n\n      // Control looping through entity batches.\n      moreEntitiesToGet = entities.length === this.batchSize;\n      entitiesRetrieved += entities.length;\n\n      for (const entity of entities) {\n        yield {\n          title: entity.metadata.title ?? entity.metadata.name,\n          location: this.applyArgsToFormat(this.locationTemplate, {\n            namespace: entity.metadata.namespace || 'default',\n            kind: entity.kind,\n            name: entity.metadata.name,\n          }),\n          text: this.getDocumentText(entity),\n          componentType: entity.spec?.type?.toString() || 'other',\n          type: entity.spec?.type?.toString() || 'other',\n          namespace: entity.metadata.namespace || 'default',\n          kind: entity.kind,\n          lifecycle: (entity.spec?.lifecycle as string) || '',\n          owner: (entity.spec?.owner as string) || '',\n          authorization: {\n            resourceRef: stringifyEntityRef(entity),\n          },\n        };\n      }\n    }\n  }\n}\n","/*\n * Copyright 2021 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  PluginEndpointDiscovery,\n  TokenManager,\n} from '@backstage/backend-common';\nimport {\n  Entity,\n  stringifyEntityRef,\n  UserEntity,\n} from '@backstage/catalog-model';\nimport { Config } from '@backstage/config';\nimport {\n  CatalogApi,\n  CatalogClient,\n  GetEntitiesRequest,\n} from '@backstage/catalog-client';\nimport {\n  catalogEntityReadPermission,\n  CatalogEntityDocument,\n} from '@backstage/plugin-catalog-common';\n\n/**\n * @public\n * @deprecated Upgrade to a more recent `@backstage/search-backend-node` and\n * use `DefaultCatalogCollatorFactory` instead.\n */\nexport class DefaultCatalogCollator {\n  protected discovery: PluginEndpointDiscovery;\n  protected locationTemplate: string;\n  protected filter?: GetEntitiesRequest['filter'];\n  protected readonly catalogClient: CatalogApi;\n  public readonly type: string = 'software-catalog';\n  public readonly visibilityPermission = catalogEntityReadPermission;\n  protected tokenManager: TokenManager;\n\n  static fromConfig(\n    _config: Config,\n    options: {\n      discovery: PluginEndpointDiscovery;\n      tokenManager: TokenManager;\n      filter?: GetEntitiesRequest['filter'];\n    },\n  ) {\n    return new DefaultCatalogCollator({\n      ...options,\n    });\n  }\n\n  constructor(options: {\n    discovery: PluginEndpointDiscovery;\n    tokenManager: TokenManager;\n    locationTemplate?: string;\n    filter?: GetEntitiesRequest['filter'];\n    catalogClient?: CatalogApi;\n  }) {\n    const { discovery, locationTemplate, filter, catalogClient, tokenManager } =\n      options;\n\n    this.discovery = discovery;\n    this.locationTemplate =\n      locationTemplate || '/catalog/:namespace/:kind/:name';\n    this.filter = filter;\n    this.catalogClient =\n      catalogClient || new CatalogClient({ discoveryApi: discovery });\n    this.tokenManager = tokenManager;\n  }\n\n  protected applyArgsToFormat(\n    format: string,\n    args: Record<string, string>,\n  ): string {\n    let formatted = format;\n    for (const [key, value] of Object.entries(args)) {\n      formatted = formatted.replace(`:${key}`, value);\n    }\n    return formatted.toLowerCase();\n  }\n\n  private isUserEntity(entity: Entity): entity is UserEntity {\n    return entity.kind.toLocaleUpperCase('en-US') === 'USER';\n  }\n\n  private getDocumentText(entity: Entity): string {\n    let documentText = entity.metadata.description || '';\n    if (this.isUserEntity(entity)) {\n      if (entity.spec?.profile?.displayName && documentText) {\n        // combine displayName and description\n        const displayName = entity.spec?.profile?.displayName;\n        documentText = displayName.concat(' : ', documentText);\n      } else {\n        documentText = entity.spec?.profile?.displayName || documentText;\n      }\n    }\n    return documentText;\n  }\n\n  async execute() {\n    const { token } = await this.tokenManager.getToken();\n    const response = await this.catalogClient.getEntities(\n      {\n        filter: this.filter,\n      },\n      { token },\n    );\n    return response.items.map((entity: Entity): CatalogEntityDocument => {\n      return {\n        title: entity.metadata.title ?? entity.metadata.name,\n        location: this.applyArgsToFormat(this.locationTemplate, {\n          namespace: entity.metadata.namespace || 'default',\n          kind: entity.kind,\n          name: entity.metadata.name,\n        }),\n        text: this.getDocumentText(entity),\n        componentType: entity.spec?.type?.toString() || 'other',\n        type: entity.spec?.type?.toString() || 'other',\n        namespace: entity.metadata.namespace || 'default',\n        kind: entity.kind,\n        lifecycle: (entity.spec?.lifecycle as string) || '',\n        owner: (entity.spec?.owner as string) || '',\n        authorization: {\n          resourceRef: stringifyEntityRef(entity),\n        },\n      };\n    });\n  }\n}\n","/*\n * Copyright 2021 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  Entity,\n  LocationEntityV1alpha1,\n  ANNOTATION_LOCATION,\n  ANNOTATION_ORIGIN_LOCATION,\n  stringifyEntityRef,\n  stringifyLocationRef,\n} from '@backstage/catalog-model';\nimport { createHash } from 'crypto';\nimport { LocationSpec } from '../api';\n\nexport function locationSpecToMetadataName(location: LocationSpec) {\n  const hash = createHash('sha1')\n    .update(`${location.type}:${location.target}`)\n    .digest('hex');\n  return `generated-${hash}`;\n}\n\nexport function locationSpecToLocationEntity(\n  location: LocationSpec,\n  parentEntity?: Entity,\n): LocationEntityV1alpha1 {\n  let ownLocation: string;\n  let originLocation: string;\n  if (parentEntity) {\n    const maybeOwnLocation =\n      parentEntity.metadata.annotations?.[ANNOTATION_LOCATION];\n    if (!maybeOwnLocation) {\n      throw new Error(\n        `Parent entity '${stringifyEntityRef(\n          parentEntity,\n        )}' of location '${stringifyLocationRef(\n          location,\n        )}' does not have a location annotation`,\n      );\n    }\n    ownLocation = maybeOwnLocation;\n    const maybeOriginLocation =\n      parentEntity.metadata.annotations?.[ANNOTATION_ORIGIN_LOCATION];\n    if (!maybeOriginLocation) {\n      throw new Error(\n        `Parent entity '${stringifyEntityRef(\n          parentEntity,\n        )}' of location '${stringifyLocationRef(\n          location,\n        )}' does not have an origin location annotation`,\n      );\n    }\n    originLocation = maybeOriginLocation;\n  } else {\n    ownLocation = stringifyLocationRef(location);\n    originLocation = ownLocation;\n  }\n\n  const result: LocationEntityV1alpha1 = {\n    apiVersion: 'backstage.io/v1alpha1',\n    kind: 'Location',\n    metadata: {\n      name: locationSpecToMetadataName(location),\n      annotations: {\n        [ANNOTATION_LOCATION]: ownLocation,\n        [ANNOTATION_ORIGIN_LOCATION]: originLocation,\n      },\n    },\n    spec: {\n      type: location.type,\n      target: location.target,\n      presence: location.presence,\n    },\n  };\n\n  return result;\n}\n","/*\n * Copyright 2021 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  Entity,\n  entityEnvelopeSchemaValidator,\n  entitySchemaValidator,\n  LocationEntity,\n  ANNOTATION_LOCATION,\n  ANNOTATION_ORIGIN_LOCATION,\n  stringifyEntityRef,\n} from '@backstage/catalog-model';\nimport { JsonObject, JsonValue } from '@backstage/types';\nimport { InputError } from '@backstage/errors';\nimport { ScmIntegrationRegistry } from '@backstage/integration';\nimport path from 'path';\nimport { LocationSpec } from '../api';\n\nexport function isLocationEntity(entity: Entity): entity is LocationEntity {\n  return entity.kind === 'Location';\n}\n\nexport function getEntityLocationRef(entity: Entity): string {\n  const ref = entity.metadata.annotations?.[ANNOTATION_LOCATION];\n  if (!ref) {\n    const entityRef = stringifyEntityRef(entity);\n    throw new InputError(\n      `Entity '${entityRef}' does not have the annotation ${ANNOTATION_LOCATION}`,\n    );\n  }\n  return ref;\n}\n\nexport function getEntityOriginLocationRef(entity: Entity): string {\n  const ref = entity.metadata.annotations?.[ANNOTATION_ORIGIN_LOCATION];\n  if (!ref) {\n    const entityRef = stringifyEntityRef(entity);\n    throw new InputError(\n      `Entity '${entityRef}' does not have the annotation ${ANNOTATION_ORIGIN_LOCATION}`,\n    );\n  }\n  return ref;\n}\n\nexport function toAbsoluteUrl(\n  integrations: ScmIntegrationRegistry,\n  base: LocationSpec,\n  type: string,\n  target: string,\n): string {\n  if (base.type !== type) {\n    return target;\n  }\n  try {\n    if (type === 'file') {\n      if (target.startsWith('.')) {\n        return path.join(path.dirname(base.target), target);\n      }\n      return target;\n    } else if (type === 'url') {\n      return integrations.resolveUrl({ url: target, base: base.target });\n    }\n    return target;\n  } catch (e) {\n    return target;\n  }\n}\n\nexport function isObject(value: JsonValue | undefined): value is JsonObject {\n  return typeof value === 'object' && value !== null && !Array.isArray(value);\n}\n\nexport const validateEntity = entitySchemaValidator();\n\nexport const validateEntityEnvelope = entityEnvelopeSchemaValidator();\n","/*\n * Copyright 2021 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  Entity,\n  ANNOTATION_LOCATION,\n  ANNOTATION_ORIGIN_LOCATION,\n  stringifyLocationRef,\n} from '@backstage/catalog-model';\nimport { assertError } from '@backstage/errors';\nimport { Logger } from 'winston';\nimport { CatalogProcessorResult, EntityRelationSpec } from '../api';\nimport { locationSpecToLocationEntity } from '../util/conversion';\nimport { DeferredEntity } from './types';\nimport {\n  getEntityLocationRef,\n  getEntityOriginLocationRef,\n  validateEntityEnvelope,\n} from './util';\n\n/**\n * Helper class for aggregating all of the emitted data from processors.\n */\nexport class ProcessorOutputCollector {\n  private readonly errors = new Array<Error>();\n  private readonly relations = new Array<EntityRelationSpec>();\n  private readonly deferredEntities = new Array<DeferredEntity>();\n  private done = false;\n\n  constructor(\n    private readonly logger: Logger,\n    private readonly parentEntity: Entity,\n  ) {}\n\n  get onEmit(): (i: CatalogProcessorResult) => void {\n    return i => this.receive(i);\n  }\n\n  results() {\n    this.done = true;\n    return {\n      errors: this.errors,\n      relations: this.relations,\n      deferredEntities: this.deferredEntities,\n    };\n  }\n\n  private receive(i: CatalogProcessorResult) {\n    if (this.done) {\n      this.logger.warn(\n        `Item of type \"${\n          i.type\n        }\" was emitted after processing had completed. Stack trace: ${\n          new Error().stack\n        }`,\n      );\n      return;\n    }\n\n    if (i.type === 'entity') {\n      let entity: Entity;\n      const location = stringifyLocationRef(i.location);\n\n      try {\n        entity = validateEntityEnvelope(i.entity);\n      } catch (e) {\n        assertError(e);\n        this.logger.debug(`Envelope validation failed at ${location}, ${e}`);\n        this.errors.push(e);\n        return;\n      }\n\n      // Note that at this point, we have only validated the envelope part of\n      // the entity data. Annotations are not part of that, so we have to be\n      // defensive. If the annotations were malformed (e.g. were not a valid\n      // object), we just skip over this step and let the full entity\n      // validation at the next step of processing catch that.\n      const annotations = entity.metadata.annotations || {};\n      if (typeof annotations === 'object' && !Array.isArray(annotations)) {\n        const originLocation = getEntityOriginLocationRef(this.parentEntity);\n        entity = {\n          ...entity,\n          metadata: {\n            ...entity.metadata,\n            annotations: {\n              ...annotations,\n              [ANNOTATION_ORIGIN_LOCATION]: originLocation,\n              [ANNOTATION_LOCATION]: location,\n            },\n          },\n        };\n      }\n\n      this.deferredEntities.push({ entity, locationKey: location });\n    } else if (i.type === 'location') {\n      const entity = locationSpecToLocationEntity(\n        i.location,\n        this.parentEntity,\n      );\n      const locationKey = getEntityLocationRef(entity);\n      this.deferredEntities.push({ entity, locationKey });\n    } else if (i.type === 'relation') {\n      this.relations.push(i.relation);\n    } else if (i.type === 'error') {\n      this.errors.push(i.error);\n    }\n  }\n}\n","/*\n * Copyright 2021 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { JsonObject, JsonValue } from '@backstage/types';\nimport { CatalogProcessor, CatalogProcessorCache } from '../api';\nimport { isObject } from './util';\n\nclass SingleProcessorSubCache implements CatalogProcessorCache {\n  private newState?: JsonObject;\n\n  constructor(private readonly existingState?: JsonObject) {}\n\n  async get<ItemType extends JsonValue>(\n    key: string,\n  ): Promise<ItemType | undefined> {\n    return this.existingState?.[key] as ItemType | undefined;\n  }\n\n  async set<ItemType extends JsonValue>(\n    key: string,\n    value: ItemType,\n  ): Promise<void> {\n    if (!this.newState) {\n      this.newState = {};\n    }\n\n    this.newState[key] = value;\n  }\n\n  collect(): JsonObject | undefined {\n    return this.newState ?? this.existingState;\n  }\n}\n\nclass SingleProcessorCache implements CatalogProcessorCache {\n  private newState?: JsonObject;\n  private subCaches: Map<string, SingleProcessorSubCache> = new Map();\n\n  constructor(private readonly existingState?: JsonObject) {}\n\n  async get<ItemType extends JsonValue>(\n    key: string,\n  ): Promise<ItemType | undefined> {\n    return this.existingState?.[key] as ItemType | undefined;\n  }\n\n  async set<ItemType extends JsonValue>(\n    key: string,\n    value: ItemType,\n  ): Promise<void> {\n    if (!this.newState) {\n      this.newState = {};\n    }\n\n    this.newState[key] = value;\n  }\n\n  withKey(key: string) {\n    const existingSubCache = this.subCaches.get(key);\n    if (existingSubCache) {\n      return existingSubCache;\n    }\n    const existing = this.existingState?.[key];\n    const subCache = new SingleProcessorSubCache(\n      isObject(existing) ? existing : undefined,\n    );\n    this.subCaches.set(key, subCache);\n    return subCache;\n  }\n\n  collect(): JsonObject | undefined {\n    let obj = this.newState ?? this.existingState;\n    for (const [key, subCache] of this.subCaches) {\n      const subCacheValue = subCache.collect();\n      if (subCacheValue) {\n        obj = { ...obj, [key]: subCacheValue };\n      }\n    }\n    return obj;\n  }\n}\n\nexport class ProcessorCacheManager {\n  private caches = new Map<string, SingleProcessorCache>();\n\n  constructor(private readonly existingState: JsonObject) {}\n\n  forProcessor(\n    processor: CatalogProcessor,\n    key?: string,\n  ): CatalogProcessorCache {\n    // constructor name will be deprecated in the future when we make `getProcessorName` required in the implementation\n    const name = processor.getProcessorName();\n    const cache = this.caches.get(name);\n    if (cache) {\n      return key ? cache.withKey(key) : cache;\n    }\n\n    const existing = this.existingState[name];\n\n    const newCache = new SingleProcessorCache(\n      isObject(existing) ? existing : undefined,\n    );\n    this.caches.set(name, newCache);\n    return key ? newCache.withKey(key) : newCache;\n  }\n\n  collect(): JsonObject {\n    const result: JsonObject = {};\n    for (const [key, value] of this.caches.entries()) {\n      result[key] = value.collect();\n    }\n\n    return result;\n  }\n}\n","/*\n * Copyright 2021 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  Entity,\n  EntityPolicy,\n  LocationEntity,\n  parseLocationRef,\n  stringifyEntityRef,\n  stringifyLocationRef,\n} from '@backstage/catalog-model';\nimport {\n  assertError,\n  ConflictError,\n  InputError,\n  NotAllowedError,\n} from '@backstage/errors';\nimport { JsonValue } from '@backstage/types';\nimport { ScmIntegrationRegistry } from '@backstage/integration';\nimport path from 'path';\nimport { Logger } from 'winston';\nimport {\n  CatalogProcessor,\n  CatalogProcessorParser,\n  LocationSpec,\n  processingResult,\n} from '../api';\nimport {\n  CatalogProcessingOrchestrator,\n  EntityProcessingRequest,\n  EntityProcessingResult,\n} from './types';\nimport { ProcessorOutputCollector } from './ProcessorOutputCollector';\nimport {\n  getEntityLocationRef,\n  getEntityOriginLocationRef,\n  isLocationEntity,\n  toAbsoluteUrl,\n  validateEntity,\n  validateEntityEnvelope,\n  isObject,\n} from './util';\nimport { CatalogRulesEnforcer } from '../ingestion/CatalogRules';\nimport { ProcessorCacheManager } from './ProcessorCacheManager';\n\ntype Context = {\n  entityRef: string;\n  location: LocationSpec;\n  originLocation: LocationSpec;\n  collector: ProcessorOutputCollector;\n  cache: ProcessorCacheManager;\n};\n\n/** @public */\nexport class DefaultCatalogProcessingOrchestrator\n  implements CatalogProcessingOrchestrator\n{\n  constructor(\n    private readonly options: {\n      processors: CatalogProcessor[];\n      integrations: ScmIntegrationRegistry;\n      logger: Logger;\n      parser: CatalogProcessorParser;\n      policy: EntityPolicy;\n      rulesEnforcer: CatalogRulesEnforcer;\n    },\n  ) {}\n\n  async process(\n    request: EntityProcessingRequest,\n  ): Promise<EntityProcessingResult> {\n    return this.processSingleEntity(request.entity, request.state);\n  }\n\n  private async processSingleEntity(\n    unprocessedEntity: Entity,\n    state: JsonValue | undefined,\n  ): Promise<EntityProcessingResult> {\n    const collector = new ProcessorOutputCollector(\n      this.options.logger,\n      unprocessedEntity,\n    );\n\n    // Cache that is scoped to the entity and processor\n    const cache = new ProcessorCacheManager(\n      isObject(state) && isObject(state.cache) ? state.cache : {},\n    );\n\n    try {\n      // This will be checked and mutated step by step below\n      let entity: Entity = unprocessedEntity;\n\n      // NOTE: At this early point, we can only rely on the envelope having to\n      // be valid; full entity + kind validation happens after the (potentially\n      // mutative) pre-steps. This means that the code below can't make a lot\n      // of assumptions about the data despite it using the Entity type.\n      try {\n        validateEntityEnvelope(entity);\n      } catch (e) {\n        throw new InputError(\n          `Entity envelope failed validation before processing`,\n          e,\n        );\n      }\n\n      // TODO: which one do we actually use for the location?\n      // source-location? - maybe probably doesn't exist yet?\n      const context: Context = {\n        entityRef: stringifyEntityRef(entity),\n        location: parseLocationRef(getEntityLocationRef(entity)),\n        originLocation: parseLocationRef(getEntityOriginLocationRef(entity)),\n        cache,\n        collector,\n      };\n\n      // Run the steps\n      entity = await this.runPreProcessStep(entity, context);\n      entity = await this.runPolicyStep(entity);\n      await this.runValidateStep(entity, context);\n      if (isLocationEntity(entity)) {\n        await this.runSpecialLocationStep(entity, context);\n      }\n      entity = await this.runPostProcessStep(entity, context);\n\n      // Check that any emitted entities are permitted to originate from that\n      // particular location according to the catalog rules\n      const collectorResults = context.collector.results();\n      for (const deferredEntity of collectorResults.deferredEntities) {\n        if (\n          !this.options.rulesEnforcer.isAllowed(\n            deferredEntity.entity,\n            context.originLocation,\n          )\n        ) {\n          throw new NotAllowedError(\n            `Entity ${stringifyEntityRef(\n              deferredEntity.entity,\n            )} at ${stringifyLocationRef(\n              context.location,\n            )}, originated at ${stringifyLocationRef(\n              context.originLocation,\n            )}, is not of an allowed kind for that location`,\n          );\n        }\n      }\n\n      return {\n        ...collectorResults,\n        completedEntity: entity,\n        state: { cache: cache.collect() },\n        ok: collectorResults.errors.length === 0,\n      };\n    } catch (error) {\n      assertError(error);\n      return {\n        ok: false,\n        errors: collector.results().errors.concat(error),\n      };\n    }\n  }\n\n  // Pre-process phase, used to populate entities with data that is required\n  // during the main processing step\n  private async runPreProcessStep(\n    entity: Entity,\n    context: Context,\n  ): Promise<Entity> {\n    let res = entity;\n\n    for (const processor of this.options.processors) {\n      if (processor.preProcessEntity) {\n        try {\n          res = await processor.preProcessEntity(\n            res,\n            context.location,\n            context.collector.onEmit,\n            context.originLocation,\n            context.cache.forProcessor(processor),\n          );\n        } catch (e) {\n          throw new InputError(\n            `Processor ${processor.constructor.name} threw an error while preprocessing`,\n            e,\n          );\n        }\n      }\n    }\n\n    return res;\n  }\n\n  /**\n   * Enforce entity policies making sure that entities conform to a general schema\n   */\n  private async runPolicyStep(entity: Entity): Promise<Entity> {\n    let policyEnforcedEntity: Entity | undefined;\n\n    try {\n      policyEnforcedEntity = await this.options.policy.enforce(entity);\n    } catch (e) {\n      throw new InputError('Policy check failed', e);\n    }\n\n    if (!policyEnforcedEntity) {\n      throw new Error('Policy unexpectedly returned no data');\n    }\n\n    return policyEnforcedEntity;\n  }\n\n  /**\n   * Validate the given entity\n   */\n  private async runValidateStep(\n    entity: Entity,\n    context: Context,\n  ): Promise<void> {\n    // Double check that none of the previous steps tried to change something\n    // related to the entity ref, which would break downstream\n    if (stringifyEntityRef(entity) !== context.entityRef) {\n      throw new ConflictError(\n        'Fatal: The entity kind, namespace, or name changed during processing',\n      );\n    }\n\n    // Validate that the end result is a valid Entity at all\n    try {\n      validateEntity(entity);\n    } catch (e) {\n      throw new ConflictError(\n        `Entity envelope failed validation after preprocessing`,\n        e,\n      );\n    }\n\n    let foundKind = false;\n\n    for (const processor of this.options.processors) {\n      if (processor.validateEntityKind) {\n        try {\n          foundKind = await processor.validateEntityKind(entity);\n          if (foundKind) {\n            // TODO(freben): It would make sense to keep running, so that\n            // multiple processors could have a go at making checks. For\n            // example, an org may want to add additional rules on top of the\n            // provided ones. But that would be a breaking change, so we'll\n            // postpone that to a future processors rewrite.\n            break;\n          }\n        } catch (e) {\n          throw new InputError(\n            `Processor ${processor.constructor.name} threw an error while validating the entity`,\n            e,\n          );\n        }\n      }\n    }\n\n    if (!foundKind) {\n      throw new InputError(\n        'No processor recognized the entity as valid, possibly caused by a foreign kind or apiVersion',\n      );\n    }\n  }\n\n  /**\n   * Backwards compatible processing of location entities\n   */\n  private async runSpecialLocationStep(\n    entity: LocationEntity,\n    context: Context,\n  ): Promise<void> {\n    const { type = context.location.type, presence = 'required' } = entity.spec;\n    const targets = new Array<string>();\n    if (entity.spec.target) {\n      targets.push(entity.spec.target);\n    }\n    if (entity.spec.targets) {\n      targets.push(...entity.spec.targets);\n    }\n\n    for (const maybeRelativeTarget of targets) {\n      if (type === 'file' && maybeRelativeTarget.endsWith(path.sep)) {\n        context.collector.onEmit(\n          processingResult.inputError(\n            context.location,\n            `LocationEntityProcessor cannot handle ${type} type location with target ${context.location.target} that ends with a path separator`,\n          ),\n        );\n        continue;\n      }\n      const target = toAbsoluteUrl(\n        this.options.integrations,\n        context.location,\n        type,\n        maybeRelativeTarget,\n      );\n\n      let didRead = false;\n      for (const processor of this.options.processors) {\n        if (processor.readLocation) {\n          try {\n            const read = await processor.readLocation(\n              {\n                type,\n                target,\n                presence,\n              },\n              presence === 'optional',\n              context.collector.onEmit,\n              this.options.parser,\n              context.cache.forProcessor(processor, target),\n            );\n            if (read) {\n              didRead = true;\n              break;\n            }\n          } catch (e) {\n            throw new InputError(\n              `Processor ${processor.constructor.name} threw an error while reading ${type}:${target}`,\n              e,\n            );\n          }\n        }\n      }\n      if (!didRead) {\n        throw new InputError(\n          `No processor was able to handle reading of ${type}:${target}`,\n        );\n      }\n    }\n  }\n\n  /**\n   * Main processing step of the entity\n   */\n  private async runPostProcessStep(\n    entity: Entity,\n    context: Context,\n  ): Promise<Entity> {\n    let res = entity;\n\n    for (const processor of this.options.processors) {\n      if (processor.postProcessEntity) {\n        try {\n          res = await processor.postProcessEntity(\n            res,\n            context.location,\n            context.collector.onEmit,\n            context.cache.forProcessor(processor),\n          );\n        } catch (e) {\n          throw new InputError(\n            `Processor ${processor.constructor.name} threw an error while postprocessing`,\n            e,\n          );\n        }\n      }\n    }\n\n    return res;\n  }\n}\n","/*\n * Copyright 2021 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n/**\n * Function that returns the catalog refresh interval in seconds.\n * @deprecated use {@link ProcessingIntervalFunction} instead\n * @public\n */\nexport type RefreshIntervalFunction = () => number;\n\n/**\n * Function that returns the catalog processing interval in seconds.\n * @public\n */\nexport type ProcessingIntervalFunction = () => number;\n\n/**\n * Creates a function that returns a random refresh interval between minSeconds and maxSeconds.\n * @returns A {@link RefreshIntervalFunction} that provides the next refresh interval\n * @deprecated use {@link createRandomProcessingInterval} instead\n * @public\n */\nexport function createRandomRefreshInterval(options: {\n  minSeconds: number;\n  maxSeconds: number;\n}): RefreshIntervalFunction {\n  const { minSeconds, maxSeconds } = options;\n  return () => {\n    return Math.random() * (maxSeconds - minSeconds) + minSeconds;\n  };\n}\n\n/**\n * Creates a function that returns a random processing interval between minSeconds and maxSeconds.\n * @returns A {@link ProcessingIntervalFunction} that provides the next processing interval\n * @public\n */\nexport function createRandomProcessingInterval(options: {\n  minSeconds: number;\n  maxSeconds: number;\n}): ProcessingIntervalFunction {\n  const { minSeconds, maxSeconds } = options;\n  return () => {\n    return Math.random() * (maxSeconds - minSeconds) + minSeconds;\n  };\n}\n","/*\n * Copyright 2021 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { EntitiesSearchFilter, EntityFilter } from '../../catalog';\n\n/**\n * Forms a full EntityFilter based on a single key-value(s) object.\n */\nexport function basicEntityFilter(\n  items: Record<string, string | string[]>,\n): EntityFilter {\n  const filtersByKey: Record<string, EntitiesSearchFilter> = {};\n\n  for (const [key, value] of Object.entries(items)) {\n    const values = [value].flat();\n\n    const f =\n      key in filtersByKey\n        ? filtersByKey[key]\n        : (filtersByKey[key] = { key, values: [] });\n\n    f.values!.push(...values);\n  }\n\n  return { anyOf: [{ allOf: Object.values(filtersByKey) }] };\n}\n","/*\n * Copyright 2021 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { InputError } from '@backstage/errors';\n\n/**\n * Takes a single unknown parameter and makes sure that it's a string that can\n * be parsed as an integer.\n */\nexport function parseIntegerParam(\n  param: unknown,\n  ctx: string,\n): number | undefined {\n  if (param === undefined) {\n    return undefined;\n  }\n\n  if (typeof param !== 'string') {\n    throw new InputError(`Invalid ${ctx}, not an integer on string form`);\n  }\n\n  const parsed = parseInt(param, 10);\n  if (!Number.isInteger(parsed) || String(parsed) !== param) {\n    throw new InputError(`Invalid ${ctx}, not an integer`);\n  }\n\n  return parsed;\n}\n\n/**\n * Takes a single unknown parameter and makes sure that it's a string.\n */\nexport function parseStringParam(\n  param: unknown,\n  ctx: string,\n): string | undefined {\n  if (param === undefined) {\n    return undefined;\n  }\n\n  if (typeof param !== 'string') {\n    throw new InputError(`Invalid ${ctx}, not a string`);\n  }\n\n  return param;\n}\n\n/**\n * Takes a single unknown parameter and makes sure that it's a single string or\n * an array of strings, and returns as an array.\n */\nexport function parseStringsParam(\n  param: unknown,\n  ctx: string,\n): string[] | undefined {\n  if (param === undefined) {\n    return undefined;\n  }\n\n  const array = [param].flat();\n  if (array.some(p => typeof p !== 'string')) {\n    throw new InputError(`Invalid ${ctx}, not a string`);\n  }\n\n  return array as string[];\n}\n","/*\n * Copyright 2021 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { InputError } from '@backstage/errors';\nimport { EntitiesSearchFilter, EntityFilter } from '../../catalog';\nimport { parseStringsParam } from './common';\n\n/**\n * Parses the filtering part of a query, like\n * /entities?filter=metadata.namespace=default,kind=Component\n */\nexport function parseEntityFilterParams(\n  params: Record<string, unknown>,\n): EntityFilter | undefined {\n  // Each filter string is on the form a=b,c=d\n  const filterStrings = parseStringsParam(params.filter, 'filter');\n  if (!filterStrings) {\n    return undefined;\n  }\n\n  // Outer array: \"any of the inner ones\"\n  // Inner arrays: \"all of these must match\"\n  const filters = filterStrings.map(parseEntityFilterString).filter(Boolean);\n  if (!filters.length) {\n    return undefined;\n  }\n\n  return { anyOf: filters.map(f => ({ allOf: f! })) };\n}\n\n/**\n * Parses a single filter string as seen in a filter query, for example\n * metadata.namespace=default,kind=Component\n */\nexport function parseEntityFilterString(\n  filterString: string,\n): EntitiesSearchFilter[] | undefined {\n  const statements = filterString\n    .split(',')\n    .map(s => s.trim())\n    .filter(Boolean);\n\n  if (!statements.length) {\n    return undefined;\n  }\n\n  const filtersByKey: Record<string, EntitiesSearchFilter> = {};\n\n  for (const statement of statements) {\n    const equalsIndex = statement.indexOf('=');\n\n    const key =\n      equalsIndex === -1 ? statement : statement.substr(0, equalsIndex).trim();\n    const value =\n      equalsIndex === -1 ? undefined : statement.substr(equalsIndex + 1).trim();\n    if (!key) {\n      throw new InputError(\n        `Invalid filter, '${statement}' is not a valid statement (expected a string on the form a=b or a= or a)`,\n      );\n    }\n\n    const f =\n      key in filtersByKey ? filtersByKey[key] : (filtersByKey[key] = { key });\n\n    if (value !== undefined) {\n      f.values = f.values || [];\n      f.values.push(value);\n    }\n  }\n\n  return Object.values(filtersByKey);\n}\n","/*\n * Copyright 2021 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { InputError } from '@backstage/errors';\nimport { EntityPagination } from '../../catalog';\nimport { parseIntegerParam, parseStringParam } from './common';\n\n/**\n * Parses the pagination related parameters out of a query, e.g.\n * /entities?offset=100&limit=10\n */\nexport function parseEntityPaginationParams(\n  params: Record<string, unknown>,\n): EntityPagination | undefined {\n  const offset = parseIntegerParam(params.offset, 'offset');\n  const limit = parseIntegerParam(params.limit, 'limit');\n  const after = parseStringParam(params.after, 'after');\n\n  if (offset === undefined && limit === undefined && after === undefined) {\n    return undefined;\n  }\n\n  if (offset !== undefined && offset < 0) {\n    throw new InputError(`Invalid offset, must be zero or greater`);\n  }\n  if (limit !== undefined && limit <= 0) {\n    throw new InputError(`Invalid limit, must be greater than zero`);\n  }\n  if (after !== undefined && !after) {\n    throw new InputError(`Invalid after, must not be empty`);\n  }\n\n  return {\n    ...(offset !== undefined ? { offset } : {}),\n    ...(limit !== undefined ? { limit } : {}),\n    ...(after !== undefined ? { after } : {}),\n  };\n}\n","/*\n * Copyright 2021 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Entity } from '@backstage/catalog-model';\nimport { InputError } from '@backstage/errors';\nimport lodash from 'lodash';\nimport { RecursivePartial } from '../../util';\nimport { parseStringsParam } from './common';\n\nexport function parseEntityTransformParams(\n  params: Record<string, unknown>,\n): ((entity: Entity) => Entity) | undefined {\n  const fieldsStrings = parseStringsParam(params.fields, 'fields');\n  if (!fieldsStrings) {\n    return undefined;\n  }\n\n  const fields = fieldsStrings\n    .map(s => s.split(','))\n    .flat()\n    .map(s => s.trim())\n    .filter(Boolean);\n\n  if (!fields.length) {\n    return undefined;\n  }\n\n  if (fields.some(f => f.includes('['))) {\n    throw new InputError('invalid fields, array type fields are not supported');\n  }\n\n  return input => {\n    const output: RecursivePartial<Entity> = {};\n\n    for (const field of fields) {\n      const value = lodash.get(input, field);\n      if (value !== undefined) {\n        lodash.set(output, field, value);\n      }\n    }\n\n    return output as Entity;\n  };\n}\n","/*\n * Copyright 2020 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { InputError, NotAllowedError } from '@backstage/errors';\nimport { Request } from 'express';\nimport lodash from 'lodash';\nimport { z } from 'zod';\n\nexport async function requireRequestBody(req: Request): Promise<unknown> {\n  const contentType = req.header('content-type');\n  if (!contentType) {\n    throw new InputError('Content-Type missing');\n  } else if (!contentType.match(/^application\\/json($|;)/)) {\n    throw new InputError('Illegal Content-Type');\n  }\n\n  const body = req.body;\n  if (!body) {\n    throw new InputError('Missing request body');\n  } else if (!lodash.isPlainObject(body)) {\n    throw new InputError('Expected body to be a JSON object');\n  } else if (Object.keys(body).length === 0) {\n    // Because of how express.json() translates the empty body to {}\n    throw new InputError('Empty request body');\n  }\n\n  return body;\n}\n\nexport const locationInput = z\n  .object({\n    type: z.string(),\n    target: z.string(),\n    presence: z.literal('required').or(z.literal('optional')).optional(),\n  })\n  .strict(); // no unknown keys;\n\nexport async function validateRequestBody<T>(\n  req: Request,\n  schema: z.Schema<T>,\n): Promise<T> {\n  const body = await requireRequestBody(req);\n  try {\n    return await schema.parse(body);\n  } catch (e) {\n    throw new InputError(`Malformed request: ${e}`);\n  }\n}\n\nexport function disallowReadonlyMode(readonly: boolean) {\n  if (readonly) {\n    throw new NotAllowedError('This operation not allowed in readonly mode');\n  }\n}\n","/*\n * Copyright 2022 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { InputError } from '@backstage/errors';\nimport { parseStringsParam } from './common';\n\n/**\n * Parses the facets part of a facet query, like\n * /entity-facets?filter=metadata.namespace=default,kind=Component&facet=metadata.namespace\n */\nexport function parseEntityFacetParams(\n  params: Record<string, unknown>,\n): string[] {\n  // Each facet string is on the form a.b.c\n  const facetStrings = parseStringsParam(params.facet, 'facet');\n  if (facetStrings) {\n    const filtered = facetStrings.filter(Boolean);\n    if (filtered.length) {\n      return filtered;\n    }\n  }\n\n  throw new InputError('Missing facet parameter');\n}\n","/*\n * Copyright 2020 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { errorHandler } from '@backstage/backend-common';\nimport { stringifyEntityRef } from '@backstage/catalog-model';\nimport { Config } from '@backstage/config';\nimport { NotFoundError } from '@backstage/errors';\nimport express from 'express';\nimport Router from 'express-promise-router';\nimport { Logger } from 'winston';\nimport yn from 'yn';\nimport { EntitiesCatalog } from '../catalog';\nimport { LocationAnalyzer } from '../ingestion/types';\nimport {\n  basicEntityFilter,\n  parseEntityFilterParams,\n  parseEntityPaginationParams,\n  parseEntityTransformParams,\n} from './request';\nimport {\n  disallowReadonlyMode,\n  locationInput,\n  validateRequestBody,\n} from './util';\nimport { RefreshOptions, LocationService, RefreshService } from './types';\nimport { z } from 'zod';\nimport { parseEntityFacetParams } from './request/parseEntityFacetParams';\n\n/**\n * Options used by {@link createRouter}.\n *\n * @public\n */\nexport interface RouterOptions {\n  entitiesCatalog?: EntitiesCatalog;\n  locationAnalyzer?: LocationAnalyzer;\n  locationService: LocationService;\n  refreshService?: RefreshService;\n  logger: Logger;\n  config: Config;\n  permissionIntegrationRouter?: express.Router;\n}\n\n/**\n * Creates a catalog router.\n *\n * @public\n */\nexport async function createRouter(\n  options: RouterOptions,\n): Promise<express.Router> {\n  const {\n    entitiesCatalog,\n    locationAnalyzer,\n    locationService,\n    refreshService,\n    config,\n    logger,\n    permissionIntegrationRouter,\n  } = options;\n\n  const router = Router();\n  router.use(express.json());\n\n  const readonlyEnabled =\n    config.getOptionalBoolean('catalog.readonly') || false;\n  if (readonlyEnabled) {\n    logger.info('Catalog is running in readonly mode');\n  }\n\n  if (refreshService) {\n    router.post('/refresh', async (req, res) => {\n      const refreshOptions: RefreshOptions = req.body;\n      refreshOptions.authorizationToken = getBearerToken(\n        req.header('authorization'),\n      );\n\n      await refreshService.refresh(refreshOptions);\n      res.status(200).send();\n    });\n  }\n\n  if (permissionIntegrationRouter) {\n    router.use(permissionIntegrationRouter);\n  }\n\n  if (entitiesCatalog) {\n    router\n      .get('/entities', async (req, res) => {\n        const { entities, pageInfo } = await entitiesCatalog.entities({\n          filter: parseEntityFilterParams(req.query),\n          fields: parseEntityTransformParams(req.query),\n          pagination: parseEntityPaginationParams(req.query),\n          authorizationToken: getBearerToken(req.header('authorization')),\n        });\n\n        // Add a Link header to the next page\n        if (pageInfo.hasNextPage) {\n          const url = new URL(`http://ignored${req.url}`);\n          url.searchParams.delete('offset');\n          url.searchParams.set('after', pageInfo.endCursor);\n          res.setHeader('link', `<${url.pathname}${url.search}>; rel=\"next\"`);\n        }\n\n        // TODO(freben): encode the pageInfo in the response\n        res.json(entities);\n      })\n      .get('/entities/by-uid/:uid', async (req, res) => {\n        const { uid } = req.params;\n        const { entities } = await entitiesCatalog.entities({\n          filter: basicEntityFilter({ 'metadata.uid': uid }),\n          authorizationToken: getBearerToken(req.header('authorization')),\n        });\n        if (!entities.length) {\n          throw new NotFoundError(`No entity with uid ${uid}`);\n        }\n        res.status(200).json(entities[0]);\n      })\n      .delete('/entities/by-uid/:uid', async (req, res) => {\n        const { uid } = req.params;\n        await entitiesCatalog.removeEntityByUid(uid, {\n          authorizationToken: getBearerToken(req.header('authorization')),\n        });\n        res.status(204).end();\n      })\n      .get('/entities/by-name/:kind/:namespace/:name', async (req, res) => {\n        const { kind, namespace, name } = req.params;\n        const { entities } = await entitiesCatalog.entities({\n          filter: basicEntityFilter({\n            kind: kind,\n            'metadata.namespace': namespace,\n            'metadata.name': name,\n          }),\n          authorizationToken: getBearerToken(req.header('authorization')),\n        });\n        if (!entities.length) {\n          throw new NotFoundError(\n            `No entity named '${name}' found, with kind '${kind}' in namespace '${namespace}'`,\n          );\n        }\n        res.status(200).json(entities[0]);\n      })\n      .get(\n        '/entities/by-name/:kind/:namespace/:name/ancestry',\n        async (req, res) => {\n          const { kind, namespace, name } = req.params;\n          const entityRef = stringifyEntityRef({ kind, namespace, name });\n          const response = await entitiesCatalog.entityAncestry(entityRef);\n          res.status(200).json(response);\n        },\n      )\n      .get('/entity-facets', async (req, res) => {\n        const response = await entitiesCatalog.facets({\n          filter: parseEntityFilterParams(req.query),\n          facets: parseEntityFacetParams(req.query),\n          authorizationToken: getBearerToken(req.header('authorization')),\n        });\n        res.status(200).json(response);\n      });\n  }\n\n  if (locationService) {\n    router\n      .post('/locations', async (req, res) => {\n        const location = await validateRequestBody(req, locationInput);\n        const dryRun = yn(req.query.dryRun, { default: false });\n\n        // when in dryRun addLocation is effectively a read operation so we don't\n        // need to disallow readonly\n        if (!dryRun) {\n          disallowReadonlyMode(readonlyEnabled);\n        }\n\n        const output = await locationService.createLocation(location, dryRun, {\n          authorizationToken: getBearerToken(req.header('authorization')),\n        });\n        res.status(201).json(output);\n      })\n      .get('/locations', async (req, res) => {\n        const locations = await locationService.listLocations({\n          authorizationToken: getBearerToken(req.header('authorization')),\n        });\n        res.status(200).json(locations.map(l => ({ data: l })));\n      })\n\n      .get('/locations/:id', async (req, res) => {\n        const { id } = req.params;\n        const output = await locationService.getLocation(id, {\n          authorizationToken: getBearerToken(req.header('authorization')),\n        });\n        res.status(200).json(output);\n      })\n      .delete('/locations/:id', async (req, res) => {\n        disallowReadonlyMode(readonlyEnabled);\n\n        const { id } = req.params;\n        await locationService.deleteLocation(id, {\n          authorizationToken: getBearerToken(req.header('authorization')),\n        });\n        res.status(204).end();\n      });\n  }\n\n  if (locationAnalyzer) {\n    router.post('/analyze-location', async (req, res) => {\n      const body = await validateRequestBody(\n        req,\n        z.object({ location: locationInput }),\n      );\n      const schema = z.object({ location: locationInput });\n      const output = await locationAnalyzer.analyzeLocation(schema.parse(body));\n      res.status(200).json(output);\n    });\n  }\n\n  router.use(errorHandler());\n  return router;\n}\n\nfunction getBearerToken(\n  authorizationHeader: string | undefined,\n): string | undefined {\n  if (typeof authorizationHeader !== 'string') {\n    return undefined;\n  }\n  const matches = authorizationHeader.match(/Bearer\\s+(\\S+)/i);\n  return matches?.[1];\n}\n","/*\n * Copyright 2021 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Config } from '@backstage/config';\nimport path from 'path';\nimport { getEntityLocationRef } from '../../processing/util';\nimport { EntityProvider, EntityProviderConnection } from '../../api';\nimport { locationSpecToLocationEntity } from '../../util/conversion';\n\nexport class ConfigLocationEntityProvider implements EntityProvider {\n  constructor(private readonly config: Config) {}\n\n  getProviderName(): string {\n    return 'ConfigLocationProvider';\n  }\n\n  async connect(connection: EntityProviderConnection): Promise<void> {\n    const entities = this.getEntitiesFromConfig();\n    await connection.applyMutation({\n      type: 'full',\n      entities,\n    });\n\n    if (this.config.subscribe) {\n      let currentKey = JSON.stringify(entities);\n\n      this.config.subscribe(() => {\n        const newEntities = this.getEntitiesFromConfig();\n        const newKey = JSON.stringify(newEntities);\n\n        if (currentKey !== newKey) {\n          currentKey = newKey;\n          connection.applyMutation({\n            type: 'full',\n            entities: newEntities,\n          });\n        }\n      });\n    }\n  }\n\n  private getEntitiesFromConfig() {\n    const locationConfigs =\n      this.config.getOptionalConfigArray('catalog.locations') ?? [];\n\n    return locationConfigs.map(location => {\n      const type = location.getString('type');\n      const target = location.getString('target');\n      const entity = locationSpecToLocationEntity({\n        type,\n        target: type === 'file' ? path.resolve(target) : target,\n      });\n      const locationKey = getEntityLocationRef(entity);\n      return { entity, locationKey };\n    });\n  }\n}\n","/*\n * Copyright 2021 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Location } from '@backstage/catalog-client';\nimport { ConflictError, NotFoundError } from '@backstage/errors';\nimport { Knex } from 'knex';\nimport { v4 as uuid } from 'uuid';\nimport { DbLocationsRow } from '../../database/tables';\nimport { getEntityLocationRef } from '../../processing/util';\nimport { EntityProvider, EntityProviderConnection } from '../../api';\nimport { locationSpecToLocationEntity } from '../../util/conversion';\nimport { LocationInput, LocationStore } from '../../service';\n\nexport class DefaultLocationStore implements LocationStore, EntityProvider {\n  private _connection: EntityProviderConnection | undefined;\n\n  constructor(private readonly db: Knex) {}\n\n  getProviderName(): string {\n    return 'DefaultLocationStore';\n  }\n\n  async createLocation(input: LocationInput): Promise<Location> {\n    const location = await this.db.transaction(async tx => {\n      // Attempt to find a previous location matching the input\n      const previousLocations = await this.locations(tx);\n      // TODO: when location id's are a compilation of input target we can remove this full\n      // lookup of locations first and just grab the by that instead.\n      const previousLocation = previousLocations.some(\n        l => input.type === l.type && input.target === l.target,\n      );\n      if (previousLocation) {\n        throw new ConflictError(\n          `Location ${input.type}:${input.target} already exists`,\n        );\n      }\n\n      const inner: DbLocationsRow = {\n        id: uuid(),\n        type: input.type,\n        target: input.target,\n      };\n\n      await tx<DbLocationsRow>('locations').insert(inner);\n\n      return inner;\n    });\n    const entity = locationSpecToLocationEntity(location);\n    await this.connection.applyMutation({\n      type: 'delta',\n      added: [{ entity, locationKey: getEntityLocationRef(entity) }],\n      removed: [],\n    });\n\n    return location;\n  }\n\n  async listLocations(): Promise<Location[]> {\n    return await this.locations();\n  }\n\n  async getLocation(id: string): Promise<Location> {\n    const items = await this.db<DbLocationsRow>('locations')\n      .where({ id })\n      .select();\n\n    if (!items.length) {\n      throw new NotFoundError(`Found no location with ID ${id}`);\n    }\n    return items[0];\n  }\n\n  async deleteLocation(id: string): Promise<void> {\n    if (!this.connection) {\n      throw new Error('location store is not initialized');\n    }\n\n    const deleted = await this.db.transaction(async tx => {\n      const [location] = await tx<DbLocationsRow>('locations')\n        .where({ id })\n        .select();\n\n      if (!location) {\n        throw new NotFoundError(`Found no location with ID ${id}`);\n      }\n\n      await tx<DbLocationsRow>('locations').where({ id }).del();\n      return location;\n    });\n    const entity = locationSpecToLocationEntity(deleted);\n    await this.connection.applyMutation({\n      type: 'delta',\n      added: [],\n      removed: [{ entity, locationKey: getEntityLocationRef(entity) }],\n    });\n  }\n\n  private get connection(): EntityProviderConnection {\n    if (!this._connection) {\n      throw new Error('location store is not initialized');\n    }\n\n    return this._connection;\n  }\n\n  async connect(connection: EntityProviderConnection): Promise<void> {\n    this._connection = connection;\n\n    const locations = await this.locations();\n\n    const entities = locations.map(location => {\n      const entity = locationSpecToLocationEntity(location);\n      return { entity, locationKey: getEntityLocationRef(entity) };\n    });\n\n    await this.connection.applyMutation({\n      type: 'full',\n      entities,\n    });\n  }\n\n  private async locations(dbOrTx: Knex.Transaction | Knex = this.db) {\n    const locations = await dbOrTx<DbLocationsRow>('locations').select();\n    return (\n      locations\n        // TODO(blam): We should create a mutation to remove this location for everyone\n        // eventually when it's all done and dusted\n        .filter(({ type }) => type !== 'bootstrap')\n        .map(item => ({\n          id: item.id,\n          target: item.target,\n          type: item.type,\n        }))\n    );\n  }\n}\n","/*\n * Copyright 2020 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Logger } from 'winston';\nimport parseGitUrl from 'git-url-parse';\nimport { Entity } from '@backstage/catalog-model';\nimport { ScmIntegrationRegistry } from '@backstage/integration';\nimport {\n  AnalyzeLocationRequest,\n  AnalyzeLocationResponse,\n  LocationAnalyzer,\n} from './types';\n\nexport class RepoLocationAnalyzer implements LocationAnalyzer {\n  private readonly logger: Logger;\n  private readonly scmIntegrations: ScmIntegrationRegistry;\n\n  constructor(logger: Logger, scmIntegrations: ScmIntegrationRegistry) {\n    this.logger = logger;\n    this.scmIntegrations = scmIntegrations;\n  }\n  async analyzeLocation(\n    request: AnalyzeLocationRequest,\n  ): Promise<AnalyzeLocationResponse> {\n    const { owner, name } = parseGitUrl(request.location.target);\n    const entity: Entity = {\n      apiVersion: 'backstage.io/v1alpha1',\n      kind: 'Component',\n      metadata: {\n        name: name,\n      },\n      spec: { type: 'other', lifecycle: 'unknown' },\n    };\n\n    const integration = this.scmIntegrations.byUrl(request.location.target);\n    let annotationPrefix;\n    switch (integration?.type) {\n      case 'azure':\n        annotationPrefix = 'dev.azure.com';\n        break;\n      case 'bitbucket':\n        annotationPrefix = 'bitbucket.org';\n        break;\n      case 'github':\n        annotationPrefix = 'github.com';\n        break;\n      case 'gitlab':\n        annotationPrefix = 'gitlab.com';\n        break;\n      default:\n        break;\n    }\n\n    if (annotationPrefix) {\n      entity.metadata.annotations = {\n        [`${annotationPrefix}/project-slug`]: `${owner}/${name}`,\n      };\n    }\n\n    this.logger.debug(`entity created for ${request.location.target}`);\n    return {\n      existingEntityFiles: [],\n      generateEntities: [{ entity, fields: [] }],\n    };\n  }\n}\n","/*\n * Copyright 2021 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { ConflictError, InputError } from '@backstage/errors';\nimport { DateTime } from 'luxon';\n\n/**\n * Takes a TIMESTAMP type column and converts it to a DateTime.\n *\n * Some engines return the SQL string form (e.g. 'YYYY-MM-DD hh:mm:ss'), some\n * return ISO string form (e.g. 'YYYY-MM-DDThh:mm:ss.SSSZ'), some return a js\n * Date object.\n */\nexport function timestampToDateTime(input: Date | string): DateTime {\n  try {\n    if (typeof input === 'object') {\n      return DateTime.fromJSDate(input).toUTC();\n    }\n\n    const result = input.includes(' ')\n      ? DateTime.fromSQL(input, { zone: 'utc' })\n      : DateTime.fromISO(input, { zone: 'utc' });\n    if (!result.isValid) {\n      throw new TypeError('Not valid');\n    }\n\n    return result;\n  } catch (e) {\n    throw new InputError(`Failed to parse database timestamp ${input}`, e);\n  }\n}\n\n/**\n * Rethrows an error, possibly translating it to a more precise error type.\n */\nexport function rethrowError(e: any): never {\n  if (\n    /SQLITE_CONSTRAINT: UNIQUE/.test(e.message) ||\n    /unique constraint/.test(e.message)\n  ) {\n    throw new ConflictError(`Rejected due to a conflicting entity`, e);\n  }\n\n  throw e;\n}\n","/*\n * Copyright 2021 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  Counter,\n  CounterConfiguration,\n  Gauge,\n  GaugeConfiguration,\n  Histogram,\n  HistogramConfiguration,\n  register,\n  Summary,\n  SummaryConfiguration,\n} from 'prom-client';\n\nexport function createCounterMetric<T extends string>(\n  config: CounterConfiguration<T>,\n): Counter<T> {\n  const existing = register.getSingleMetric(config.name) as Counter<T>;\n  return existing || new Counter<T>(config);\n}\n\nexport function createGaugeMetric<T extends string>(\n  config: GaugeConfiguration<T>,\n): Gauge<T> {\n  const existing = register.getSingleMetric(config.name) as Gauge<T>;\n  return existing || new Gauge<T>(config);\n}\n\nexport function createSummaryMetric<T extends string>(\n  config: SummaryConfiguration<T>,\n): Summary<T> {\n  const existing = register.getSingleMetric(config.name) as Summary<T>;\n  return existing || new Summary<T>(config);\n}\n\nexport function createHistogramMetric<T extends string>(\n  config: HistogramConfiguration<T>,\n): Histogram<T> {\n  const existing = register.getSingleMetric(config.name) as Histogram<T>;\n  return existing || new Histogram<T>(config);\n}\n","/*\n * Copyright 2021 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Knex } from 'knex';\nimport { createGaugeMetric } from '../util/metrics';\nimport { DbRefreshStateRow, DbRelationsRow, DbLocationsRow } from './tables';\n\nexport function initDatabaseMetrics(knex: Knex) {\n  const seen = new Set<string>();\n  return {\n    entities_count: createGaugeMetric({\n      name: 'catalog_entities_count',\n      help: 'Total amount of entities in the catalog',\n      labelNames: ['kind'],\n      async collect() {\n        const result = await knex<DbRefreshStateRow>('refresh_state').select(\n          'entity_ref',\n        );\n        const results = result\n          .map(row => row.entity_ref.split(':')[0])\n          .reduce((acc, e) => acc.set(e, (acc.get(e) || 0) + 1), new Map());\n\n        results.forEach((value, key) => {\n          seen.add(key);\n          this.set({ kind: key }, value);\n        });\n\n        // Set all the entities that were not seen to 0 and delete them from the seen set.\n        seen.forEach(key => {\n          if (!results.has(key)) {\n            this.set({ kind: key }, 0);\n            seen.delete(key);\n          }\n        });\n      },\n    }),\n    registered_locations: createGaugeMetric({\n      name: 'catalog_registered_locations_count',\n      help: 'Total amount of registered locations in the catalog',\n      async collect() {\n        const total = await knex<DbLocationsRow>('locations').count({\n          count: '*',\n        });\n        this.set(Number(total[0].count));\n      },\n    }),\n    relations: createGaugeMetric({\n      name: 'catalog_relations_count',\n      help: 'Total amount of relations between entities',\n      async collect() {\n        const total = await knex<DbRelationsRow>('relations').count({\n          count: '*',\n        });\n        this.set(Number(total[0].count));\n      },\n    }),\n  };\n}\n","/*\n * Copyright 2021 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Entity } from '@backstage/catalog-model';\nimport { createHash } from 'crypto';\nimport stableStringify from 'fast-json-stable-stringify';\n\nexport function generateStableHash(entity: Entity) {\n  return createHash('sha1')\n    .update(stableStringify({ ...entity }))\n    .digest('hex');\n}\n","/*\n * Copyright 2021 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Entity, stringifyEntityRef } from '@backstage/catalog-model';\nimport { ConflictError, isError, NotFoundError } from '@backstage/errors';\nimport { Knex } from 'knex';\nimport lodash from 'lodash';\nimport { v4 as uuid } from 'uuid';\nimport type { Logger } from 'winston';\nimport {\n  Transaction,\n  GetProcessableEntitiesResult,\n  ProcessingDatabase,\n  RefreshStateItem,\n  RefreshOptions,\n  ReplaceUnprocessedEntitiesOptions,\n  UpdateProcessedEntityOptions,\n  ListAncestorsOptions,\n  ListAncestorsResult,\n  UpdateEntityCacheOptions,\n  ListParentsOptions,\n  ListParentsResult,\n} from './types';\nimport { DeferredEntity } from '../processing/types';\nimport { RefreshIntervalFunction } from '../processing/refresh';\nimport { rethrowError, timestampToDateTime } from './conversion';\nimport { initDatabaseMetrics } from './metrics';\nimport {\n  DbRefreshStateReferencesRow,\n  DbRefreshStateRow,\n  DbRelationsRow,\n} from './tables';\n\nimport { generateStableHash } from './util';\nimport { isDatabaseConflictError } from '@backstage/backend-common';\n\n// The number of items that are sent per batch to the database layer, when\n// doing .batchInsert calls to knex. This needs to be low enough to not cause\n// errors in the underlying engine due to exceeding query limits, but large\n// enough to get the speed benefits.\nconst BATCH_SIZE = 50;\nconst MAX_ANCESTOR_DEPTH = 32;\n\nexport class DefaultProcessingDatabase implements ProcessingDatabase {\n  constructor(\n    private readonly options: {\n      database: Knex;\n      logger: Logger;\n      refreshInterval: RefreshIntervalFunction;\n    },\n  ) {\n    initDatabaseMetrics(options.database);\n  }\n\n  async updateProcessedEntity(\n    txOpaque: Transaction,\n    options: UpdateProcessedEntityOptions,\n  ): Promise<void> {\n    const tx = txOpaque as Knex.Transaction;\n    const {\n      id,\n      processedEntity,\n      resultHash,\n      errors,\n      relations,\n      deferredEntities,\n      locationKey,\n    } = options;\n    const refreshResult = await tx<DbRefreshStateRow>('refresh_state')\n      .update({\n        processed_entity: JSON.stringify(processedEntity),\n        result_hash: resultHash,\n        errors,\n        location_key: locationKey,\n      })\n      .where('entity_id', id)\n      .andWhere(inner => {\n        if (!locationKey) {\n          return inner.whereNull('location_key');\n        }\n        return inner\n          .where('location_key', locationKey)\n          .orWhereNull('location_key');\n      });\n    if (refreshResult === 0) {\n      throw new ConflictError(\n        `Conflicting write of processing result for ${id} with location key '${locationKey}'`,\n      );\n    }\n\n    // Schedule all deferred entities for future processing.\n    await this.addUnprocessedEntities(tx, {\n      entities: deferredEntities,\n      sourceEntityRef: stringifyEntityRef(processedEntity),\n    });\n\n    // Delete old relations\n    await tx<DbRelationsRow>('relations')\n      .where({ originating_entity_id: id })\n      .delete();\n\n    // Batch insert new relations\n    const relationRows: DbRelationsRow[] = relations.map(\n      ({ source, target, type }) => ({\n        originating_entity_id: id,\n        source_entity_ref: stringifyEntityRef(source),\n        target_entity_ref: stringifyEntityRef(target),\n        type,\n      }),\n    );\n    await tx.batchInsert(\n      'relations',\n      this.deduplicateRelations(relationRows),\n      BATCH_SIZE,\n    );\n  }\n\n  async updateProcessedEntityErrors(\n    txOpaque: Transaction,\n    options: UpdateProcessedEntityOptions,\n  ): Promise<void> {\n    const tx = txOpaque as Knex.Transaction;\n    const { id, errors, resultHash } = options;\n\n    await tx<DbRefreshStateRow>('refresh_state')\n      .update({\n        errors,\n        result_hash: resultHash,\n      })\n      .where('entity_id', id);\n  }\n\n  async updateEntityCache(\n    txOpaque: Transaction,\n    options: UpdateEntityCacheOptions,\n  ): Promise<void> {\n    const tx = txOpaque as Knex.Transaction;\n    const { id, state } = options;\n\n    await tx<DbRefreshStateRow>('refresh_state')\n      .update({ cache: JSON.stringify(state ?? {}) })\n      .where('entity_id', id);\n  }\n\n  async replaceUnprocessedEntities(\n    txOpaque: Transaction,\n    options: ReplaceUnprocessedEntitiesOptions,\n  ): Promise<void> {\n    const tx = txOpaque as Knex.Transaction;\n\n    const { toAdd, toUpsert, toRemove } = await this.createDelta(tx, options);\n\n    if (toRemove.length) {\n      // TODO(freben): Batch split, to not hit variable limits?\n      /*\n      WITH RECURSIVE\n        -- All the nodes that can be reached downwards from our root\n        descendants(root_id, entity_ref) AS (\n          SELECT id, target_entity_ref\n          FROM refresh_state_references\n          WHERE source_key = \"R1\" AND target_entity_ref = \"A\"\n          UNION\n          SELECT descendants.root_id, target_entity_ref\n          FROM descendants\n          JOIN refresh_state_references ON source_entity_ref = descendants.entity_ref\n        ),\n        -- All the nodes that can be reached upwards from the descendants\n        ancestors(root_id, via_entity_ref, to_entity_ref) AS (\n          SELECT CAST(NULL as INT), entity_ref, entity_ref\n          FROM descendants\n          UNION\n          SELECT\n            CASE WHEN source_key IS NOT NULL THEN id ELSE NULL END,\n            source_entity_ref,\n            ancestors.to_entity_ref\n          FROM ancestors\n          JOIN refresh_state_references ON target_entity_ref = ancestors.via_entity_ref\n        )\n      -- Start out with all of the descendants\n      SELECT descendants.entity_ref\n      FROM descendants\n      -- Expand with all ancestors that point to those, but aren't the current root\n      LEFT OUTER JOIN ancestors\n        ON ancestors.to_entity_ref = descendants.entity_ref\n        AND ancestors.root_id IS NOT NULL\n        AND ancestors.root_id != descendants.root_id\n      -- Exclude all lines that had such a foreign ancestor\n      WHERE ancestors.root_id IS NULL;\n      */\n      const removedCount = await tx<DbRefreshStateRow>('refresh_state')\n        .whereIn('entity_ref', function orphanedEntityRefs(orphans) {\n          return (\n            orphans\n              // All the nodes that can be reached downwards from our root\n              .withRecursive('descendants', function descendants(outer) {\n                return outer\n                  .select({ root_id: 'id', entity_ref: 'target_entity_ref' })\n                  .from('refresh_state_references')\n                  .where('source_key', options.sourceKey)\n                  .whereIn('target_entity_ref', toRemove)\n                  .union(function recursive(inner) {\n                    return inner\n                      .select({\n                        root_id: 'descendants.root_id',\n                        entity_ref:\n                          'refresh_state_references.target_entity_ref',\n                      })\n                      .from('descendants')\n                      .join('refresh_state_references', {\n                        'descendants.entity_ref':\n                          'refresh_state_references.source_entity_ref',\n                      });\n                  });\n              })\n              // All the nodes that can be reached upwards from the descendants\n              .withRecursive('ancestors', function ancestors(outer) {\n                return outer\n                  .select({\n                    root_id: tx.raw('CAST(NULL as INT)', []),\n                    via_entity_ref: 'entity_ref',\n                    to_entity_ref: 'entity_ref',\n                  })\n                  .from('descendants')\n                  .union(function recursive(inner) {\n                    return inner\n                      .select({\n                        root_id: tx.raw(\n                          'CASE WHEN source_key IS NOT NULL THEN id ELSE NULL END',\n                          [],\n                        ),\n                        via_entity_ref: 'source_entity_ref',\n                        to_entity_ref: 'ancestors.to_entity_ref',\n                      })\n                      .from('ancestors')\n                      .join('refresh_state_references', {\n                        target_entity_ref: 'ancestors.via_entity_ref',\n                      });\n                  });\n              })\n              // Start out with all of the descendants\n              .select('descendants.entity_ref')\n              .from('descendants')\n              // Expand with all ancestors that point to those, but aren't the current root\n              .leftOuterJoin('ancestors', function keepaliveRoots() {\n                this.on(\n                  'ancestors.to_entity_ref',\n                  '=',\n                  'descendants.entity_ref',\n                );\n                this.andOnNotNull('ancestors.root_id');\n                this.andOn('ancestors.root_id', '!=', 'descendants.root_id');\n              })\n              .whereNull('ancestors.root_id')\n          );\n        })\n        .delete();\n\n      await tx<DbRefreshStateReferencesRow>('refresh_state_references')\n        .where('source_key', '=', options.sourceKey)\n        .whereIn('target_entity_ref', toRemove)\n        .delete();\n\n      this.options.logger.debug(\n        `removed, ${removedCount} entities: ${JSON.stringify(toRemove)}`,\n      );\n    }\n\n    if (toAdd.length) {\n      // The reason for this chunking, rather than just massively batch\n      // inserting the entire payload, is that we fall back to the individual\n      // upsert mechanism below on conflicts. That path is massively slower than\n      // the fast batch path, so we don't want to end up accidentally having to\n      // for example item-by-item upsert tens of thousands of entities in a\n      // large initial delivery dump. The implication is that the size of these\n      // chunks needs to weigh the benefit of fast successful inserts, against\n      // the drawback of super slow but more rare fallbacks. There's quickly\n      // diminishing returns though with turning up this value way high.\n      for (const chunk of lodash.chunk(toAdd, 50)) {\n        try {\n          await tx.batchInsert(\n            'refresh_state',\n            chunk.map(item => ({\n              entity_id: uuid(),\n              entity_ref: stringifyEntityRef(item.deferred.entity),\n              unprocessed_entity: JSON.stringify(item.deferred.entity),\n              unprocessed_hash: item.hash,\n              errors: '',\n              location_key: item.deferred.locationKey,\n              next_update_at: tx.fn.now(),\n              last_discovery_at: tx.fn.now(),\n            })),\n            BATCH_SIZE,\n          );\n          await tx.batchInsert(\n            'refresh_state_references',\n            chunk.map(item => ({\n              source_key: options.sourceKey,\n              target_entity_ref: stringifyEntityRef(item.deferred.entity),\n            })),\n            BATCH_SIZE,\n          );\n        } catch (error) {\n          if (!isDatabaseConflictError(error)) {\n            throw error;\n          } else {\n            this.options.logger.debug(\n              `Fast insert path failed, falling back to slow path, ${error}`,\n            );\n            toUpsert.push(...chunk);\n          }\n        }\n      }\n    }\n\n    if (toUpsert.length) {\n      for (const {\n        deferred: { entity, locationKey },\n        hash,\n      } of toUpsert) {\n        const entityRef = stringifyEntityRef(entity);\n\n        try {\n          let ok = await this.updateUnprocessedEntity(\n            tx,\n            entity,\n            hash,\n            locationKey,\n          );\n          if (!ok) {\n            ok = await this.insertUnprocessedEntity(\n              tx,\n              entity,\n              hash,\n              locationKey,\n            );\n          }\n\n          if (ok) {\n            await tx<DbRefreshStateReferencesRow>(\n              'refresh_state_references',\n            ).insert({\n              source_key: options.sourceKey,\n              target_entity_ref: entityRef,\n            });\n          } else {\n            const conflictingKey = await this.checkLocationKeyConflict(\n              tx,\n              entityRef,\n              locationKey,\n            );\n            if (conflictingKey) {\n              this.options.logger.warn(\n                `Source ${options.sourceKey} detected conflicting entityRef ${entityRef} already referenced by ${conflictingKey} and now also ${locationKey}`,\n              );\n            }\n          }\n        } catch (error) {\n          this.options.logger.error(\n            `Failed to add '${entityRef}' from source '${options.sourceKey}', ${error}`,\n          );\n        }\n      }\n    }\n  }\n\n  async getProcessableEntities(\n    txOpaque: Transaction,\n    request: { processBatchSize: number },\n  ): Promise<GetProcessableEntitiesResult> {\n    const tx = txOpaque as Knex.Transaction;\n\n    let itemsQuery = tx<DbRefreshStateRow>('refresh_state').select();\n\n    // This avoids duplication of work because of race conditions and is\n    // also fast because locked rows are ignored rather than blocking.\n    // It's only available in MySQL and PostgreSQL\n    if (['mysql', 'mysql2', 'pg'].includes(tx.client.config.client)) {\n      itemsQuery = itemsQuery.forUpdate().skipLocked();\n    }\n\n    const items = await itemsQuery\n      .where('next_update_at', '<=', tx.fn.now())\n      .limit(request.processBatchSize)\n      .orderBy('next_update_at', 'asc');\n\n    const interval = this.options.refreshInterval();\n    await tx<DbRefreshStateRow>('refresh_state')\n      .whereIn(\n        'entity_ref',\n        items.map(i => i.entity_ref),\n      )\n      .update({\n        next_update_at: tx.client.config.client.includes('sqlite3')\n          ? tx.raw(`datetime('now', ?)`, [`${interval} seconds`])\n          : tx.raw(`now() + interval '${interval} seconds'`),\n      });\n\n    return {\n      items: items.map(\n        i =>\n          ({\n            id: i.entity_id,\n            entityRef: i.entity_ref,\n            unprocessedEntity: JSON.parse(i.unprocessed_entity) as Entity,\n            processedEntity: i.processed_entity\n              ? (JSON.parse(i.processed_entity) as Entity)\n              : undefined,\n            resultHash: i.result_hash || '',\n            nextUpdateAt: timestampToDateTime(i.next_update_at),\n            lastDiscoveryAt: timestampToDateTime(i.last_discovery_at),\n            state: i.cache ? JSON.parse(i.cache) : undefined,\n            errors: i.errors,\n            locationKey: i.location_key,\n          } as RefreshStateItem),\n      ),\n    };\n  }\n\n  async listAncestors(\n    txOpaque: Transaction,\n    options: ListAncestorsOptions,\n  ): Promise<ListAncestorsResult> {\n    const tx = txOpaque as Knex.Transaction;\n    const { entityRef } = options;\n    const entityRefs = new Array<string>();\n\n    let currentRef = entityRef.toLocaleLowerCase('en-US');\n    for (let depth = 1; depth <= MAX_ANCESTOR_DEPTH; depth += 1) {\n      const rows = await tx<DbRefreshStateReferencesRow>(\n        'refresh_state_references',\n      )\n        .where({ target_entity_ref: currentRef })\n        .select();\n\n      if (rows.length === 0) {\n        if (depth === 1) {\n          throw new NotFoundError(`Entity ${currentRef} not found`);\n        }\n        throw new NotFoundError(\n          `Entity ${entityRef} has a broken parent reference chain at ${currentRef}`,\n        );\n      }\n\n      const parentRef = rows.find(r => r.source_entity_ref)?.source_entity_ref;\n      if (!parentRef) {\n        // We've reached the top of the tree which is the entityProvider.\n        // In this case we refresh the entity itself.\n        return { entityRefs };\n      }\n      entityRefs.push(parentRef);\n      currentRef = parentRef;\n    }\n    throw new Error(\n      `Unable receive ancestors for ${entityRef}, reached maximum depth of ${MAX_ANCESTOR_DEPTH}`,\n    );\n  }\n\n  async listParents(\n    txOpaque: Transaction,\n    options: ListParentsOptions,\n  ): Promise<ListParentsResult> {\n    const tx = txOpaque as Knex.Transaction;\n\n    const rows = await tx<DbRefreshStateReferencesRow>(\n      'refresh_state_references',\n    )\n      .where({ target_entity_ref: options.entityRef })\n      .select();\n\n    const entityRefs = rows.map(r => r.source_entity_ref!).filter(Boolean);\n\n    return { entityRefs };\n  }\n\n  async refresh(txOpaque: Transaction, options: RefreshOptions): Promise<void> {\n    const tx = txOpaque as Knex.Transaction;\n    const { entityRef } = options;\n\n    const updateResult = await tx<DbRefreshStateRow>('refresh_state')\n      .where({ entity_ref: entityRef.toLocaleLowerCase('en-US') })\n      .update({ next_update_at: tx.fn.now() });\n    if (updateResult === 0) {\n      throw new NotFoundError(`Failed to schedule ${entityRef} for refresh`);\n    }\n  }\n\n  async transaction<T>(fn: (tx: Transaction) => Promise<T>): Promise<T> {\n    try {\n      let result: T | undefined = undefined;\n\n      await this.options.database.transaction(\n        async tx => {\n          // We can't return here, as knex swallows the return type in case the transaction is rolled back:\n          // https://github.com/knex/knex/blob/e37aeaa31c8ef9c1b07d2e4d3ec6607e557d800d/lib/transaction.js#L136\n          result = await fn(tx);\n        },\n        {\n          // If we explicitly trigger a rollback, don't fail.\n          doNotRejectOnRollback: true,\n        },\n      );\n\n      return result!;\n    } catch (e) {\n      this.options.logger.debug(`Error during transaction, ${e}`);\n      throw rethrowError(e);\n    }\n  }\n\n  /**\n   * Attempts to update an existing refresh state row, returning true if it was\n   * updated and false if there was no entity with a matching ref and location key.\n   *\n   * Updating the entity will also cause it to be scheduled for immediate processing.\n   */\n  private async updateUnprocessedEntity(\n    tx: Knex.Transaction,\n    entity: Entity,\n    hash: string,\n    locationKey?: string,\n  ): Promise<boolean> {\n    const entityRef = stringifyEntityRef(entity);\n    const serializedEntity = JSON.stringify(entity);\n\n    const refreshResult = await tx<DbRefreshStateRow>('refresh_state')\n      .update({\n        unprocessed_entity: serializedEntity,\n        unprocessed_hash: hash,\n        location_key: locationKey,\n        last_discovery_at: tx.fn.now(),\n        // We only get to this point if a processed entity actually had any changes, or\n        // if an entity provider requested this mutation, meaning that we can safely\n        // bump the deferred entities to the front of the queue for immediate processing.\n        next_update_at: tx.fn.now(),\n      })\n      .where('entity_ref', entityRef)\n      .andWhere(inner => {\n        if (!locationKey) {\n          return inner.whereNull('location_key');\n        }\n        return inner\n          .where('location_key', locationKey)\n          .orWhereNull('location_key');\n      });\n\n    return refreshResult === 1;\n  }\n\n  /**\n   * Attempts to insert a new refresh state row for the given entity, returning\n   * true if successful and false if there was a conflict.\n   */\n  private async insertUnprocessedEntity(\n    tx: Knex.Transaction,\n    entity: Entity,\n    hash: string,\n    locationKey?: string,\n  ): Promise<boolean> {\n    const entityRef = stringifyEntityRef(entity);\n    const serializedEntity = JSON.stringify(entity);\n\n    try {\n      let query = tx<DbRefreshStateRow>('refresh_state').insert({\n        entity_id: uuid(),\n        entity_ref: entityRef,\n        unprocessed_entity: serializedEntity,\n        unprocessed_hash: hash,\n        errors: '',\n        location_key: locationKey,\n        next_update_at: tx.fn.now(),\n        last_discovery_at: tx.fn.now(),\n      });\n\n      // TODO(Rugvip): only tested towards Postgres and SQLite\n      // We have to do this because the only way to detect if there was a conflict with\n      // SQLite is to catch the error, while Postgres needs to ignore the conflict to not\n      // break the ongoing transaction.\n      if (!tx.client.config.client.includes('sqlite3')) {\n        query = query.onConflict('entity_ref').ignore() as any; // type here does not match runtime\n      }\n\n      // Postgres gives as an object with rowCount, SQLite gives us an array\n      const result: { rowCount?: number; length?: number } = await query;\n      return result.rowCount === 1 || result.length === 1;\n    } catch (error) {\n      // SQLite reached this rather than the rowCount check above\n      if (\n        isError(error) &&\n        error.message.includes('UNIQUE constraint failed')\n      ) {\n        return false;\n      }\n      throw error;\n    }\n  }\n\n  /**\n   * Checks whether a refresh state exists for the given entity that has a\n   * location key that does not match the provided location key.\n   *\n   * @returns The conflicting key if there is one.\n   */\n  private async checkLocationKeyConflict(\n    tx: Knex.Transaction,\n    entityRef: string,\n    locationKey?: string,\n  ): Promise<string | undefined> {\n    const row = await tx<DbRefreshStateRow>('refresh_state')\n      .select('location_key')\n      .where('entity_ref', entityRef)\n      .first();\n\n    const conflictingKey = row?.location_key;\n\n    // If there's no existing key we can't have a conflict\n    if (!conflictingKey) {\n      return undefined;\n    }\n\n    if (conflictingKey !== locationKey) {\n      return conflictingKey;\n    }\n    return undefined;\n  }\n\n  private deduplicateRelations(rows: DbRelationsRow[]): DbRelationsRow[] {\n    return lodash.uniqBy(\n      rows,\n      r => `${r.source_entity_ref}:${r.target_entity_ref}:${r.type}`,\n    );\n  }\n\n  private async createDelta(\n    tx: Knex.Transaction,\n    options: ReplaceUnprocessedEntitiesOptions,\n  ): Promise<{\n    toAdd: { deferred: DeferredEntity; hash: string }[];\n    toUpsert: { deferred: DeferredEntity; hash: string }[];\n    toRemove: string[];\n  }> {\n    if (options.type === 'delta') {\n      return {\n        toAdd: [],\n        toUpsert: options.added.map(e => ({\n          deferred: e,\n          hash: generateStableHash(e.entity),\n        })),\n        toRemove: options.removed.map(e => stringifyEntityRef(e.entity)),\n      };\n    }\n\n    // Grab all of the existing references from the same source, and their locationKeys as well\n    const oldRefs = await tx<DbRefreshStateReferencesRow>(\n      'refresh_state_references',\n    )\n      .leftJoin<DbRefreshStateRow>('refresh_state', {\n        target_entity_ref: 'entity_ref',\n      })\n      .where({ source_key: options.sourceKey })\n      .select({\n        target_entity_ref: 'refresh_state_references.target_entity_ref',\n        location_key: 'refresh_state.location_key',\n        unprocessed_hash: 'refresh_state.unprocessed_hash',\n      });\n\n    const items = options.items.map(deferred => ({\n      deferred,\n      ref: stringifyEntityRef(deferred.entity),\n      hash: generateStableHash(deferred.entity),\n    }));\n\n    const oldRefsSet = new Map(\n      oldRefs.map(r => [\n        r.target_entity_ref,\n        {\n          locationKey: r.location_key,\n          oldEntityHash: r.unprocessed_hash,\n        },\n      ]),\n    );\n    const newRefsSet = new Set(items.map(item => item.ref));\n\n    const toAdd = new Array<{ deferred: DeferredEntity; hash: string }>();\n    const toUpsert = new Array<{ deferred: DeferredEntity; hash: string }>();\n    const toRemove = oldRefs\n      .map(row => row.target_entity_ref)\n      .filter(ref => !newRefsSet.has(ref));\n\n    for (const item of items) {\n      const oldRef = oldRefsSet.get(item.ref);\n      const upsertItem = { deferred: item.deferred, hash: item.hash };\n      if (!oldRef) {\n        // Add any entity that does not exist in the database\n        toAdd.push(upsertItem);\n      } else if (oldRef.locationKey !== item.deferred.locationKey) {\n        // Remove and then re-add any entity that exists, but with a different location key\n        toRemove.push(item.ref);\n        toAdd.push(upsertItem);\n      } else if (oldRef.oldEntityHash !== item.hash) {\n        // Entities with modifications should be pushed through too\n        toUpsert.push(upsertItem);\n      }\n    }\n\n    return { toAdd, toUpsert, toRemove };\n  }\n\n  /**\n   * Add a set of deferred entities for processing.\n   * The entities will be added at the front of the processing queue.\n   */\n  private async addUnprocessedEntities(\n    txOpaque: Transaction,\n    options: {\n      sourceEntityRef: string;\n      entities: DeferredEntity[];\n    },\n  ): Promise<void> {\n    const tx = txOpaque as Knex.Transaction;\n\n    // Keeps track of the entities that we end up inserting to update refresh_state_references afterwards\n    const stateReferences = new Array<string>();\n    const conflictingStateReferences = new Array<string>();\n\n    // Upsert all of the unprocessed entities into the refresh_state table, by\n    // their entity ref.\n    for (const { entity, locationKey } of options.entities) {\n      const entityRef = stringifyEntityRef(entity);\n      const hash = generateStableHash(entity);\n\n      const updated = await this.updateUnprocessedEntity(\n        tx,\n        entity,\n        hash,\n        locationKey,\n      );\n      if (updated) {\n        stateReferences.push(entityRef);\n        continue;\n      }\n\n      const inserted = await this.insertUnprocessedEntity(\n        tx,\n        entity,\n        hash,\n        locationKey,\n      );\n      if (inserted) {\n        stateReferences.push(entityRef);\n        continue;\n      }\n\n      // If the row can't be inserted, we have a conflict, but it could be either\n      // because of a conflicting locationKey or a race with another instance, so check\n      // whether the conflicting entity has the same entityRef but a different locationKey\n      const conflictingKey = await this.checkLocationKeyConflict(\n        tx,\n        entityRef,\n        locationKey,\n      );\n      if (conflictingKey) {\n        this.options.logger.warn(\n          `Detected conflicting entityRef ${entityRef} already referenced by ${conflictingKey} and now also ${locationKey}`,\n        );\n        conflictingStateReferences.push(entityRef);\n      }\n    }\n\n    // Replace all references for the originating entity or source and then create new ones\n    await tx<DbRefreshStateReferencesRow>('refresh_state_references')\n      .whereNotIn('target_entity_ref', conflictingStateReferences)\n      .andWhere({ source_entity_ref: options.sourceEntityRef })\n      .delete();\n    await tx.batchInsert(\n      'refresh_state_references',\n      stateReferences.map(entityRef => ({\n        source_entity_ref: options.sourceEntityRef,\n        target_entity_ref: entityRef,\n      })),\n      BATCH_SIZE,\n    );\n  }\n}\n","/*\n * Copyright 2020 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { resolvePackagePath } from '@backstage/backend-common';\nimport { Knex } from 'knex';\n\nexport async function applyDatabaseMigrations(knex: Knex): Promise<void> {\n  const migrationsDir = resolvePackagePath(\n    '@backstage/plugin-catalog-backend',\n    'migrations',\n  );\n\n  await knex.migrate.latest({\n    directory: migrationsDir,\n  });\n}\n","/*\n * Copyright 2021 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nconst DEFAULT_POLLING_INTERVAL_MS = 1000;\n\ntype Options<T> = {\n  /**\n   * The callback used to load in new tasks. The number of items returned\n   * in the array must be at most `count` number of items, but may be lower.\n   *\n   * Any error thrown from this method fill be treated as an unhandled rejection.\n   */\n  loadTasks: (count: number) => Promise<Array<T>>;\n\n  /**\n   * The callback used to process a single item.\n   *\n   * Any error thrown from this method fill be treated as an unhandled rejection.\n   */\n  processTask: (item: T) => Promise<void>;\n\n  /**\n   * The target minimum number of items to process in parallel. Once the number\n   * of in-flight tasks reaches this count, more tasks will be loaded in.\n   */\n  lowWatermark: number;\n\n  /**\n   * The maximum number of items to process in parallel.\n   */\n  highWatermark: number;\n\n  /**\n   * The interval at which tasks are polled for in the background when\n   * there aren't enough tasks to load to satisfy the low watermark.\n   *\n   * @default 1000\n   */\n  pollingIntervalMs?: number;\n};\n\n/**\n * Creates a task processing pipeline which continuously loads in tasks to\n * keep the number of parallel in-flight tasks between a low and high watermark.\n *\n * @param options - The options for the pipeline.\n * @returns A stop function which when called halts all processing.\n */\nexport function startTaskPipeline<T>(options: Options<T>) {\n  const {\n    loadTasks,\n    processTask,\n    lowWatermark,\n    highWatermark,\n    pollingIntervalMs = DEFAULT_POLLING_INTERVAL_MS,\n  } = options;\n\n  if (lowWatermark >= highWatermark) {\n    throw new Error('lowWatermark must be lower than highWatermark');\n  }\n\n  let loading = false;\n  let stopped = false;\n  let inFlightCount = 0;\n\n  async function maybeLoadMore() {\n    if (stopped || loading || inFlightCount > lowWatermark) {\n      return;\n    }\n\n    // Once we hit the low watermark we load in enough items to reach the high watermark\n    loading = true;\n    const loadCount = highWatermark - inFlightCount;\n    const loadedItems = await loadTasks(loadCount);\n    loading = false;\n\n    // We might not reach the high watermark here, in case there weren't enough items to load\n    inFlightCount += loadedItems.length;\n    loadedItems.forEach(item => {\n      processTask(item).finally(() => {\n        if (stopped) {\n          return;\n        }\n\n        // For each item we complete we check if it's time to load more\n        inFlightCount -= 1;\n        maybeLoadMore();\n      });\n    });\n\n    // We might have processed some tasks while we where loading, so check if we can load more\n    if (loadedItems.length > 1) {\n      maybeLoadMore();\n    }\n  }\n\n  // This interval makes sure that we load in new items if the loop runs\n  // dry because of the lack of available tasks. As long as there are\n  // enough items to process this will be a noop.\n  const intervalId = setInterval(() => {\n    maybeLoadMore();\n  }, pollingIntervalMs);\n\n  return () => {\n    stopped = true;\n    clearInterval(intervalId);\n  };\n}\n","/*\n * Copyright 2021 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { stringifyEntityRef } from '@backstage/catalog-model';\nimport { assertError, serializeError } from '@backstage/errors';\nimport { Hash } from 'crypto';\nimport stableStringify from 'fast-json-stable-stringify';\nimport { Logger } from 'winston';\nimport { ProcessingDatabase, RefreshStateItem } from '../database/types';\nimport { createCounterMetric, createSummaryMetric } from '../util/metrics';\nimport {\n  CatalogProcessingEngine,\n  CatalogProcessingOrchestrator,\n  EntityProcessingResult,\n} from '../processing/types';\nimport { Stitcher } from '../stitching/Stitcher';\nimport { startTaskPipeline } from './TaskPipeline';\n\nconst CACHE_TTL = 5;\n\nexport class DefaultCatalogProcessingEngine implements CatalogProcessingEngine {\n  private readonly tracker = progressTracker();\n  private stopFunc?: () => void;\n\n  constructor(\n    private readonly logger: Logger,\n    private readonly processingDatabase: ProcessingDatabase,\n    private readonly orchestrator: CatalogProcessingOrchestrator,\n    private readonly stitcher: Stitcher,\n    private readonly createHash: () => Hash,\n    private readonly pollingIntervalMs: number = 1000,\n  ) {}\n\n  async start() {\n    if (this.stopFunc) {\n      throw new Error('Processing engine is already started');\n    }\n\n    this.stopFunc = startTaskPipeline<RefreshStateItem>({\n      lowWatermark: 5,\n      highWatermark: 10,\n      pollingIntervalMs: this.pollingIntervalMs,\n      loadTasks: async count => {\n        try {\n          const { items } = await this.processingDatabase.transaction(\n            async tx => {\n              return this.processingDatabase.getProcessableEntities(tx, {\n                processBatchSize: count,\n              });\n            },\n          );\n          return items;\n        } catch (error) {\n          this.logger.warn('Failed to load processing items', error);\n          return [];\n        }\n      },\n      processTask: async item => {\n        const track = this.tracker.processStart(item, this.logger);\n\n        try {\n          const {\n            id,\n            state,\n            unprocessedEntity,\n            entityRef,\n            locationKey,\n            resultHash: previousResultHash,\n          } = item;\n          const result = await this.orchestrator.process({\n            entity: unprocessedEntity,\n            state,\n          });\n\n          track.markProcessorsCompleted(result);\n\n          if (result.ok) {\n            if (stableStringify(state) !== stableStringify(result.state)) {\n              await this.processingDatabase.transaction(async tx => {\n                await this.processingDatabase.updateEntityCache(tx, {\n                  id,\n                  state: {\n                    ttl: CACHE_TTL,\n                    ...result.state,\n                  },\n                });\n              });\n            }\n          } else {\n            const maybeTtl = state?.ttl;\n            const ttl = Number.isInteger(maybeTtl) ? (maybeTtl as number) : 0;\n            await this.processingDatabase.transaction(async tx => {\n              await this.processingDatabase.updateEntityCache(tx, {\n                id,\n                state: ttl > 0 ? { ...state, ttl: ttl - 1 } : {},\n              });\n            });\n          }\n\n          for (const error of result.errors) {\n            // TODO(freben): Try to extract the location out of the unprocessed\n            // entity and add as meta to the log lines\n            this.logger.warn(error.message, {\n              entity: entityRef,\n            });\n          }\n          const errorsString = JSON.stringify(\n            result.errors.map(e => serializeError(e)),\n          );\n\n          let hashBuilder = this.createHash().update(errorsString);\n          if (result.ok) {\n            const { entityRefs: parents } =\n              await this.processingDatabase.transaction(tx =>\n                this.processingDatabase.listParents(tx, {\n                  entityRef,\n                }),\n              );\n\n            hashBuilder = hashBuilder\n              .update(stableStringify({ ...result.completedEntity }))\n              .update(stableStringify([...result.deferredEntities]))\n              .update(stableStringify([...result.relations]))\n              .update(stableStringify([...parents]));\n          }\n\n          const resultHash = hashBuilder.digest('hex');\n          if (resultHash === previousResultHash) {\n            // If nothing changed in our produced outputs, we cannot have any\n            // significant effect on our surroundings; therefore, we just abort\n            // without any updates / stitching.\n            track.markSuccessfulWithNoChanges();\n            return;\n          }\n\n          // If the result was marked as not OK, it signals that some part of the\n          // processing pipeline threw an exception. This can happen both as part of\n          // non-catastrophic things such as due to validation errors, as well as if\n          // something fatal happens inside the processing for other reasons. In any\n          // case, this means we can't trust that anything in the output is okay. So\n          // just store the errors and trigger a stich so that they become visible to\n          // the outside.\n          if (!result.ok) {\n            await this.processingDatabase.transaction(async tx => {\n              await this.processingDatabase.updateProcessedEntityErrors(tx, {\n                id,\n                errors: errorsString,\n                resultHash,\n              });\n            });\n            await this.stitcher.stitch(\n              new Set([stringifyEntityRef(unprocessedEntity)]),\n            );\n            track.markSuccessfulWithErrors();\n            return;\n          }\n\n          result.completedEntity.metadata.uid = id;\n          await this.processingDatabase.transaction(async tx => {\n            await this.processingDatabase.updateProcessedEntity(tx, {\n              id,\n              processedEntity: result.completedEntity,\n              resultHash,\n              errors: errorsString,\n              relations: result.relations,\n              deferredEntities: result.deferredEntities,\n              locationKey,\n            });\n          });\n\n          const setOfThingsToStitch = new Set<string>([\n            stringifyEntityRef(result.completedEntity),\n            ...result.relations.map(relation =>\n              stringifyEntityRef(relation.source),\n            ),\n          ]);\n          await this.stitcher.stitch(setOfThingsToStitch);\n\n          track.markSuccessfulWithChanges(setOfThingsToStitch.size);\n        } catch (error) {\n          assertError(error);\n          track.markFailed(error);\n        }\n      },\n    });\n  }\n\n  async stop() {\n    if (this.stopFunc) {\n      this.stopFunc();\n      this.stopFunc = undefined;\n    }\n  }\n}\n\n// Helps wrap the timing and logging behaviors\nfunction progressTracker() {\n  const stitchedEntities = createCounterMetric({\n    name: 'catalog_stitched_entities_count',\n    help: 'Amount of entities stitched',\n  });\n  const processedEntities = createCounterMetric({\n    name: 'catalog_processed_entities_count',\n    help: 'Amount of entities processed',\n    labelNames: ['result'],\n  });\n  const processingDuration = createSummaryMetric({\n    name: 'catalog_processing_duration_seconds',\n    help: 'Time spent executing the full processing flow',\n    labelNames: ['result'],\n  });\n  const processorsDuration = createSummaryMetric({\n    name: 'catalog_processors_duration_seconds',\n    help: 'Time spent executing catalog processors',\n    labelNames: ['result'],\n  });\n  const processingQueueDelay = createSummaryMetric({\n    name: 'catalog_processing_queue_delay_seconds',\n    help: 'The amount of delay between being scheduled for processing, and the start of actually being processed',\n  });\n\n  function processStart(item: RefreshStateItem, logger: Logger) {\n    logger.debug(`Processing ${item.entityRef}`);\n\n    if (item.nextUpdateAt) {\n      processingQueueDelay.observe(-item.nextUpdateAt.diffNow().as('seconds'));\n    }\n\n    const endOverallTimer = processingDuration.startTimer();\n    const endProcessorsTimer = processorsDuration.startTimer();\n\n    function markProcessorsCompleted(result: EntityProcessingResult) {\n      endProcessorsTimer({ result: result.ok ? 'ok' : 'failed' });\n    }\n\n    function markSuccessfulWithNoChanges() {\n      endOverallTimer({ result: 'unchanged' });\n      processedEntities.inc({ result: 'unchanged' }, 1);\n    }\n\n    function markSuccessfulWithErrors() {\n      endOverallTimer({ result: 'errors' });\n      processedEntities.inc({ result: 'errors' }, 1);\n    }\n\n    function markSuccessfulWithChanges(stitchedCount: number) {\n      endOverallTimer({ result: 'changed' });\n      stitchedEntities.inc(stitchedCount);\n      processedEntities.inc({ result: 'changed' }, 1);\n    }\n\n    function markFailed(error: Error) {\n      processedEntities.inc({ result: 'failed' }, 1);\n      logger.warn(`Processing of ${item.entityRef} failed`, error);\n    }\n\n    return {\n      markProcessorsCompleted,\n      markSuccessfulWithNoChanges,\n      markSuccessfulWithErrors,\n      markSuccessfulWithChanges,\n      markFailed,\n    };\n  }\n\n  return { processStart };\n}\n","/*\n * Copyright 2021 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  Entity,\n  ANNOTATION_LOCATION,\n  ANNOTATION_ORIGIN_LOCATION,\n  stringifyEntityRef,\n} from '@backstage/catalog-model';\nimport { Location } from '@backstage/catalog-client';\nimport {\n  CatalogProcessingOrchestrator,\n  DeferredEntity,\n} from '../processing/types';\nimport { LocationInput, LocationService, LocationStore } from './types';\nimport { locationSpecToMetadataName } from '../util/conversion';\n\nexport class DefaultLocationService implements LocationService {\n  constructor(\n    private readonly store: LocationStore,\n    private readonly orchestrator: CatalogProcessingOrchestrator,\n  ) {}\n\n  async createLocation(\n    input: LocationInput,\n    dryRun: boolean,\n  ): Promise<{ location: Location; entities: Entity[]; exists?: boolean }> {\n    if (dryRun) {\n      return this.dryRunCreateLocation(input);\n    }\n    const location = await this.store.createLocation(input);\n    return { location, entities: [] };\n  }\n\n  listLocations(): Promise<Location[]> {\n    return this.store.listLocations();\n  }\n  getLocation(id: string): Promise<Location> {\n    return this.store.getLocation(id);\n  }\n  deleteLocation(id: string): Promise<void> {\n    return this.store.deleteLocation(id);\n  }\n\n  private async processEntities(\n    unprocessedEntities: DeferredEntity[],\n  ): Promise<Entity[]> {\n    const entities: Entity[] = [];\n    while (unprocessedEntities.length) {\n      const currentEntity = unprocessedEntities.pop();\n      if (!currentEntity) {\n        continue;\n      }\n      const processed = await this.orchestrator.process({\n        entity: currentEntity.entity,\n        state: {}, // we process without the existing cache\n      });\n\n      if (processed.ok) {\n        if (\n          entities.some(\n            e =>\n              stringifyEntityRef(e) ===\n              stringifyEntityRef(processed.completedEntity),\n          )\n        ) {\n          throw new Error(\n            `Duplicate nested entity: ${stringifyEntityRef(\n              processed.completedEntity,\n            )}`,\n          );\n        }\n        unprocessedEntities.push(...processed.deferredEntities);\n        entities.push(processed.completedEntity);\n      } else {\n        throw Error(processed.errors.map(String).join(', '));\n      }\n    }\n    return entities;\n  }\n\n  private async dryRunCreateLocation(\n    spec: LocationInput,\n  ): Promise<{ location: Location; entities: Entity[]; exists?: boolean }> {\n    // Run the existence check in parallel with the processing\n    const existsPromise = this.store\n      .listLocations()\n      .then(locations =>\n        locations.some(l => l.type === spec.type && l.target === spec.target),\n      );\n\n    const entity = {\n      apiVersion: 'backstage.io/v1alpha1',\n      kind: 'Location',\n      metadata: {\n        name: locationSpecToMetadataName({\n          type: spec.type,\n          target: spec.target,\n        }),\n        namespace: 'default',\n        annotations: {\n          [ANNOTATION_LOCATION]: `${spec.type}:${spec.target}`,\n          [ANNOTATION_ORIGIN_LOCATION]: `${spec.type}:${spec.target}`,\n        },\n      },\n      spec: {\n        type: spec.type,\n        target: spec.target,\n      },\n    };\n    const unprocessedEntities: DeferredEntity[] = [\n      { entity, locationKey: `${spec.type}:${spec.target}` },\n    ];\n    const entities: Entity[] = await this.processEntities(unprocessedEntities);\n\n    return {\n      exists: await existsPromise,\n      location: { ...spec, id: `${spec.type}:${spec.target}` },\n      entities,\n    };\n  }\n}\n","/*\n * Copyright 2020 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  Entity,\n  parseEntityRef,\n  stringifyEntityRef,\n} from '@backstage/catalog-model';\nimport { InputError, NotFoundError } from '@backstage/errors';\nimport { Knex } from 'knex';\nimport lodash from 'lodash';\nimport {\n  EntitiesCatalog,\n  EntitiesRequest,\n  EntitiesResponse,\n  EntitiesSearchFilter,\n  EntityAncestryResponse,\n  EntityFacetsRequest,\n  EntityFacetsResponse,\n  EntityFilter,\n  EntityPagination,\n} from '../catalog/types';\nimport {\n  DbFinalEntitiesRow,\n  DbPageInfo,\n  DbRefreshStateReferencesRow,\n  DbRefreshStateRow,\n  DbSearchRow,\n} from '../database/tables';\n\nfunction parsePagination(input?: EntityPagination): {\n  limit?: number;\n  offset?: number;\n} {\n  if (!input) {\n    return {};\n  }\n\n  let { limit, offset } = input;\n\n  if (input.after !== undefined) {\n    let cursor;\n    try {\n      const json = Buffer.from(input.after, 'base64').toString('utf8');\n      cursor = JSON.parse(json);\n    } catch {\n      throw new InputError('Malformed after cursor, could not be parsed');\n    }\n    if (cursor.limit !== undefined) {\n      if (!Number.isInteger(cursor.limit)) {\n        throw new InputError('Malformed after cursor, limit was not an number');\n      }\n      limit = cursor.limit;\n    }\n    if (cursor.offset !== undefined) {\n      if (!Number.isInteger(cursor.offset)) {\n        throw new InputError('Malformed after cursor, offset was not a number');\n      }\n      offset = cursor.offset;\n    }\n  }\n\n  return { limit, offset };\n}\n\nfunction stringifyPagination(input: { limit: number; offset: number }) {\n  const json = JSON.stringify({ limit: input.limit, offset: input.offset });\n  const base64 = Buffer.from(json, 'utf8').toString('base64');\n  return base64;\n}\n\nfunction addCondition(\n  queryBuilder: Knex.QueryBuilder,\n  db: Knex,\n  filter: EntitiesSearchFilter,\n  negate: boolean = false,\n) {\n  // NOTE(freben): This used to be a set of OUTER JOIN, which may seem to\n  // make a lot of sense. However, it had abysmal performance on sqlite\n  // when datasets grew large, so we're using IN instead.\n  const matchQuery = db<DbSearchRow>('search')\n    .select('entity_id')\n    .where({ key: filter.key.toLowerCase() })\n    .andWhere(function keyFilter() {\n      if (filter.values) {\n        if (filter.values.length === 1) {\n          this.where({ value: filter.values[0].toLowerCase() });\n        } else {\n          this.andWhere(\n            'value',\n            'in',\n            filter.values.map(v => v.toLowerCase()),\n          );\n        }\n      }\n    });\n  queryBuilder.andWhere('entity_id', negate ? 'not in' : 'in', matchQuery);\n}\n\nfunction isEntitiesSearchFilter(\n  filter: EntitiesSearchFilter | EntityFilter,\n): filter is EntitiesSearchFilter {\n  return filter.hasOwnProperty('key');\n}\n\nfunction isOrEntityFilter(\n  filter: { anyOf: EntityFilter[] } | EntityFilter,\n): filter is { anyOf: EntityFilter[] } {\n  return filter.hasOwnProperty('anyOf');\n}\n\nfunction isNegationEntityFilter(\n  filter: { not: EntityFilter } | EntityFilter,\n): filter is { not: EntityFilter } {\n  return filter.hasOwnProperty('not');\n}\n\nfunction parseFilter(\n  filter: EntityFilter,\n  query: Knex.QueryBuilder,\n  db: Knex,\n  negate: boolean = false,\n): Knex.QueryBuilder {\n  if (isEntitiesSearchFilter(filter)) {\n    return query.andWhere(function filterFunction() {\n      addCondition(this, db, filter, negate);\n    });\n  }\n\n  if (isNegationEntityFilter(filter)) {\n    return parseFilter(filter.not, query, db, !negate);\n  }\n\n  return query[negate ? 'andWhereNot' : 'andWhere'](function filterFunction() {\n    if (isOrEntityFilter(filter)) {\n      for (const subFilter of filter.anyOf ?? []) {\n        this.orWhere(subQuery => parseFilter(subFilter, subQuery, db));\n      }\n    } else {\n      for (const subFilter of filter.allOf ?? []) {\n        this.andWhere(subQuery => parseFilter(subFilter, subQuery, db));\n      }\n    }\n  });\n}\n\nexport class DefaultEntitiesCatalog implements EntitiesCatalog {\n  constructor(private readonly database: Knex) {}\n\n  async entities(request?: EntitiesRequest): Promise<EntitiesResponse> {\n    const db = this.database;\n\n    let entitiesQuery = db<DbFinalEntitiesRow>('final_entities');\n    if (request?.filter) {\n      entitiesQuery = parseFilter(request.filter, entitiesQuery, db);\n    }\n\n    // TODO: move final_entities to use entity_ref\n    entitiesQuery = entitiesQuery\n      .select('final_entities.*')\n      .whereNotNull('final_entities.final_entity')\n      .orderBy('entity_id', 'asc');\n\n    const { limit, offset } = parsePagination(request?.pagination);\n    if (limit !== undefined) {\n      entitiesQuery = entitiesQuery.limit(limit + 1);\n    }\n    if (offset !== undefined) {\n      entitiesQuery = entitiesQuery.offset(offset);\n    }\n\n    let rows = await entitiesQuery;\n\n    let pageInfo: DbPageInfo;\n    if (limit === undefined || rows.length <= limit) {\n      pageInfo = { hasNextPage: false };\n    } else {\n      rows = rows.slice(0, -1);\n      pageInfo = {\n        hasNextPage: true,\n        endCursor: stringifyPagination({\n          limit,\n          offset: (offset ?? 0) + limit,\n        }),\n      };\n    }\n\n    let entities: Entity[] = rows.map(e => JSON.parse(e.final_entity!));\n\n    if (request?.fields) {\n      entities = entities.map(e => request.fields!(e));\n    }\n\n    // TODO(freben): This is added as a compatibility guarantee, until we can be\n    // sure that all adopters have re-stitched their entities so that the new\n    // targetRef field is present on them, and that they have stopped consuming\n    // the now-removed old field\n    for (const entity of entities) {\n      if (entity.relations) {\n        for (const relation of entity.relations) {\n          if (!relation.targetRef && relation.target) {\n            // This is the case where an old-form entity, not yet stitched with\n            // the updated code, was in the database\n            relation.targetRef = stringifyEntityRef(relation.target);\n          } else if (!relation.target && relation.targetRef) {\n            // This is the case where a new-form entity, stitched with the\n            // updated code, was in the database but we still want to produce\n            // the old data shape as well for compatibility reasons\n            relation.target = parseEntityRef(relation.targetRef);\n          }\n        }\n      }\n    }\n\n    return {\n      entities,\n      pageInfo,\n    };\n  }\n\n  async removeEntityByUid(uid: string): Promise<void> {\n    // Clear the hashed state of the immediate parents of the deleted entity.\n    // This makes sure that when they get reprocessed, their output is written\n    // down again. The reason for wanting to do this, is that if the user\n    // deletes entities that ARE still emitted by the parent, the parent\n    // processing will still generate the same output hash as always, which\n    // means it'll never try to write down the children again (it assumes that\n    // they already exist). This means that without the code below, the database\n    // never \"heals\" from accidental deletes.\n    await this.database<DbRefreshStateRow>('refresh_state')\n      .update({\n        result_hash: 'child-was-deleted',\n      })\n      .whereIn('entity_ref', function parents(builder) {\n        return builder\n          .from<DbRefreshStateRow>('refresh_state')\n          .innerJoin<DbRefreshStateReferencesRow>('refresh_state_references', {\n            'refresh_state_references.target_entity_ref':\n              'refresh_state.entity_ref',\n          })\n          .where('refresh_state.entity_id', '=', uid)\n          .select('refresh_state_references.source_entity_ref');\n      });\n\n    await this.database<DbRefreshStateRow>('refresh_state')\n      .where('entity_id', uid)\n      .delete();\n  }\n\n  async entityAncestry(rootRef: string): Promise<EntityAncestryResponse> {\n    const [rootRow] = await this.database<DbRefreshStateRow>('refresh_state')\n      .leftJoin<DbFinalEntitiesRow>('final_entities', {\n        'refresh_state.entity_id': 'final_entities.entity_id',\n      })\n      .where('refresh_state.entity_ref', '=', rootRef)\n      .select({\n        entityJson: 'final_entities.final_entity',\n      });\n\n    if (!rootRow) {\n      throw new NotFoundError(`No such entity ${rootRef}`);\n    }\n\n    const rootEntity = JSON.parse(rootRow.entityJson) as Entity;\n    const seenEntityRefs = new Set<string>();\n    const todo = new Array<Entity>();\n    const items = new Array<{ entity: Entity; parentEntityRefs: string[] }>();\n\n    for (\n      let current: Entity | undefined = rootEntity;\n      current;\n      current = todo.pop()\n    ) {\n      const currentRef = stringifyEntityRef(current);\n      seenEntityRefs.add(currentRef);\n\n      const parentRows = await this.database<DbRefreshStateReferencesRow>(\n        'refresh_state_references',\n      )\n        .innerJoin<DbRefreshStateRow>('refresh_state', {\n          'refresh_state_references.source_entity_ref':\n            'refresh_state.entity_ref',\n        })\n        .innerJoin<DbFinalEntitiesRow>('final_entities', {\n          'refresh_state.entity_id': 'final_entities.entity_id',\n        })\n        .where('refresh_state_references.target_entity_ref', '=', currentRef)\n        .select({\n          parentEntityRef: 'refresh_state.entity_ref',\n          parentEntityJson: 'final_entities.final_entity',\n        });\n\n      const parentRefs: string[] = [];\n      for (const { parentEntityRef, parentEntityJson } of parentRows) {\n        parentRefs.push(parentEntityRef);\n        if (!seenEntityRefs.has(parentEntityRef)) {\n          seenEntityRefs.add(parentEntityRef);\n          todo.push(JSON.parse(parentEntityJson));\n        }\n      }\n\n      items.push({\n        entity: current,\n        parentEntityRefs: parentRefs,\n      });\n    }\n\n    return {\n      rootEntityRef: stringifyEntityRef(rootEntity),\n      items,\n    };\n  }\n\n  async facets(request: EntityFacetsRequest): Promise<EntityFacetsResponse> {\n    const { entities } = await this.entities({\n      filter: request.filter,\n      authorizationToken: request.authorizationToken,\n    });\n\n    const facets: EntityFacetsResponse['facets'] = {};\n\n    for (const facet of request.facets) {\n      const values = entities\n        .map(entity => {\n          // TODO(freben): Generalize this code to handle any field that may\n          // have dots in its key?\n          if (facet.startsWith('metadata.annotations.')) {\n            return entity.metadata.annotations?.[\n              facet.substring('metadata.annotations.'.length)\n            ];\n          } else if (facet.startsWith('metadata.labels.')) {\n            return entity.metadata.labels?.[\n              facet.substring('metadata.labels.'.length)\n            ];\n          }\n          return lodash.get(entity, facet);\n        })\n        .flatMap(field => {\n          if (typeof field === 'string') {\n            return [field];\n          } else if (Array.isArray(field)) {\n            return field.filter(i => typeof i === 'string');\n          }\n          return [];\n        })\n        .sort();\n\n      const counts = lodash.countBy(values, lodash.identity);\n\n      facets[facet] = Object.entries(counts).map(([value, count]) => ({\n        value,\n        count,\n      }));\n    }\n\n    return { facets };\n  }\n}\n","/*\n * Copyright 2020 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Entity, DEFAULT_NAMESPACE } from '@backstage/catalog-model';\nimport { InputError } from '@backstage/errors';\nimport { DbSearchRow } from '../database/tables';\n\n// These are excluded in the generic loop, either because they do not make sense\n// to index, or because they are special-case always inserted whether they are\n// null or not\nconst SPECIAL_KEYS = [\n  'attachments',\n  'relations',\n  'status',\n  'metadata.name',\n  'metadata.namespace',\n  'metadata.uid',\n  'metadata.etag',\n  'metadata.generation',\n];\n\n// The maximum length allowed for search values. These columns are indexed, and\n// database engines do not like to index on massive values. For example,\n// postgres will balk after 8191 byte line sizes.\nconst MAX_KEY_LENGTH = 200;\nconst MAX_VALUE_LENGTH = 200;\n\ntype Kv = {\n  key: string;\n  value: unknown;\n};\n\n// Helper for traversing through a nested structure and outputting a list of\n// path->value entries of the leaves.\n//\n// For example, this yaml structure\n//\n// a: 1\n// b:\n//   c: null\n//   e: [f, g]\n// h:\n//  - i: 1\n//    j: k\n//  - i: 2\n//    j: l\n//\n// will result in\n//\n// \"a\", 1\n// \"b.c\", null\n// \"b.e\": \"f\"\n// \"b.e.f\": true\n// \"b.e\": \"g\"\n// \"b.e.g\": true\n// \"h.i\": 1\n// \"h.j\": \"k\"\n// \"h.i\": 2\n// \"h.j\": \"l\"\nexport function traverse(root: unknown): Kv[] {\n  const output: Kv[] = [];\n\n  function visit(path: string, current: unknown) {\n    if (SPECIAL_KEYS.includes(path)) {\n      return;\n    }\n\n    // empty or scalar\n    if (\n      current === undefined ||\n      current === null ||\n      ['string', 'number', 'boolean'].includes(typeof current)\n    ) {\n      output.push({ key: path, value: current });\n      return;\n    }\n\n    // unknown\n    if (typeof current !== 'object') {\n      return;\n    }\n\n    // array\n    if (Array.isArray(current)) {\n      for (const item of current) {\n        // NOTE(freben): The reason that these are output in two different ways,\n        // is to support use cases where you want to express that MORE than one\n        // tag is present in a list. Since the EntityFilters structure is a\n        // record, you can't have several entries of the same key. Therefore\n        // you will have to match on\n        //\n        // { \"a.b\": [\"true\"], \"a.c\": [\"true\"] }\n        //\n        // rather than\n        //\n        // { \"a\": [\"b\", \"c\"] }\n        //\n        // because the latter means EITHER b or c has to be present.\n        visit(path, item);\n        if (typeof item === 'string') {\n          output.push({ key: `${path}.${item}`, value: true });\n        }\n      }\n      return;\n    }\n\n    // object\n    for (const [key, value] of Object.entries(current!)) {\n      visit(path ? `${path}.${key}` : key, value);\n    }\n  }\n\n  visit('', root);\n\n  return output;\n}\n\n// Translates a number of raw data rows to search table rows\nexport function mapToRows(input: Kv[], entityId: string): DbSearchRow[] {\n  const result: DbSearchRow[] = [];\n\n  for (const { key: rawKey, value: rawValue } of input) {\n    const key = rawKey.toLocaleLowerCase('en-US');\n    if (rawValue === undefined || rawValue === null) {\n      result.push({ entity_id: entityId, key, value: null });\n    } else {\n      const value = String(rawValue).toLocaleLowerCase('en-US');\n      if (key.length <= MAX_KEY_LENGTH && value.length <= MAX_VALUE_LENGTH) {\n        result.push({ entity_id: entityId, key, value });\n      }\n    }\n  }\n\n  return result;\n}\n\n/**\n * Generates all of the search rows that are relevant for this entity.\n *\n * @param entityId - The uid of the entity\n * @param entity - The entity\n * @returns A list of entity search rows\n */\nexport function buildEntitySearch(\n  entityId: string,\n  entity: Entity,\n): DbSearchRow[] {\n  // Visit the base structure recursively\n  const raw = traverse(entity);\n\n  // Start with some special keys that are always present because you want to\n  // be able to easily search for null specifically\n  raw.push({ key: 'metadata.name', value: entity.metadata.name });\n  raw.push({ key: 'metadata.namespace', value: entity.metadata.namespace });\n  raw.push({ key: 'metadata.uid', value: entity.metadata.uid });\n\n  // Namespace not specified has the default value \"default\", so we want to\n  // match on that as well\n  if (!entity.metadata.namespace) {\n    raw.push({ key: 'metadata.namespace', value: DEFAULT_NAMESPACE });\n  }\n\n  // Visit relations\n  for (const relation of entity.relations ?? []) {\n    raw.push({\n      key: `relations.${relation.type}`,\n      value: relation.targetRef,\n    });\n  }\n\n  // This validates that there are no keys that vary only in casing, such\n  // as `spec.foo` and `spec.Foo`.\n  const keys = new Set(raw.map(r => r.key));\n  const lowerKeys = new Set(raw.map(r => r.key.toLocaleLowerCase('en-US')));\n  if (keys.size !== lowerKeys.size) {\n    const difference = [];\n    for (const key of keys) {\n      const lower = key.toLocaleLowerCase('en-US');\n      if (!lowerKeys.delete(lower)) {\n        difference.push(lower);\n      }\n    }\n    const badKeys = `'${difference.join(\"', '\")}'`;\n    throw new InputError(\n      `Entity has duplicate keys that vary only in casing, ${badKeys}`,\n    );\n  }\n\n  return mapToRows(raw, entityId);\n}\n","/*\n * Copyright 2021 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Entity } from '@backstage/catalog-model';\nimport { createHash } from 'crypto';\nimport stableStringify from 'fast-json-stable-stringify';\n\n// The number of items that are sent per batch to the database layer, when\n// doing .batchInsert calls to knex. This needs to be low enough to not cause\n// errors in the underlying engine due to exceeding query limits, but large\n// enough to get the speed benefits.\nexport const BATCH_SIZE = 50;\n\nexport function generateStableHash(entity: Entity) {\n  return createHash('sha1')\n    .update(stableStringify({ ...entity }))\n    .digest('hex');\n}\n","/*\n * Copyright 2021 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { ENTITY_STATUS_CATALOG_PROCESSING_TYPE } from '@backstage/catalog-client';\nimport {\n  AlphaEntity,\n  parseEntityRef,\n  EntityRelation,\n  EntityStatusItem,\n} from '@backstage/catalog-model';\nimport { SerializedError, stringifyError } from '@backstage/errors';\nimport { Knex } from 'knex';\nimport { uniqBy } from 'lodash';\nimport { v4 as uuid } from 'uuid';\nimport { Logger } from 'winston';\nimport {\n  DbFinalEntitiesRow,\n  DbRefreshStateRow,\n  DbSearchRow,\n} from '../database/tables';\nimport { buildEntitySearch } from './buildEntitySearch';\nimport { BATCH_SIZE, generateStableHash } from './util';\n\n/**\n * Performs the act of stitching - to take all of the various outputs from the\n * ingestion process, and stitching them together into the final entity JSON\n * shape.\n */\nexport class Stitcher {\n  constructor(\n    private readonly database: Knex,\n    private readonly logger: Logger,\n  ) {}\n\n  async stitch(entityRefs: Set<string>) {\n    for (const entityRef of entityRefs) {\n      try {\n        await this.stitchOne(entityRef);\n      } catch (error) {\n        this.logger.error(\n          `Failed to stitch ${entityRef}, ${stringifyError(error)}`,\n        );\n      }\n    }\n  }\n\n  private async stitchOne(entityRef: string): Promise<void> {\n    const entityResult = await this.database<DbRefreshStateRow>('refresh_state')\n      .where({ entity_ref: entityRef })\n      .limit(1)\n      .select('entity_id');\n    if (!entityResult.length) {\n      // Entity does no exist in refresh state table, no stitching required.\n      return;\n    }\n\n    // Insert stitching ticket that will be compared before inserting the final entity.\n    const ticket = uuid();\n    await this.database<DbFinalEntitiesRow>('final_entities')\n      .insert({\n        entity_id: entityResult[0].entity_id,\n        hash: '',\n        stitch_ticket: ticket,\n      })\n      .onConflict('entity_id')\n      .merge(['stitch_ticket']);\n\n    // Selecting from refresh_state and final_entities should yield exactly\n    // one row (except in abnormal cases where the stitch was invoked for\n    // something that didn't exist at all, in which case it's zero rows).\n    // The join with the temporary incoming_references still gives one row.\n    // The only result set \"expanding\" join is the one with relations, so\n    // the output should be at least one row (if zero or one relations were\n    // found), or at most the same number of rows as relations.\n    const result: Array<{\n      entityId: string;\n      processedEntity?: string;\n      errors: string;\n      incomingReferenceCount: string | number;\n      previousHash?: string;\n      relationType?: string;\n      relationTarget?: string;\n    }> = await this.database\n      .with('incoming_references', function incomingReferences(builder) {\n        return builder\n          .from('refresh_state_references')\n          .where({ target_entity_ref: entityRef })\n          .count({ count: '*' });\n      })\n      .select({\n        entityId: 'refresh_state.entity_id',\n        processedEntity: 'refresh_state.processed_entity',\n        errors: 'refresh_state.errors',\n        incomingReferenceCount: 'incoming_references.count',\n        previousHash: 'final_entities.hash',\n        relationType: 'relations.type',\n        relationTarget: 'relations.target_entity_ref',\n      })\n      .from('refresh_state')\n      .where({ 'refresh_state.entity_ref': entityRef })\n      .crossJoin(this.database.raw('incoming_references'))\n      .leftOuterJoin('final_entities', {\n        'final_entities.entity_id': 'refresh_state.entity_id',\n      })\n      .leftOuterJoin('relations', {\n        'relations.source_entity_ref': 'refresh_state.entity_ref',\n      })\n      .orderBy('relationType', 'asc')\n      .orderBy('relationTarget', 'asc');\n\n    // If there were no rows returned, it would mean that there was no\n    // matching row even in the refresh_state. This can happen for example\n    // if we emit a relation to something that hasn't been ingested yet.\n    // It's safe to ignore this stitch attempt in that case.\n    if (!result.length) {\n      this.logger.error(\n        `Unable to stitch ${entityRef}, item does not exist in refresh state table`,\n      );\n      return;\n    }\n\n    const {\n      entityId,\n      processedEntity,\n      errors,\n      incomingReferenceCount,\n      previousHash,\n    } = result[0];\n\n    // If there was no processed entity in place, the target hasn't been\n    // through the processing steps yet. It's safe to ignore this stitch\n    // attempt in that case, since another stitch will be triggered when\n    // that processing has finished.\n    if (!processedEntity) {\n      this.logger.debug(\n        `Unable to stitch ${entityRef}, the entity has not yet been processed`,\n      );\n      return;\n    }\n\n    // Grab the processed entity and stitch all of the relevant data into\n    // it\n    const entity = JSON.parse(processedEntity) as AlphaEntity;\n    const isOrphan = Number(incomingReferenceCount) === 0;\n    let statusItems: EntityStatusItem[] = [];\n\n    if (isOrphan) {\n      this.logger.debug(`${entityRef} is an orphan`);\n      entity.metadata.annotations = {\n        ...entity.metadata.annotations,\n        ['backstage.io/orphan']: 'true',\n      };\n    }\n    if (errors) {\n      const parsedErrors = JSON.parse(errors) as SerializedError[];\n      if (Array.isArray(parsedErrors) && parsedErrors.length) {\n        statusItems = parsedErrors.map(e => ({\n          type: ENTITY_STATUS_CATALOG_PROCESSING_TYPE,\n          level: 'error',\n          message: `${e.name}: ${e.message}`,\n          error: e,\n        }));\n      }\n    }\n\n    // TODO: entityRef is lower case and should be uppercase in the final\n    // result\n    const uniqueRelationRows = uniqBy(\n      result,\n      r => `${r.relationType}:${r.relationTarget}`,\n    );\n    entity.relations = uniqueRelationRows\n      .filter(row => row.relationType /* exclude null row, if relevant */)\n      .map<EntityRelation>(row => ({\n        type: row.relationType!,\n        // TODO(freben): This field is deprecated and should be removed in a future release\n        target: parseEntityRef(row.relationTarget!),\n        targetRef: row.relationTarget!,\n      }));\n    if (statusItems.length) {\n      entity.status = {\n        ...entity.status,\n        items: [...(entity.status?.items ?? []), ...statusItems],\n      };\n    }\n\n    // If the output entity was actually not changed, just abort\n    const hash = generateStableHash(entity);\n    if (hash === previousHash) {\n      this.logger.debug(`Skipped stitching of ${entityRef}, no changes`);\n      return;\n    }\n\n    entity.metadata.uid = entityId;\n    entity.metadata.generation = 1;\n    if (!entity.metadata.etag) {\n      // If the original data source did not have its own etag handling,\n      // use the hash as a good-quality etag\n      entity.metadata.etag = hash;\n    }\n\n    // This may throw if the entity is invalid, so we call it before\n    // the final_entities write, even though we may end up not needing\n    // to write the search index.\n    const searchEntries = buildEntitySearch(entityId, entity);\n\n    const rowsChanged = await this.database<DbFinalEntitiesRow>(\n      'final_entities',\n    )\n      .update({\n        final_entity: JSON.stringify(entity),\n        hash,\n      })\n      .where('entity_id', entityId)\n      .where('stitch_ticket', ticket)\n      .onConflict('entity_id')\n      .merge(['final_entity', 'hash']);\n\n    if (rowsChanged.length === 0) {\n      this.logger.debug(\n        `Entity ${entityRef} is already processed, skipping write.`,\n      );\n      return;\n    }\n\n    // TODO(freben): Search will probably need a similar safeguard against\n    // race conditions like the final_entities ticket handling above.\n    // Otherwise, it can be the case that:\n    // A writes the entity ->\n    // B writes the entity ->\n    // B writes search ->\n    // A writes search\n    await this.database<DbSearchRow>('search')\n      .where({ entity_id: entityId })\n      .delete();\n    await this.database.batchInsert('search', searchEntries, BATCH_SIZE);\n  }\n}\n","/*\n * Copyright 2021 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { DefaultProcessingDatabase } from '../database/DefaultProcessingDatabase';\nimport { RefreshOptions, RefreshService } from './types';\n\nexport class DefaultRefreshService implements RefreshService {\n  private database: DefaultProcessingDatabase;\n\n  constructor(options: { database: DefaultProcessingDatabase }) {\n    this.database = options.database;\n  }\n\n  async refresh(options: RefreshOptions) {\n    await this.database.transaction(async tx => {\n      const { entityRefs } = await this.database.listAncestors(tx, {\n        entityRef: options.entityRef,\n      });\n      const locationAncestor = entityRefs.find(ref =>\n        ref.startsWith('location:'),\n      );\n\n      // TODO: Refreshes are currently scheduled(as soon as possible) for execution and will therefore happen in the future.\n      // There's room for improvements here where the refresh could potentially hang or return an ID so that the user can check progress.\n      if (locationAncestor) {\n        await this.database.refresh(tx, {\n          entityRef: locationAncestor,\n        });\n      }\n      await this.database.refresh(tx, {\n        entityRef: options.entityRef,\n      });\n    });\n  }\n}\n","/*\n * Copyright 2021 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { NotAllowedError } from '@backstage/errors';\nimport { catalogEntityRefreshPermission } from '@backstage/plugin-catalog-common';\nimport {\n  AuthorizeResult,\n  PermissionAuthorizer,\n} from '@backstage/plugin-permission-common';\nimport { RefreshOptions, RefreshService } from './types';\n\nexport class AuthorizedRefreshService implements RefreshService {\n  constructor(\n    private readonly service: RefreshService,\n    private readonly permissionApi: PermissionAuthorizer,\n  ) {}\n\n  async refresh(options: RefreshOptions) {\n    const authorizeDecision = (\n      await this.permissionApi.authorize(\n        [\n          {\n            permission: catalogEntityRefreshPermission,\n            resourceRef: options.entityRef,\n          },\n        ],\n        { token: options.authorizationToken },\n      )\n    )[0];\n    if (authorizeDecision.result !== AuthorizeResult.ALLOW) {\n      throw new NotAllowedError();\n    }\n    await this.service.refresh(options);\n  }\n}\n","/*\n * Copyright 2021 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  Entity,\n  entityEnvelopeSchemaValidator,\n} from '@backstage/catalog-model';\nimport { ProcessingDatabase } from '../database/types';\nimport {\n  EntityProvider,\n  EntityProviderConnection,\n  EntityProviderMutation,\n} from '../api';\n\nclass Connection implements EntityProviderConnection {\n  readonly validateEntityEnvelope = entityEnvelopeSchemaValidator();\n\n  constructor(\n    private readonly config: {\n      id: string;\n      processingDatabase: ProcessingDatabase;\n    },\n  ) {}\n\n  async applyMutation(mutation: EntityProviderMutation): Promise<void> {\n    const db = this.config.processingDatabase;\n\n    if (mutation.type === 'full') {\n      this.check(mutation.entities.map(e => e.entity));\n      await db.transaction(async tx => {\n        await db.replaceUnprocessedEntities(tx, {\n          sourceKey: this.config.id,\n          type: 'full',\n          items: mutation.entities,\n        });\n      });\n    } else if (mutation.type === 'delta') {\n      this.check(mutation.added.map(e => e.entity));\n      this.check(mutation.removed.map(e => e.entity));\n      await db.transaction(async tx => {\n        await db.replaceUnprocessedEntities(tx, {\n          sourceKey: this.config.id,\n          type: 'delta',\n          added: mutation.added,\n          removed: mutation.removed,\n        });\n      });\n    }\n  }\n\n  private check(entities: Entity[]) {\n    for (const entity of entities) {\n      try {\n        this.validateEntityEnvelope(entity);\n      } catch (e) {\n        throw new TypeError(`Malformed entity envelope, ${e}`);\n      }\n    }\n  }\n}\n\nexport async function connectEntityProviders(\n  db: ProcessingDatabase,\n  providers: EntityProvider[],\n) {\n  await Promise.all(\n    providers.map(async provider => {\n      const connection = new Connection({\n        id: provider.getProviderName(),\n        processingDatabase: db,\n      });\n      return provider.connect(connection);\n    }),\n  );\n}\n","/*\n * Copyright 2022 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Entity } from '@backstage/catalog-model';\nimport { makeCreatePermissionRule } from '@backstage/plugin-permission-node';\nimport { EntitiesSearchFilter } from '../../catalog/types';\n\n/**\n * Helper function for creating correctly-typed\n * {@link @backstage/plugin-permission-node#PermissionRule}s for the\n * catalog-backend.\n *\n * @alpha\n */\nexport const createCatalogPermissionRule = makeCreatePermissionRule<\n  Entity,\n  EntitiesSearchFilter\n>();\n","/*\n * Copyright 2021 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Entity } from '@backstage/catalog-model';\nimport { createCatalogPermissionRule } from './util';\n\n/**\n * A catalog {@link @backstage/plugin-permission-node#PermissionRule} which\n * filters for the presence of an annotation on a given entity.\n *\n * @alpha\n */\nexport const hasAnnotation = createCatalogPermissionRule({\n  name: 'HAS_ANNOTATION',\n  description:\n    'Allow entities which are annotated with the specified annotation',\n  apply: (resource: Entity, annotation: string) =>\n    !!resource.metadata.annotations?.hasOwnProperty(annotation),\n  toQuery: (annotation: string) => ({\n    key: `metadata.annotations.${annotation}`,\n  }),\n});\n","/*\n * Copyright 2021 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nimport { Entity } from '@backstage/catalog-model';\nimport { EntitiesSearchFilter } from '../../catalog/types';\nimport { createCatalogPermissionRule } from './util';\n\n/**\n * A catalog {@link @backstage/plugin-permission-node#PermissionRule} which\n * filters for entities with a specified kind.\n * @alpha\n */\nexport const isEntityKind = createCatalogPermissionRule({\n  name: 'IS_ENTITY_KIND',\n  description: 'Allow entities with the specified kind',\n  apply(resource: Entity, kinds: string[]) {\n    const resourceKind = resource.kind.toLocaleLowerCase('en-US');\n    return kinds.some(kind => kind.toLocaleLowerCase('en-US') === resourceKind);\n  },\n  toQuery(kinds: string[]): EntitiesSearchFilter {\n    return {\n      key: 'kind',\n      values: kinds.map(kind => kind.toLocaleLowerCase('en-US')),\n    };\n  },\n});\n","/*\n * Copyright 2021 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Entity, RELATION_OWNED_BY } from '@backstage/catalog-model';\nimport { createCatalogPermissionRule } from './util';\n\n/**\n * A catalog {@link @backstage/plugin-permission-node#PermissionRule} which\n * filters for entities with a specified owner.\n *\n * @alpha\n */\nexport const isEntityOwner = createCatalogPermissionRule({\n  name: 'IS_ENTITY_OWNER',\n  description: 'Allow entities owned by the current user',\n  apply: (resource: Entity, claims: string[]) => {\n    if (!resource.relations) {\n      return false;\n    }\n\n    return resource.relations\n      .filter(relation => relation.type === RELATION_OWNED_BY)\n      .some(relation => claims.includes(relation.targetRef));\n  },\n  toQuery: (claims: string[]) => ({\n    key: 'relations.ownedBy',\n    values: claims,\n  }),\n});\n","/*\n * Copyright 2022 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Entity } from '@backstage/catalog-model';\nimport { createCatalogPermissionRule } from './util';\n\n/**\n * A catalog {@link @backstage/plugin-permission-node#PermissionRule} which\n * filters for entities with a specified label in its metadata.\n * @alpha\n */\nexport const hasLabel = createCatalogPermissionRule({\n  name: 'HAS_LABEL',\n  description: 'Allow entities which have the specified label metadata.',\n  apply: (resource: Entity, label: string) =>\n    !!resource.metadata.labels?.hasOwnProperty(label),\n  toQuery: (label: string) => ({\n    key: `metadata.labels.${label}`,\n  }),\n});\n","/*\n * Copyright 2022 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { get } from 'lodash';\nimport { Entity } from '@backstage/catalog-model';\nimport { createCatalogPermissionRule } from './util';\n\nexport const createPropertyRule = (propertyType: 'metadata' | 'spec') =>\n  createCatalogPermissionRule({\n    name: `HAS_${propertyType.toUpperCase()}`,\n    description: `Allow entities which have the specified ${propertyType} subfield.`,\n    apply: (resource: Entity, key: string, value?: string) => {\n      const foundValue = get(resource[propertyType], key);\n      if (value !== undefined) {\n        return value === foundValue;\n      }\n      return !!foundValue;\n    },\n    toQuery: (key: string, value?: string) => ({\n      key: `${propertyType}.${key}`,\n      ...(value !== undefined && { values: [value] }),\n    }),\n  });\n","/*\n * Copyright 2022 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { createPropertyRule } from './createPropertyRule';\n\n/**\n * A catalog {@link @backstage/plugin-permission-node#PermissionRule} which\n * filters for entities with the specified metadata subfield. Also matches on\n * values if value is provided.\n *\n * The key argument to the `apply` and `toQuery` methods can be nested, such as\n * 'field.nestedfield'.\n * @alpha\n */\nexport const hasMetadata = createPropertyRule('metadata');\n","/*\n * Copyright 2022 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { createPropertyRule } from './createPropertyRule';\n\n/**\n * A catalog {@link @backstage/plugin-permission-node#PermissionRule} which\n * filters for entities with the specified spec subfield. Also matches on values\n * if value is provided.\n *\n * The key argument to the `apply` and `toQuery` methods can be nested, such as\n * 'field.nestedfield'.\n * @alpha\n */\nexport const hasSpec = createPropertyRule('spec');\n","/*\n * Copyright 2021 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { hasAnnotation } from './hasAnnotation';\nimport { isEntityKind } from './isEntityKind';\nimport { isEntityOwner } from './isEntityOwner';\nimport { hasLabel } from './hasLabel';\nimport { hasMetadata } from './hasMetadata';\nimport { hasSpec } from './hasSpec';\n\n/**\n * These permission rules can be used to conditionally filter catalog entities\n * or describe a user's access to the entities.\n *\n * @alpha\n */\nexport const permissionRules = {\n  hasAnnotation,\n  hasLabel,\n  hasMetadata,\n  hasSpec,\n  isEntityKind,\n  isEntityOwner,\n};\n\nexport { createCatalogPermissionRule } from './util';\n","/*\n * Copyright 2022 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { NotAllowedError } from '@backstage/errors';\nimport {\n  catalogEntityDeletePermission,\n  catalogEntityReadPermission,\n} from '@backstage/plugin-catalog-common';\nimport { Entity, stringifyEntityRef } from '@backstage/catalog-model';\nimport {\n  AuthorizeResult,\n  PermissionAuthorizer,\n} from '@backstage/plugin-permission-common';\nimport { ConditionTransformer } from '@backstage/plugin-permission-node';\nimport {\n  EntitiesCatalog,\n  EntitiesRequest,\n  EntitiesResponse,\n  EntityAncestryResponse,\n  EntityFacetsRequest,\n  EntityFacetsResponse,\n  EntityFilter,\n} from '../catalog/types';\nimport { basicEntityFilter } from './request/basicEntityFilter';\n\nexport class AuthorizedEntitiesCatalog implements EntitiesCatalog {\n  constructor(\n    private readonly entitiesCatalog: EntitiesCatalog,\n    private readonly permissionApi: PermissionAuthorizer,\n    private readonly transformConditions: ConditionTransformer<EntityFilter>,\n  ) {}\n\n  async entities(request?: EntitiesRequest): Promise<EntitiesResponse> {\n    const authorizeDecision = (\n      await this.permissionApi.authorize(\n        [{ permission: catalogEntityReadPermission }],\n        { token: request?.authorizationToken },\n      )\n    )[0];\n\n    if (authorizeDecision.result === AuthorizeResult.DENY) {\n      return {\n        entities: [],\n        pageInfo: { hasNextPage: false },\n      };\n    }\n\n    if (authorizeDecision.result === AuthorizeResult.CONDITIONAL) {\n      const permissionFilter: EntityFilter = this.transformConditions(\n        authorizeDecision.conditions,\n      );\n      return this.entitiesCatalog.entities({\n        ...request,\n        filter: request?.filter\n          ? { allOf: [permissionFilter, request.filter] }\n          : permissionFilter,\n      });\n    }\n\n    return this.entitiesCatalog.entities(request);\n  }\n\n  async removeEntityByUid(\n    uid: string,\n    options?: { authorizationToken?: string },\n  ): Promise<void> {\n    const authorizeResponse = (\n      await this.permissionApi.authorize(\n        [{ permission: catalogEntityDeletePermission }],\n        { token: options?.authorizationToken },\n      )\n    )[0];\n    if (authorizeResponse.result === AuthorizeResult.DENY) {\n      throw new NotAllowedError();\n    }\n    if (authorizeResponse.result === AuthorizeResult.CONDITIONAL) {\n      const permissionFilter: EntityFilter = this.transformConditions(\n        authorizeResponse.conditions,\n      );\n      const { entities } = await this.entitiesCatalog.entities({\n        filter: {\n          allOf: [permissionFilter, basicEntityFilter({ 'metadata.uid': uid })],\n        },\n      });\n      if (entities.length === 0) {\n        throw new NotAllowedError();\n      }\n    }\n    return this.entitiesCatalog.removeEntityByUid(uid);\n  }\n\n  async entityAncestry(\n    entityRef: string,\n    options?: { authorizationToken?: string },\n  ): Promise<EntityAncestryResponse> {\n    const rootEntityAuthorizeResponse = (\n      await this.permissionApi.authorize(\n        [{ permission: catalogEntityReadPermission, resourceRef: entityRef }],\n        { token: options?.authorizationToken },\n      )\n    )[0];\n    if (rootEntityAuthorizeResponse.result === AuthorizeResult.DENY) {\n      throw new NotAllowedError();\n    }\n\n    const ancestryResult = await this.entitiesCatalog.entityAncestry(entityRef);\n    const authorizeResponse = await this.permissionApi.authorize(\n      ancestryResult.items.map(item => ({\n        permission: catalogEntityReadPermission,\n        resourceRef: stringifyEntityRef(item.entity),\n      })),\n      { token: options?.authorizationToken },\n    );\n    const unauthorizedAncestryItems = ancestryResult.items.filter(\n      (_, index) => authorizeResponse[index].result === AuthorizeResult.DENY,\n    );\n    if (unauthorizedAncestryItems.length === 0) {\n      return ancestryResult;\n    }\n    const rootUnauthorizedEntityRefs = unauthorizedAncestryItems.map(\n      ancestryItem => stringifyEntityRef(ancestryItem.entity),\n    );\n    const allUnauthorizedEntityRefs = new Set(\n      rootUnauthorizedEntityRefs.flatMap(rootEntityRef =>\n        this.findParents(\n          rootEntityRef,\n          ancestryResult.items,\n          new Set(rootUnauthorizedEntityRefs),\n        ),\n      ),\n    );\n    return {\n      rootEntityRef: ancestryResult.rootEntityRef,\n      items: ancestryResult.items.filter(\n        ancestryItem =>\n          !allUnauthorizedEntityRefs.has(\n            stringifyEntityRef(ancestryItem.entity),\n          ),\n      ),\n    };\n  }\n\n  async facets(request: EntityFacetsRequest): Promise<EntityFacetsResponse> {\n    const authorizeDecision = (\n      await this.permissionApi.authorize(\n        [{ permission: catalogEntityReadPermission }],\n        { token: request?.authorizationToken },\n      )\n    )[0];\n\n    if (authorizeDecision.result === AuthorizeResult.DENY) {\n      return {\n        facets: Object.fromEntries(request.facets.map(f => [f, []])),\n      };\n    }\n\n    if (authorizeDecision.result === AuthorizeResult.CONDITIONAL) {\n      const permissionFilter: EntityFilter = this.transformConditions(\n        authorizeDecision.conditions,\n      );\n      return this.entitiesCatalog.facets({\n        ...request,\n        filter: request?.filter\n          ? { allOf: [permissionFilter, request.filter] }\n          : permissionFilter,\n      });\n    }\n\n    return this.entitiesCatalog.facets(request);\n  }\n\n  private findParents(\n    entityRef: string,\n    allAncestryItems: { entity: Entity; parentEntityRefs: string[] }[],\n    seenEntityRefs: Set<string>,\n  ): string[] {\n    const entity = allAncestryItems.find(\n      ancestryItem => stringifyEntityRef(ancestryItem.entity) === entityRef,\n    );\n    if (!entity) return [];\n\n    const newSeenEntityRefs = new Set(seenEntityRefs);\n    entity.parentEntityRefs.forEach(parentRef =>\n      newSeenEntityRefs.add(parentRef),\n    );\n\n    return [\n      entityRef,\n      ...entity.parentEntityRefs.flatMap(parentRef =>\n        seenEntityRefs.has(parentRef)\n          ? []\n          : this.findParents(parentRef, allAncestryItems, newSeenEntityRefs),\n      ),\n    ];\n  }\n}\n","/*\n * Copyright 2022 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Location } from '@backstage/catalog-client';\nimport { Entity } from '@backstage/catalog-model';\nimport { NotAllowedError, NotFoundError } from '@backstage/errors';\nimport {\n  catalogLocationCreatePermission,\n  catalogLocationDeletePermission,\n  catalogLocationReadPermission,\n} from '@backstage/plugin-catalog-common';\nimport {\n  AuthorizeResult,\n  PermissionAuthorizer,\n} from '@backstage/plugin-permission-common';\nimport { LocationInput, LocationService } from './types';\n\nexport class AuthorizedLocationService implements LocationService {\n  constructor(\n    private readonly locationService: LocationService,\n    private readonly permissionApi: PermissionAuthorizer,\n  ) {}\n\n  async createLocation(\n    spec: LocationInput,\n    dryRun: boolean,\n    options?: {\n      authorizationToken?: string;\n    },\n  ): Promise<{\n    location: Location;\n    entities: Entity[];\n    exists?: boolean | undefined;\n  }> {\n    const authorizationResponse = (\n      await this.permissionApi.authorize(\n        [{ permission: catalogLocationCreatePermission }],\n        { token: options?.authorizationToken },\n      )\n    )[0];\n\n    if (authorizationResponse.result === AuthorizeResult.DENY) {\n      throw new NotAllowedError();\n    }\n\n    return this.locationService.createLocation(spec, dryRun);\n  }\n\n  async listLocations(options?: {\n    authorizationToken?: string;\n  }): Promise<Location[]> {\n    const authorizationResponse = (\n      await this.permissionApi.authorize(\n        [{ permission: catalogLocationReadPermission }],\n        { token: options?.authorizationToken },\n      )\n    )[0];\n\n    if (authorizationResponse.result === AuthorizeResult.DENY) {\n      return [];\n    }\n\n    return this.locationService.listLocations();\n  }\n\n  async getLocation(\n    id: string,\n    options?: { authorizationToken?: string },\n  ): Promise<Location> {\n    const authorizationResponse = (\n      await this.permissionApi.authorize(\n        [{ permission: catalogLocationReadPermission }],\n        { token: options?.authorizationToken },\n      )\n    )[0];\n\n    if (authorizationResponse.result === AuthorizeResult.DENY) {\n      throw new NotFoundError(`Found no location with ID ${id}`);\n    }\n\n    return this.locationService.getLocation(id);\n  }\n\n  async deleteLocation(\n    id: string,\n    options?: { authorizationToken?: string },\n  ): Promise<void> {\n    const authorizationResponse = (\n      await this.permissionApi.authorize(\n        [{ permission: catalogLocationDeletePermission }],\n        { token: options?.authorizationToken },\n      )\n    )[0];\n\n    if (authorizationResponse.result === AuthorizeResult.DENY) {\n      throw new NotAllowedError();\n    }\n\n    return this.locationService.deleteLocation(id);\n  }\n}\n","/*\n * Copyright 2020 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { PluginDatabaseManager, UrlReader } from '@backstage/backend-common';\nimport {\n  DefaultNamespaceEntityPolicy,\n  Entity,\n  EntityPolicies,\n  EntityPolicy,\n  FieldFormatEntityPolicy,\n  makeValidator,\n  NoForeignRootFieldsEntityPolicy,\n  parseEntityRef,\n  SchemaValidEntityPolicy,\n  stringifyEntityRef,\n  Validators,\n} from '@backstage/catalog-model';\nimport { ScmIntegrations } from '@backstage/integration';\nimport { createHash } from 'crypto';\nimport { Router } from 'express';\nimport lodash, { keyBy } from 'lodash';\nimport { EntitiesCatalog, EntitiesSearchFilter } from '../catalog';\n\nimport {\n  CatalogProcessor,\n  CatalogProcessorParser,\n  EntityProvider,\n} from '../api';\nimport {\n  AnnotateLocationEntityProcessor,\n  BuiltinKindsEntityProcessor,\n  CodeOwnersProcessor,\n  FileReaderProcessor,\n  PlaceholderProcessor,\n  PlaceholderResolver,\n  UrlReaderProcessor,\n} from '../modules';\nimport { ConfigLocationEntityProvider } from '../modules/core/ConfigLocationEntityProvider';\nimport { DefaultLocationStore } from '../modules/core/DefaultLocationStore';\nimport { RepoLocationAnalyzer } from '../ingestion/LocationAnalyzer';\nimport {\n  jsonPlaceholderResolver,\n  textPlaceholderResolver,\n  yamlPlaceholderResolver,\n} from '../modules/core/PlaceholderProcessor';\nimport { defaultEntityDataParser } from '../modules/util/parse';\nimport { LocationAnalyzer } from '../ingestion/types';\nimport { CatalogProcessingEngine } from '../processing/types';\nimport { DefaultProcessingDatabase } from '../database/DefaultProcessingDatabase';\nimport { applyDatabaseMigrations } from '../database/migrations';\nimport { DefaultCatalogProcessingEngine } from '../processing/DefaultCatalogProcessingEngine';\nimport { DefaultLocationService } from './DefaultLocationService';\nimport { DefaultEntitiesCatalog } from './DefaultEntitiesCatalog';\nimport { DefaultCatalogProcessingOrchestrator } from '../processing/DefaultCatalogProcessingOrchestrator';\nimport { Stitcher } from '../stitching/Stitcher';\nimport {\n  createRandomProcessingInterval,\n  RefreshIntervalFunction,\n  ProcessingIntervalFunction,\n} from '../processing/refresh';\nimport { createRouter } from './createRouter';\nimport { DefaultRefreshService } from './DefaultRefreshService';\nimport { AuthorizedRefreshService } from './AuthorizedRefreshService';\nimport { DefaultCatalogRulesEnforcer } from '../ingestion/CatalogRules';\nimport { Config } from '@backstage/config';\nimport { Logger } from 'winston';\nimport { LocationService } from './types';\nimport { connectEntityProviders } from '../processing/connectEntityProviders';\nimport { permissionRules as catalogPermissionRules } from '../permissions/rules';\nimport { PermissionAuthorizer } from '@backstage/plugin-permission-common';\nimport {\n  PermissionRule,\n  createConditionTransformer,\n  createPermissionIntegrationRouter,\n} from '@backstage/plugin-permission-node';\nimport { AuthorizedEntitiesCatalog } from './AuthorizedEntitiesCatalog';\nimport { basicEntityFilter } from './request/basicEntityFilter';\nimport { RESOURCE_TYPE_CATALOG_ENTITY } from '@backstage/plugin-catalog-common';\nimport { AuthorizedLocationService } from './AuthorizedLocationService';\n\n/** @public */\nexport type CatalogEnvironment = {\n  logger: Logger;\n  database: PluginDatabaseManager;\n  config: Config;\n  reader: UrlReader;\n  permissions: PermissionAuthorizer;\n};\n\n/**\n * A builder that helps wire up all of the component parts of the catalog.\n *\n * The touch points where you can replace or extend behavior are as follows:\n *\n * - Entity policies can be added or replaced. These are automatically run\n *   after the processors' pre-processing steps. All policies are given the\n *   chance to inspect the entity, and all of them have to pass in order for\n *   the entity to be considered valid from an overall point of view.\n * - Placeholder resolvers can be replaced or added. These run on the raw\n *   structured data between the parsing and pre-processing steps, to replace\n *   dollar-prefixed entries with their actual values (like $file).\n * - Field format validators can be replaced. These check the format of\n *   individual core fields such as metadata.name, to ensure that they adhere\n *   to certain rules.\n * - Processors can be added or replaced. These implement the functionality of\n *   reading, parsing, validating, and processing the entity data before it is\n *   persisted in the catalog.\n *\n * @public\n */\nexport class CatalogBuilder {\n  private readonly env: CatalogEnvironment;\n  private entityPolicies: EntityPolicy[];\n  private entityPoliciesReplace: boolean;\n  private placeholderResolvers: Record<string, PlaceholderResolver>;\n  private fieldFormatValidators: Partial<Validators>;\n  private entityProviders: EntityProvider[];\n  private processors: CatalogProcessor[];\n  private processorsReplace: boolean;\n  private parser: CatalogProcessorParser | undefined;\n  private processingInterval: ProcessingIntervalFunction =\n    createRandomProcessingInterval({\n      minSeconds: 100,\n      maxSeconds: 150,\n    });\n  private locationAnalyzer: LocationAnalyzer | undefined = undefined;\n  private permissionRules: PermissionRule<\n    Entity,\n    EntitiesSearchFilter,\n    unknown[]\n  >[];\n\n  /**\n   * Creates a catalog builder.\n   */\n  static create(env: CatalogEnvironment): CatalogBuilder {\n    return new CatalogBuilder(env);\n  }\n\n  private constructor(env: CatalogEnvironment) {\n    this.env = env;\n    this.entityPolicies = [];\n    this.entityPoliciesReplace = false;\n    this.placeholderResolvers = {};\n    this.fieldFormatValidators = {};\n    this.entityProviders = [];\n    this.processors = [];\n    this.processorsReplace = false;\n    this.parser = undefined;\n    this.permissionRules = Object.values(catalogPermissionRules);\n  }\n\n  /**\n   * Adds policies that are used to validate entities between the pre-\n   * processing and post-processing stages. All such policies must pass for the\n   * entity to be considered valid.\n   *\n   * If what you want to do is to replace the rules for what format is allowed\n   * in various core entity fields (such as metadata.name), you may want to use\n   * {@link CatalogBuilder#setFieldFormatValidators} instead.\n   *\n   * @param policies - One or more policies\n   */\n  addEntityPolicy(...policies: EntityPolicy[]): CatalogBuilder {\n    this.entityPolicies.push(...policies);\n    return this;\n  }\n\n  /**\n   * Refresh interval determines how often entities should be refreshed.\n   * Seconds provided will be multiplied by 1.5\n   * The default refresh duration is 100-150 seconds.\n   * setting this too low will potentially deplete request quotas to upstream services.\n   *\n   * @deprecated use {@link CatalogBuilder#setProcessingIntervalSeconds} instead\n   */\n  setRefreshIntervalSeconds(seconds: number): CatalogBuilder {\n    this.env.logger.warn(\n      '[DEPRECATION] - CatalogBuilder.setRefreshIntervalSeconds is deprecated. Use CatalogBuilder.setProcessingIntervalSeconds instead.',\n    );\n    this.processingInterval = createRandomProcessingInterval({\n      minSeconds: seconds,\n      maxSeconds: seconds * 1.5,\n    });\n    return this;\n  }\n\n  /**\n   * Processing interval determines how often entities should be processed.\n   * Seconds provided will be multiplied by 1.5\n   * The default processing interval is 100-150 seconds.\n   * setting this too low will potentially deplete request quotas to upstream services.\n   */\n  setProcessingIntervalSeconds(seconds: number): CatalogBuilder {\n    this.processingInterval = createRandomProcessingInterval({\n      minSeconds: seconds,\n      maxSeconds: seconds * 1.5,\n    });\n    return this;\n  }\n\n  /**\n   * Overwrites the default refresh interval function used to spread\n   * entity updates in the catalog.\n   *\n   * @deprecated use {@link CatalogBuilder#setProcessingInterval} instead\n   */\n  setRefreshInterval(refreshInterval: RefreshIntervalFunction): CatalogBuilder {\n    this.env.logger.warn(\n      '[DEPRECATION] - CatalogBuilder.setRefreshInterval is deprecated. Use CatalogBuilder.setProcessingInterval instead.',\n    );\n    this.processingInterval = refreshInterval;\n    return this;\n  }\n\n  /**\n   * Overwrites the default processing interval function used to spread\n   * entity updates in the catalog.\n   */\n  setProcessingInterval(\n    processingInterval: ProcessingIntervalFunction,\n  ): CatalogBuilder {\n    this.processingInterval = processingInterval;\n    return this;\n  }\n\n  /**\n   * Overwrites the default location analyzer.\n   */\n  setLocationAnalyzer(locationAnalyzer: LocationAnalyzer): CatalogBuilder {\n    this.locationAnalyzer = locationAnalyzer;\n    return this;\n  }\n\n  /**\n   * Sets what policies to use for validation of entities between the pre-\n   * processing and post-processing stages. All such policies must pass for the\n   * entity to be considered valid.\n   *\n   * If what you want to do is to replace the rules for what format is allowed\n   * in various core entity fields (such as metadata.name), you may want to use\n   * {@link CatalogBuilder#setFieldFormatValidators} instead.\n   *\n   * This function replaces the default set of policies; use with care.\n   *\n   * @param policies - One or more policies\n   */\n  replaceEntityPolicies(policies: EntityPolicy[]): CatalogBuilder {\n    this.entityPolicies = [...policies];\n    this.entityPoliciesReplace = true;\n    return this;\n  }\n\n  /**\n   * Adds, or overwrites, a handler for placeholders (e.g. $file) in entity\n   * definition files.\n   *\n   * @param key - The key that identifies the placeholder, e.g. \"file\"\n   * @param resolver - The resolver that gets values for this placeholder\n   */\n  setPlaceholderResolver(\n    key: string,\n    resolver: PlaceholderResolver,\n  ): CatalogBuilder {\n    this.placeholderResolvers[key] = resolver;\n    return this;\n  }\n\n  /**\n   * Sets the validator function to use for one or more special fields of an\n   * entity. This is useful if the default rules for formatting of fields are\n   * not sufficient.\n   *\n   * This function has no effect if used together with\n   * {@link CatalogBuilder#replaceEntityPolicies}.\n   *\n   * @param validators - The (subset of) validators to set\n   */\n  setFieldFormatValidators(validators: Partial<Validators>): CatalogBuilder {\n    lodash.merge(this.fieldFormatValidators, validators);\n    return this;\n  }\n\n  /**\n   * Adds or replaces entity providers. These are responsible for bootstrapping\n   * the list of entities out of original data sources. For example, there is\n   * one entity source for the config locations, and one for the database\n   * stored locations. If you ingest entities out of a third party system, you\n   * may want to implement that in terms of an entity provider as well.\n   *\n   * @param providers - One or more entity providers\n   */\n  addEntityProvider(...providers: EntityProvider[]): CatalogBuilder {\n    this.entityProviders.push(...providers);\n    return this;\n  }\n\n  /**\n   * Adds entity processors. These are responsible for reading, parsing, and\n   * processing entities before they are persisted in the catalog.\n   *\n   * @param processors - One or more processors\n   */\n  addProcessor(...processors: CatalogProcessor[]): CatalogBuilder {\n    this.processors.push(...processors);\n    return this;\n  }\n\n  /**\n   * Sets what entity processors to use. These are responsible for reading,\n   * parsing, and processing entities before they are persisted in the catalog.\n   *\n   * This function replaces the default set of processors, consider using with\n   * {@link CatalogBuilder#getDefaultProcessors}; use with care.\n   *\n   * @param processors - One or more processors\n   */\n  replaceProcessors(processors: CatalogProcessor[]): CatalogBuilder {\n    this.processors = [...processors];\n    this.processorsReplace = true;\n    return this;\n  }\n\n  /**\n   * Returns the default list of entity processors. These are responsible for reading,\n   * parsing, and processing entities before they are persisted in the catalog. Changing\n   * the order of processing can give more control to custom processors.\n   *\n   * Consider using with {@link CatalogBuilder#replaceProcessors}\n   *\n   */\n  getDefaultProcessors(): CatalogProcessor[] {\n    const { config, logger, reader } = this.env;\n    const integrations = ScmIntegrations.fromConfig(config);\n\n    return [\n      new FileReaderProcessor(),\n      new UrlReaderProcessor({ reader, logger }),\n      CodeOwnersProcessor.fromConfig(config, { logger, reader }),\n      new AnnotateLocationEntityProcessor({ integrations }),\n    ];\n  }\n\n  /**\n   * Sets up the catalog to use a custom parser for entity data.\n   *\n   * This is the function that gets called immediately after some raw entity\n   * specification data has been read from a remote source, and needs to be\n   * parsed and emitted as structured data.\n   *\n   * @param parser - The custom parser\n   */\n  setEntityDataParser(parser: CatalogProcessorParser): CatalogBuilder {\n    this.parser = parser;\n    return this;\n  }\n\n  /**\n   * Adds additional permission rules. Permission rules are used to evaluate\n   * catalog resources against queries. See\n   * {@link @backstage/plugin-permission-node#PermissionRule}.\n   *\n   * @param permissionRules - Additional permission rules\n   */\n  addPermissionRules(\n    ...permissionRules: PermissionRule<\n      Entity,\n      EntitiesSearchFilter,\n      unknown[]\n    >[]\n  ) {\n    this.permissionRules.push(...permissionRules);\n  }\n\n  /**\n   * Wires up and returns all of the component parts of the catalog\n   */\n  async build(): Promise<{\n    entitiesCatalog: EntitiesCatalog;\n    locationAnalyzer: LocationAnalyzer;\n    processingEngine: CatalogProcessingEngine;\n    locationService: LocationService;\n    router: Router;\n  }> {\n    const { config, database, logger, permissions } = this.env;\n\n    const policy = this.buildEntityPolicy();\n    const processors = this.buildProcessors();\n    const parser = this.parser || defaultEntityDataParser;\n\n    const dbClient = await database.getClient();\n    if (!database.migrations?.skip) {\n      logger.info('Performing database migration');\n      await applyDatabaseMigrations(dbClient);\n    }\n\n    const processingDatabase = new DefaultProcessingDatabase({\n      database: dbClient,\n      logger,\n      refreshInterval: this.processingInterval,\n    });\n    const integrations = ScmIntegrations.fromConfig(config);\n    const rulesEnforcer = DefaultCatalogRulesEnforcer.fromConfig(config);\n    const orchestrator = new DefaultCatalogProcessingOrchestrator({\n      processors,\n      integrations,\n      rulesEnforcer,\n      logger,\n      parser,\n      policy,\n    });\n    const unauthorizedEntitiesCatalog = new DefaultEntitiesCatalog(dbClient);\n    const entitiesCatalog = new AuthorizedEntitiesCatalog(\n      unauthorizedEntitiesCatalog,\n      permissions,\n      createConditionTransformer(this.permissionRules),\n    );\n    const permissionIntegrationRouter = createPermissionIntegrationRouter({\n      resourceType: RESOURCE_TYPE_CATALOG_ENTITY,\n      getResources: async (resourceRefs: string[]) => {\n        const { entities } = await unauthorizedEntitiesCatalog.entities({\n          filter: {\n            anyOf: resourceRefs.map(resourceRef => {\n              const { kind, namespace, name } = parseEntityRef(resourceRef);\n\n              return basicEntityFilter({\n                kind,\n                'metadata.namespace': namespace,\n                'metadata.name': name,\n              });\n            }),\n          },\n        });\n\n        const entitiesByRef = keyBy(entities, stringifyEntityRef);\n\n        return resourceRefs.map(\n          resourceRef =>\n            entitiesByRef[stringifyEntityRef(parseEntityRef(resourceRef))],\n        );\n      },\n      rules: this.permissionRules,\n    });\n    const stitcher = new Stitcher(dbClient, logger);\n\n    const locationStore = new DefaultLocationStore(dbClient);\n    const configLocationProvider = new ConfigLocationEntityProvider(config);\n    const entityProviders = lodash.uniqBy(\n      [...this.entityProviders, locationStore, configLocationProvider],\n      provider => provider.getProviderName(),\n    );\n\n    const processingEngine = new DefaultCatalogProcessingEngine(\n      logger,\n      processingDatabase,\n      orchestrator,\n      stitcher,\n      () => createHash('sha1'),\n    );\n\n    const locationAnalyzer =\n      this.locationAnalyzer ?? new RepoLocationAnalyzer(logger, integrations);\n    const locationService = new AuthorizedLocationService(\n      new DefaultLocationService(locationStore, orchestrator),\n      permissions,\n    );\n    const refreshService = new AuthorizedRefreshService(\n      new DefaultRefreshService({ database: processingDatabase }),\n      permissions,\n    );\n    const router = await createRouter({\n      entitiesCatalog,\n      locationAnalyzer,\n      locationService,\n      refreshService,\n      logger,\n      config,\n      permissionIntegrationRouter,\n    });\n\n    await connectEntityProviders(processingDatabase, entityProviders);\n\n    return {\n      entitiesCatalog,\n      locationAnalyzer,\n      processingEngine,\n      locationService,\n      router,\n    };\n  }\n\n  private buildEntityPolicy(): EntityPolicy {\n    const entityPolicies: EntityPolicy[] = this.entityPoliciesReplace\n      ? [new SchemaValidEntityPolicy(), ...this.entityPolicies]\n      : [\n          new SchemaValidEntityPolicy(),\n          new DefaultNamespaceEntityPolicy(),\n          new NoForeignRootFieldsEntityPolicy(),\n          new FieldFormatEntityPolicy(\n            makeValidator(this.fieldFormatValidators),\n          ),\n          ...this.entityPolicies,\n        ];\n\n    return EntityPolicies.allOf(entityPolicies);\n  }\n\n  private buildProcessors(): CatalogProcessor[] {\n    const { config, reader } = this.env;\n    const integrations = ScmIntegrations.fromConfig(config);\n\n    this.checkDeprecatedReaderProcessors();\n\n    const placeholderResolvers: Record<string, PlaceholderResolver> = {\n      json: jsonPlaceholderResolver,\n      yaml: yamlPlaceholderResolver,\n      text: textPlaceholderResolver,\n      ...this.placeholderResolvers,\n    };\n\n    // These are always there no matter what\n    const processors: CatalogProcessor[] = [\n      new PlaceholderProcessor({\n        resolvers: placeholderResolvers,\n        reader,\n        integrations,\n      }),\n      new BuiltinKindsEntityProcessor(),\n    ];\n\n    // These are only added unless the user replaced them all\n    if (!this.processorsReplace) {\n      processors.push(...this.getDefaultProcessors());\n    }\n\n    // Add the ones (if any) that the user added\n    processors.push(...this.processors);\n\n    this.checkMissingExternalProcessors(processors);\n\n    return processors;\n  }\n\n  // TODO(Rugvip): These old processors are removed, for a while we'll be throwing\n  //               errors here to make sure people know where to move the config\n  private checkDeprecatedReaderProcessors() {\n    const pc = this.env.config.getOptionalConfig('catalog.processors');\n    if (pc?.has('github')) {\n      throw new Error(\n        `Using deprecated configuration for catalog.processors.github, move to using integrations.github instead`,\n      );\n    }\n    if (pc?.has('gitlabApi')) {\n      throw new Error(\n        `Using deprecated configuration for catalog.processors.gitlabApi, move to using integrations.gitlab instead`,\n      );\n    }\n    if (pc?.has('bitbucketApi')) {\n      throw new Error(\n        `Using deprecated configuration for catalog.processors.bitbucketApi, move to using integrations.bitbucket instead`,\n      );\n    }\n    if (pc?.has('azureApi')) {\n      throw new Error(\n        `Using deprecated configuration for catalog.processors.azureApi, move to using integrations.azure instead`,\n      );\n    }\n  }\n\n  // TODO(freben): This can be removed no sooner than June 2022, after adopters have had some time to adapt to the new package structure\n  private checkMissingExternalProcessors(processors: CatalogProcessor[]) {\n    const skipCheckVarName = 'BACKSTAGE_CATALOG_SKIP_MISSING_PROCESSORS_CHECK';\n    if (process.env[skipCheckVarName]) {\n      return;\n    }\n\n    const locationTypes = new Set(\n      this.env.config\n        .getOptionalConfigArray('catalog.locations')\n        ?.map(l => l.getString('type')) ?? [],\n    );\n    const processorNames = new Set(processors.map(p => p.getProcessorName()));\n\n    function check(\n      locationType: string,\n      processorName: string,\n      installationUrl: string,\n    ) {\n      if (\n        locationTypes.has(locationType) &&\n        !processorNames.has(processorName)\n      ) {\n        throw new Error(\n          [\n            `Your config contains a \"catalog.locations\" entry of type ${locationType},`,\n            `but does not have the corresponding catalog processor ${processorName} installed.`,\n            `This processor used to be built into the catalog itself, but is now moved to an`,\n            `external module that has to be installed manually. Please follow the installation`,\n            `instructions at ${installationUrl} if you are using this ability, or remove the`,\n            `location from your app config if you do not. You can also silence this check entirely`,\n            `by setting the environment variable ${skipCheckVarName} to 'true'.`,\n          ].join(' '),\n        );\n      }\n    }\n\n    check(\n      'aws-cloud-accounts',\n      'AwsOrganizationCloudAccountProcessor',\n      'https://backstage.io/docs/integrations',\n    );\n    check(\n      's3-discovery',\n      'AwsS3DiscoveryProcessor',\n      'https://backstage.io/docs/integrations/aws-s3/discovery',\n    );\n    check(\n      'azure-discovery',\n      'AzureDevOpsDiscoveryProcessor',\n      'https://backstage.io/docs/integrations/azure/discovery',\n    );\n    check(\n      'bitbucket-discovery',\n      'BitbucketDiscoveryProcessor',\n      'https://backstage.io/docs/integrations/bitbucket/discovery',\n    );\n    check(\n      'github-discovery',\n      'GithubDiscoveryProcessor',\n      'https://backstage.io/docs/integrations/github/discovery',\n    );\n    check(\n      'github-org',\n      'GithubOrgReaderProcessor',\n      'https://backstage.io/docs/integrations/github/org',\n    );\n    check(\n      'gitlab-discovery',\n      'GitLabDiscoveryProcessor',\n      'https://backstage.io/docs/integrations/gitlab/discovery',\n    );\n    check(\n      'ldap-org',\n      'LdapOrgReaderProcessor',\n      'https://backstage.io/docs/integrations/ldap/org',\n    );\n    check(\n      'microsoft-graph-org',\n      'MicrosoftGraphOrgReaderProcessor',\n      'https://backstage.io/docs/integrations/azure/org',\n    );\n  }\n}\n","/*\n * Copyright 2022 The Backstage Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { RESOURCE_TYPE_CATALOG_ENTITY } from '@backstage/plugin-catalog-common';\nimport { createConditionExports } from '@backstage/plugin-permission-node';\nimport { permissionRules } from './rules';\n\nconst conditionExports = createConditionExports({\n  pluginId: 'catalog',\n  resourceType: RESOURCE_TYPE_CATALOG_ENTITY,\n  rules: permissionRules,\n});\n\n/**\n * These conditions are used when creating conditional decisions that are returned\n * by authorization policies.\n *\n * @alpha\n */\nexport const catalogConditions = conditionExports.conditions;\n\n/**\n * `createCatalogPolicyDecision` can be used when authoring policies to create\n * conditional decisions.\n *\n * ```\n * // MyAuthorizationPolicy.ts\n * ...\n * import { createCatalogPolicyDecision } from '@backstage/plugin-catalog-backend';\n *\n * class MyAuthorizationPolicy implements PermissionPolicy {\n *   async handle(request, user) {\n *     ...\n *\n *     return createCatalogPolicyDecision({\n *       anyOf: [...insert conditions here...],\n *     });\n *   }\n * }\n * ```\n *\n * @alpha\n */\nexport const createCatalogPolicyDecision =\n  conditionExports.createPolicyDecision;\n"],"names":["NotFoundError","InputError","path","codeowners","pipe","filter","reverse","head","get","ScmIntegrations","stringifyLocationRef","merge","pickBy","ANNOTATION_LOCATION","ANNOTATION_ORIGIN_LOCATION","ANNOTATION_VIEW_URL","ANNOTATION_EDIT_URL","ANNOTATION_SOURCE_LOCATION","identity","parseGitUrl","apiEntityV1alpha1Validator","componentEntityV1alpha1Validator","resourceEntityV1alpha1Validator","groupEntityV1alpha1Validator","locationEntityV1alpha1Validator","userEntityV1alpha1Validator","systemEntityV1alpha1Validator","domainEntityV1alpha1Validator","getCompoundEntityRef","parseEntityRef","RELATION_OWNED_BY","RELATION_OWNER_OF","RELATION_PART_OF","RELATION_HAS_PART","RELATION_PROVIDES_API","RELATION_API_PROVIDED_BY","RELATION_CONSUMES_API","RELATION_API_CONSUMED_BY","RELATION_DEPENDS_ON","RELATION_DEPENDENCY_OF","RELATION_MEMBER_OF","RELATION_HAS_MEMBER","RELATION_CHILD_OF","RELATION_PARENT_OF","promisify","g","fs","toAbsoluteUrl","yaml","limiterFactory","lodash","catalogEntityReadPermission","catalogClient","CatalogClient","Readable","stringifyEntityRef","createHash","entitySchemaValidator","entityEnvelopeSchemaValidator","parseLocationRef","NotAllowedError","ConflictError","z","Router","express","yn","errorHandler","uuid","DateTime","register","Counter","Gauge","Summary","stableStringify","BATCH_SIZE","errors","isDatabaseConflictError","isError","generateStableHash","resolvePackagePath","serializeError","DEFAULT_NAMESPACE","stringifyError","ENTITY_STATUS_CATALOG_PROCESSING_TYPE","uniqBy","catalogEntityRefreshPermission","AuthorizeResult","makeCreatePermissionRule","catalogEntityDeletePermission","catalogLocationCreatePermission","catalogLocationReadPermission","catalogLocationDeletePermission","catalogPermissionRules","createConditionTransformer","createPermissionIntegrationRouter","RESOURCE_TYPE_CATALOG_ENTITY","keyBy","SchemaValidEntityPolicy","DefaultNamespaceEntityPolicy","NoForeignRootFieldsEntityPolicy","FieldFormatEntityPolicy","makeValidator","EntityPolicies","createConditionExports"],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;uBA4BE,YACA,SACwB;AACxB,SAAO;AAAA,IACL,MAAM;AAAA,IACN,UAAU;AAAA,IACV,OAAO,IAAIA,qBAAc;AAAA;AAAA;oBAS3B,YACA,SACwB;AACxB,SAAO;AAAA,IACL,MAAM;AAAA,IACN,UAAU;AAAA,IACV,OAAO,IAAIC,kBAAW;AAAA;AAAA;sBASxB,YACA,SACwB;AACxB,SAAO,EAAE,MAAM,SAAS,UAAU,YAAY,OAAO,IAAI,MAAM;AAAA;kBAQ/D,aACA,WACwB;AACxB,SAAO,EAAE,MAAM,YAAY,UAAU;AAAA;gBAQrC,YACA,WACwB;AACxB,SAAO,EAAE,MAAM,UAAU,UAAU,YAAY,QAAQ;AAAA;kBAOhC,MAAkD;AACzE,SAAO,EAAE,MAAM,YAAY,UAAU;AAAA;;;;;;;;;;;;MCjE1B,mBAAmB,OAAO,OAAO;AAAA,EAC5C,cACE,YACA,SACwB;AACxB,WAAO;AAAA,MACL,MAAM;AAAA,MACN,UAAU;AAAA,MACV,OAAO,IAAID,qBAAc;AAAA;AAAA;AAAA,EAI7B,WACE,YACA,SACwB;AACxB,WAAO;AAAA,MACL,MAAM;AAAA,MACN,UAAU;AAAA,MACV,OAAO,IAAIC,kBAAW;AAAA;AAAA;AAAA,EAI1B,aACE,YACA,SACwB;AACxB,WAAO,EAAE,MAAM,SAAS,UAAU,YAAY,OAAO,IAAI,MAAM;AAAA;AAAA,EAGjE,SAAS,aAAmD;AAC1D,WAAO,EAAE,MAAM,YAAY,UAAU;AAAA;AAAA,EAGvC,OAAO,YAA0B,WAA2C;AAC1E,WAAO,EAAE,MAAM,UAAU,UAAU,YAAY,QAAQ;AAAA;AAAA,EAGzD,SAAS,MAAkD;AACzD,WAAO,EAAE,MAAM,YAAY,UAAU;AAAA;AAAA;;ACXlC,2CAAkE;AAAA,EA4EvE,YAA6B,OAAsB;AAAtB;AAAA;AAAA,SAlCtB,WAAW,QAAgB;AAChC,UAAM,QAAQ,IAAI;AAElB,QAAI,OAAO,IAAI,kBAAkB;AAC/B,YAAM,cAAc,OAAO,eAAe,iBAAiB,IAAI;AAAQ,QACrE,OAAO,IAAI,eAAe,SAAS,IAAI,aAAW;AAAA;AAEpD,YAAM,KAAK,GAAG;AAAA,WACT;AACL,YAAM,KAAK,GAAG,6BAA4B;AAAA;AAG5C,QAAI,OAAO,IAAI,sBAAsB;AACnC,YAAM,gBAAgB,OACnB,eAAe,qBACf,QAAQ,aAAW;AAClB,YAAI,CAAC,QAAQ,IAAI,UAAU;AACzB,iBAAO;AAAA;AAET,cAAM,OAAO,QAAQ,UAAU;AAC/B,cAAM,SAAS,cAAc,MAAM,QAAQ,UAAU;AAErD,eAAO,QAAQ,eAAe,SAAS,IAAI;AAAa,UACtD,OAAO,SAAS,eAAe,SAAS,IAAI,aAAW;AAAA,UACvD,WAAW,CAAC,EAAE,MAAM;AAAA;AAAA;AAI1B,YAAM,KAAK,GAAG;AAAA;AAGhB,WAAO,IAAI,6BAA4B;AAAA;AAAA,EASzC,UAAU,QAAgB,UAAwB;AAChD,eAAW,QAAQ,KAAK,OAAO;AAC7B,UAAI,CAAC,KAAK,cAAc,UAAU,KAAK,YAAY;AACjD;AAAA;AAGF,UAAI,KAAK,YAAY,QAAQ,KAAK,QAAQ;AACxC,eAAO;AAAA;AAAA;AAIX,WAAO;AAAA;AAAA,EAGD,cACN,UACA,UACS;AACT,QAAI,CAAC,UAAU;AACb,aAAO;AAAA;AAGT,eAAW,WAAW,UAAU;AAC9B,UAAI,QAAQ,+CAAmB,OAAM;AACnC;AAAA;AAEF,UAAI,QAAQ,UAAU,QAAQ,iDAAqB,SAAQ;AACzD;AAAA;AAEF,aAAO;AAAA;AAGT,WAAO;AAAA;AAAA,EAGD,YAAY,QAAgB,UAAwC;AA3K9E;AA4KI,QAAI,CAAC,UAAU;AACb,aAAO;AAAA;AAGT,eAAW,WAAW,UAAU;AAC9B,UAAI,wCAAQ,SAAR,mBAAc,mBAAkB,QAAQ,KAAK,eAAe;AAC9D;AAAA;AAGF,aAAO;AAAA;AAGT,WAAO;AAAA;AAAA;;AAlIJ,4BAMW,eAA8B;AAAA,EAC5C;AAAA,IACE,OAAO,CAAC,aAAa,OAAO,YAAY,IAAI,aAAW;AAAA;AAAA;AA8H7D,uBAAuB,MAAc,QAAwB;AAC3D,MAAI,SAAS,QAAQ;AACnB,WAAO;AAAA;AAGT,SAAOC,yBAAK,QAAQ;AAAA;;AC7KtB,MAAM,eAAe;AACrB,MAAM,gBAAgB;AACtB,MAAM,gBAAgB;0BAGpB,UACA,UAAU,KACU;AACpB,QAAM,SAASC,sBAAW,MAAM;AAEhC,SAAOC,QACLC,UAAO,CAAC,MAAuB,EAAE,YAAY,UAC7CC,YACAC,SACAC,OAAI,WACJD,SACA,oBACA;AAAA;4BAG+B,OAAe;AAChD,MAAI,MAAM,MAAM,gBAAgB;AAC9B,WAAO,MAAM,MAAM,KAAK;AAAA,aACf,MAAM,MAAM,eAAe;AACpC,WAAO,QAAQ,MAAM,UAAU;AAAA,aACtB,MAAM,MAAM,gBAAgB;AACrC,WAAO,MAAM,MAAM,KAAK;AAAA;AAG1B,SAAO;AAAA;;ACjCT,MAAM,aAAa;MAEN,qBAA+C;AAAA,EAE1D,WAAW,CAAC,YAAY,cAAc;AAAA,EAGtC,QAAQ,CAAC,YAAY,WAAW,cAAc,QAAQ;AAAA,EAGtD,QAAQ,CAAC,YAAY,WAAW,cAAc,QAAQ;AAAA;;8BCFtD,QACA,WACA,iBAC6B;AAC7B,QAAM,oBAAoB,OAAO,SAAkC;AACjE,UAAM,MAAM,GAAG,YAAY;AAE3B,QAAI,OAAO,SAAS;AAClB,YAAM,QAAO,MAAM,OAAO,QAAQ;AAClC,YAAM,SAAS,MAAM,MAAK;AAC1B,aAAO,OAAO;AAAA;AAEhB,UAAM,OAAO,MAAM,OAAO,KAAK;AAC/B,WAAO,KAAK;AAAA;AAGd,QAAM,aAAa,gBAAgB,IAAI;AAEvC,SAAO,QAAQ,IAAI,YAAY,MAAM,CAAC,mBAAmC;AACvE,UAAM,YAAY,eAAe,OAAO,KACtC,WAAS,mBAAmBP;AAG9B,QAAI,WAAW;AACb,YAAM;AAAA;AAGR,WAAO;AAAA;AAAA;qCAKT,QACA,WACA,gBAC6B;AA3D/B;AA4DE,QAAM,kBAAkB,mBAAmB,uDAAgB,SAAhB,YAAwB;AAEnE,QAAM,YAAY,iDAAgB,WAAW;AAAA,IAC3C,KAAK;AAAA,IACL,MAAM;AAAA;AAGR,MAAI,CAAC,aAAa,CAAC,iBAAiB;AAClC,WAAO;AAAA;AAGT,QAAM,WAAW,MAAM,eAAe,QAAQ,WAAW;AAEzD,MAAI,CAAC,UAAU;AACb,WAAO;AAAA;AAGT,QAAM,QAAQ,iBAAiB;AAE/B,SAAO;AAAA;;ACpDT,MAAM,gBAAgB,CAAC,OAAO,aAAa,UAAU,YAAY;AACjE,MAAM,yBAAyB,CAAC;0BAG6B;AAAA,SAKpD,WACL,QACA,SACA;AACA,UAAM,eAAeS,4BAAgB,WAAW;AAEhD,WAAO,IAAI,oBAAoB;AAAA,SAC1B;AAAA,MACH;AAAA;AAAA;AAAA,EAIJ,YAAY,SAIT;AACD,SAAK,eAAe,QAAQ;AAC5B,SAAK,SAAS,QAAQ;AACtB,SAAK,SAAS,QAAQ;AAAA;AAAA,EAGxB,mBAA2B;AACzB,WAAO;AAAA;AAAA,QAGH,iBACJ,QACA,UACiB;AAEjB,QACE,CAAC,UACD,CAAC,cAAc,SAAS,OAAO,SAC/B,CAAC,uBAAuB,SAAS,SAAS,SACzC,OAAO,QAAQ,OAAO,KAAK,OAC5B;AACA,aAAO;AAAA;AAGT,UAAM,iBAAiB,KAAK,aAAa,MAAM,SAAS;AACxD,QAAI,CAAC,gBAAgB;AACnB,aAAO;AAAA;AAGT,UAAM,QAAQ,MAAM,sBAClB,KAAK,QACL,SAAS,QACT;AAGF,QAAI,CAAC,OAAO;AACV,WAAK,OAAO,MACV,kDAAkD,SAAS;AAE7D,aAAO;AAAA;AAGT,WAAO;AAAA,SACF;AAAA,MACH,MAAM,KAAK,OAAO,MAAM;AAAA;AAAA;AAAA;;sCC9D2C;AAAA,EACvE,YACmB,SAGjB;AAHiB;AAAA;AAAA,EAKnB,mBAA2B;AACzB,WAAO;AAAA;AAAA,QAGH,iBACJ,QACA,UACA,GACA,gBACiB;AACjB,UAAM,EAAE,iBAAiB,KAAK;AAC9B,QAAI;AACJ,QAAI;AACJ,QAAI;AAEJ,QAAI,SAAS,SAAS,OAAO;AAC3B,YAAM,iBAAiB,aAAa,MAAM,SAAS;AAEnD,gBAAU,SAAS;AACnB,gBAAU,iDAAgB,eAAe,SAAS;AAElD,YAAM,YAAY,iDAAgB,WAAW;AAAA,QAC3C,KAAK;AAAA,QACL,MAAM,SAAS;AAAA;AAGjB,UAAI,WAAW;AACb,yBAAiBC,kCAAqB;AAAA,UACpC,MAAM;AAAA,UACN,QAAQ;AAAA;AAAA;AAAA;AAKd,WAAOC,aACL;AAAA,MACE,UAAU;AAAA,QACR,aAAaC,cACX;AAAA,WACGC,mCAAsBH,kCAAqB;AAAA,WAC3CI,0CACCJ,kCAAqB;AAAA,WACtBK,mCAAsB;AAAA,WACtBC,mCAAsB;AAAA,WACtBC,0CAA6B;AAAA,WAEhCC;AAAA;AAAA,OAIN;AAAA;AAAA;;AClEN,MAAM,4BAA4B;qCAGsC;AAAA,EACtE,YACmB,MACjB;AADiB;AAAA;AAAA,EAGnB,mBAA2B;AACzB,WAAO;AAAA;AAAA,SAGF,WAAW,QAAgD;AAChE,WAAO,IAAI,+BAA+B;AAAA,MACxC,wBAAwBT,4BAAgB,WAAW;AAAA;AAAA;AAAA,QAIjD,iBACJ,QACA,UACiB;AA9CrB;AA+CI,QAAI,OAAO,SAAS,eAAe,SAAS,SAAS,OAAO;AAC1D,aAAO;AAAA;AAGT,UAAM,iBAAiB,KAAK,KAAK,uBAAuB,MACtD,SAAS;AAGX,QAAI,CAAC,kBAAkB,eAAe,SAAS,UAAU;AACvD,aAAO;AAAA;AAGT,UAAM,SAASU,gCAAY,SAAS;AACpC,QAAI,oBACF,aAAO,SAAS,gBAAhB,mBAA8B;AAEhC,QAAI,CAAC,mBAAmB;AACtB,0BAAoB,GAAG,OAAO,SAAS,OAAO;AAAA;AAGhD,WAAOR,aACL;AAAA,MACE,UAAU;AAAA,QACR,aAAaC,cACX;AAAA,WACG,4BAA4B;AAAA,WAE/BM;AAAA;AAAA,OAIN;AAAA;AAAA;;kCCpB+D;AAAA,EAA9D,cA1DP;AA2DmB,sBAAa;AAAA,MAC5BE;AAAA,MACAC;AAAA,MACAC;AAAA,MACAC;AAAA,MACAC;AAAA,MACAC;AAAA,MACAC;AAAA,MACAC;AAAA;AAAA;AAAA,EAGF,mBAA2B;AACzB,WAAO;AAAA;AAAA,QAGH,mBAAmB,QAAkC;AACzD,eAAW,aAAa,KAAK,YAAY;AACvC,YAAM,UAAU,MAAM,UAAU,MAAM;AACtC,UAAI,SAAS;AACX,eAAO;AAAA;AAAA;AAIX,WAAO;AAAA;AAAA,QAGH,kBACJ,QACA,WACA,MACiB;AACjB,UAAM,UAAUC,kCAAqB;AAMrC,oBACE,SACA,SACA,kBACA,kBACM;AACN,UAAI,CAAC,SAAS;AACZ;AAAA;AAEF,iBAAW,UAAU,CAAC,SAAS,QAAQ;AACrC,cAAM,YAAYC,4BAAe,QAAQ;AACzC,aACE,iBAAiB,SAAS;AAAA,UACxB,QAAQ;AAAA,UACR,MAAM;AAAA,UACN,QAAQ;AAAA,YACN,MAAM,UAAU;AAAA,YAChB,WAAW,UAAU;AAAA,YACrB,MAAM,UAAU;AAAA;AAAA;AAItB,aACE,iBAAiB,SAAS;AAAA,UACxB,QAAQ;AAAA,YACN,MAAM,UAAU;AAAA,YAChB,WAAW,UAAU;AAAA,YACrB,MAAM,UAAU;AAAA;AAAA,UAElB,MAAM;AAAA,UACN,QAAQ;AAAA;AAAA;AAAA;AAUhB,QAAI,OAAO,SAAS,aAAa;AAC/B,YAAM,YAAY;AAClB,aACE,UAAU,KAAK,OACf,EAAE,aAAa,SAAS,kBAAkB,QAAQ,aAClDC,gCACAC;AAEF,aACE,UAAU,KAAK,gBACf,EAAE,aAAa,aAAa,kBAAkB,QAAQ,aACtDC,+BACAC;AAEF,aACE,UAAU,KAAK,cACf,EAAE,aAAa,OAAO,kBAAkB,QAAQ,aAChDC,oCACAC;AAEF,aACE,UAAU,KAAK,cACf,EAAE,aAAa,OAAO,kBAAkB,QAAQ,aAChDC,oCACAC;AAEF,aACE,UAAU,KAAK,WACf,EAAE,kBAAkB,QAAQ,aAC5BC,kCACAC;AAEF,aACE,UAAU,KAAK,QACf,EAAE,aAAa,UAAU,kBAAkB,QAAQ,aACnDP,+BACAC;AAAA;AAQJ,QAAI,OAAO,SAAS,OAAO;AACzB,YAAM,MAAM;AACZ,aACE,IAAI,KAAK,OACT,EAAE,aAAa,SAAS,kBAAkB,QAAQ,aAClDH,gCACAC;AAEF,aACE,IAAI,KAAK,QACT,EAAE,aAAa,UAAU,kBAAkB,QAAQ,aACnDC,+BACAC;AAAA;AAQJ,QAAI,OAAO,SAAS,YAAY;AAC9B,YAAM,WAAW;AACjB,aACE,SAAS,KAAK,OACd,EAAE,aAAa,SAAS,kBAAkB,QAAQ,aAClDH,gCACAC;AAEF,aACE,SAAS,KAAK,WACd,EAAE,kBAAkB,QAAQ,aAC5BO,kCACAC;AAEF,aACE,SAAS,KAAK,cACd,EAAE,kBAAkB,QAAQ,aAC5BA,qCACAD;AAEF,aACE,SAAS,KAAK,QACd,EAAE,aAAa,UAAU,kBAAkB,QAAQ,aACnDN,+BACAC;AAAA;AAQJ,QAAI,OAAO,SAAS,QAAQ;AAC1B,YAAM,OAAO;AACb,aACE,KAAK,KAAK,UACV,EAAE,aAAa,SAAS,kBAAkB,QAAQ,aAClDO,iCACAC;AAAA;AAQJ,QAAI,OAAO,SAAS,SAAS;AAC3B,YAAM,QAAQ;AACd,aACE,MAAM,KAAK,QACX,EAAE,aAAa,SAAS,kBAAkB,QAAQ,aAClDC,gCACAC;AAEF,aACE,MAAM,KAAK,UACX,EAAE,aAAa,SAAS,kBAAkB,QAAQ,aAClDA,iCACAD;AAEF,aACE,MAAM,KAAK,SACX,EAAE,aAAa,QAAQ,kBAAkB,QAAQ,aACjDD,kCACAD;AAAA;AAQJ,QAAI,OAAO,SAAS,UAAU;AAC5B,YAAM,SAAS;AACf,aACE,OAAO,KAAK,OACZ,EAAE,aAAa,SAAS,kBAAkB,QAAQ,aAClDV,gCACAC;AAEF,aACE,OAAO,KAAK,QACZ,EAAE,aAAa,UAAU,kBAAkB,QAAQ,aACnDC,+BACAC;AAAA;AAQJ,QAAI,OAAO,SAAS,UAAU;AAC5B,YAAM,SAAS;AACf,aACE,OAAO,KAAK,OACZ,EAAE,aAAa,SAAS,kBAAkB,QAAQ,aAClDH,gCACAC;AAAA;AAIJ,WAAO;AAAA;AAAA;;AClRX,MAAM,OAAOa,eAAUC;0BAGsC;AAAA,EAC3D,mBAA2B;AACzB,WAAO;AAAA;AAAA,QAGH,aACJ,UACA,UACA,MACA,QACkB;AAClB,QAAI,SAAS,SAAS,QAAQ;AAC5B,aAAO;AAAA;AAGT,QAAI;AACF,YAAM,cAAc,MAAM,KAAK,SAAS;AAExC,UAAI,YAAY,SAAS,GAAG;AAC1B,mBAAW,aAAa,aAAa;AACnC,gBAAM,OAAO,MAAMC,uBAAG,SAAS;AAI/B,2BAAiB,eAAe,OAAO;AAAA,YACrC;AAAA,YACA,UAAU;AAAA,cACR,MAAM;AAAA,cACN,QAAQ5C,yBAAK,UAAU;AAAA;AAAA,cAEvB;AACF,iBAAK;AAAA;AAAA;AAAA,iBAGA,CAAC,UAAU;AACpB,cAAM,UAAU,GAAG,SAAS,QAAQ,SAAS;AAC7C,aAAK,iBAAiB,cAAc,UAAU;AAAA;AAAA,aAEzC,GAAP;AACA,YAAM,UAAU,GAAG,SAAS,QAAQ,SAAS,6BAA6B;AAC1E,WAAK,iBAAiB,aAAa,UAAU;AAAA;AAG/C,WAAO;AAAA;AAAA;;yBC/CT,cACA,MACA,QACQ;AACR,MAAI;AACF,QAAI,KAAK,SAAS,QAAQ;AACxB,UAAI,OAAO,WAAW,MAAM;AAC1B,eAAOA,yBAAK,KAAKA,yBAAK,QAAQ,KAAK,SAAS;AAAA;AAE9C,aAAO;AAAA;AAET,WAAO,aAAa,WAAW,EAAE,KAAK,QAAQ,MAAM,KAAK;AAAA,WAClD,GAAP;AACA,WAAO;AAAA;AAAA;8BAUsD;AAAA,EAC/D,YAA6B,SAAyC;AAAzC;AAAA;AAAA,EAE7B,mBAA2B;AACzB,WAAO;AAAA;AAAA,QAGH,kBACJ,QACA,UACA,MACiB;AACjB,QAAI,OAAO,SAAS,YAAY;AAC9B,YAAM,iBAAiB;AAEvB,YAAM,OAAO,eAAe,KAAK,QAAQ,SAAS;AAClD,UAAI,SAAS,UAAU,SAAS,OAAO,SAASA,yBAAK,MAAM;AACzD,aACE,iBAAiB,WACf,UACA,yCAAyC,kCAAkC,SAAS;AAAA;AAK1F,YAAM,UAAU,IAAI;AACpB,UAAI,eAAe,KAAK,QAAQ;AAC9B,gBAAQ,KAAK,eAAe,KAAK;AAAA;AAEnC,UAAI,eAAe,KAAK,SAAS;AAC/B,gBAAQ,KAAK,GAAG,eAAe,KAAK;AAAA;AAGtC,iBAAW,uBAAuB,SAAS;AACzC,cAAM,SAAS6C,gBACb,KAAK,QAAQ,cACb,UACA;AAEF,aAAK,iBAAiB,SAAS,EAAE,MAAM;AAAA;AAAA;AAI3C,WAAO;AAAA;AAAA;;2BCnCmD;AAAA,EAC5D,YAA6B,SAAsC;AAAtC;AAAA;AAAA,EAE7B,mBAA2B;AACzB,WAAO;AAAA;AAAA,QAGH,iBACJ,QACA,UACiB;AACjB,UAAM,UAAU,OAAO,SAAuC;AAC5D,UAAI,CAAC,QAAQ,kBAAkB,SAAS;AAEtC,eAAO,CAAC,MAAM;AAAA;AAGhB,UAAI,MAAM,QAAQ,OAAO;AAEvB,cAAM,QAAQ,MAAM,QAAQ,IAAI,KAAK,IAAI,UAAQ,QAAQ;AACzD,eAAO,MAAM,MAAM,CAAC,GAAG,aAAa,CAAC,WACjC,CAAC,MAAM,SACP,CAAC,MAAM,IAAI,CAAC,CAAC,UAAU,OAAO;AAAA;AAGpC,YAAM,OAAO,OAAO,KAAK;AACzB,UAAI,CAAC,KAAK,KAAK,OAAK,EAAE,WAAW,OAAO;AAGtC,cAAM,UAAU,MAAM,QAAQ,IAC5B,OAAO,QAAQ,MAAM,IAAI,CAAC,CAAC,GAAG,OAC5B,QAAQ,GAAG,KAAK,QAAM,CAAC,GAAG;AAG9B,eAAO,QAAQ,MAAM,CAAC,GAAG,GAAG,cAAc,CAAC,WACvC,CAAC,MAAM,SACP,CAAC,OAAO,YAAY,QAAQ,IAAI,CAAC,CAAC,GAAG,CAAC,QAAQ,CAAC,GAAG,MAAM;AAAA,iBACnD,KAAK,WAAW,GAAG;AAI5B,eAAO,CAAC,MAAM;AAAA;AAGhB,YAAM,cAAc,KAAK,GAAG,OAAO;AACnC,YAAM,gBAAgB,KAAK,KAAK;AAChC,YAAM,WAAW,KAAK,QAAQ,UAAU;AACxC,UAAI,CAAC,YAAY,OAAO,kBAAkB,UAAU;AAMlD,eAAO,CAAC,MAAM;AAAA;AAGhB,YAAM,OAAO,OAAO,QAAiC;AACnD,YAAI,KAAK,QAAQ,OAAO,SAAS;AAC/B,gBAAM,WAAW,MAAM,KAAK,QAAQ,OAAO,QAAQ;AACnD,gBAAM,SAAS,MAAM,SAAS;AAC9B,iBAAO;AAAA;AAET,eAAO,KAAK,QAAQ,OAAO,KAAK;AAAA;AAGlC,YAAM,aAAa,CAAC,KAAa,SAC/B,KAAK,QAAQ,aAAa,WAAW;AAAA,QACnC;AAAA,QACA;AAAA;AAGJ,aAAO;AAAA,QACL,MAAM,SAAS;AAAA,UACb,KAAK;AAAA,UACL,OAAO;AAAA,UACP,SAAS,SAAS;AAAA,UAClB;AAAA,UACA;AAAA;AAAA,QAEF;AAAA;AAAA;AAIJ,UAAM,CAAC,UAAU,MAAM,QAAQ;AAC/B,WAAO;AAAA;AAAA;uCAST,QACoB;AAxJtB;AAyJE,QAAM,OAAO,MAAM,iBAAiB;AAEpC,MAAI;AACJ,MAAI;AACF,gBAAYC,yBAAK,kBAAkB,MAAM,OAAO,OAAK;AAAA,WAC9C,GAAP;AACA,UAAM,IAAI,MACR,gBAAiB,OAAO,oCAAoC,OAAO,UAAU;AAAA;AAIjF,MAAI,UAAU,WAAW,GAAG;AAC1B,UAAM,IAAI,MACR,gBAAiB,OAAO,wDAAwD,OAAO,gBAAgB,UAAU;AAAA;AAIrH,QAAM,WAAW,UAAU;AAE3B,MAAI,eAAS,WAAT,mBAAiB,QAAQ;AAC3B,UAAM,IAAI,MACR,gBAAiB,OAAO,qCAAqC,OAAO,UAAU,SAAS,OAAO;AAAA;AAIlG,SAAO,SAAS;AAAA;uCAIhB,QACoB;AACpB,QAAM,OAAO,MAAM,iBAAiB;AAEpC,MAAI;AACF,WAAO,KAAK,MAAM;AAAA,WACX,GAAP;AACA,UAAM,IAAI,MACR,gBAAiB,OAAO,oCAAoC,OAAO,UAAU;AAAA;AAAA;uCAMjF,QACoB;AACpB,SAAO,MAAM,iBAAiB;AAAA;AAOhC,gCACE,QACiB;AACjB,QAAM,SAAS,YAAY;AAE3B,MAAI;AACF,UAAM,OAAO,MAAM,OAAO,KAAK;AAC/B,WAAO,KAAK,SAAS;AAAA,WACd,GAAP;AACA,UAAM,IAAI,MACR,gBAAiB,OAAO,+BAA+B,OAAO,UAAU;AAAA;AAAA;AAK9E,qBAAqB;AAAA,EACnB;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,GACoC;AACpC,MAAI,OAAO,UAAU,UAAU;AAC7B,UAAM,IAAI,MACR,gBAAiB;AAAA;AAIrB,MAAI;AACF,WAAO,WAAW,OAAO;AAAA,WAClB,GAAP;AAKA,UAAM,IAAI,MACR,gBAAiB,mCAAmC,eAAe,UAAU;AAAA;AAAA;;AC/MnF,MAAM,YAAY;yBAa0C;AAAA,EAC1D,YACmB,SAIjB;AAJiB;AAAA;AAAA,EAMnB,mBAAmB;AACjB,WAAO;AAAA;AAAA,QAGH,aACJ,UACA,UACA,MACA,QACA,OACkB;AAClB,QAAI,SAAS,SAAS,OAAO;AAC3B,aAAO;AAAA;AAGT,UAAM,YAAY,MAAM,MAAM,IAAe;AAE7C,QAAI;AACF,YAAM,EAAE,UAAU,MAAM,YAAY,MAAM,KAAK,OAC7C,SAAS,QACT,uCAAW;AAGb,YAAM,eAAyC;AAC/C,iBAAW,QAAQ,UAAU;AAC3B,yBAAiB,eAAe,OAAO;AAAA,UACrC,MAAM,KAAK;AAAA,UACX,UAAU,EAAE,MAAM,SAAS,MAAM,QAAQ,KAAK;AAAA,YAC5C;AACF,uBAAa,KAAK;AAClB,eAAK;AAAA;AAAA;AAIT,YAAM,iBAAiB,aAAa,MAAM,OAAK,EAAE,SAAS;AAC1D,UAAI,WAAW,gBAAgB;AAC7B,cAAM,MAAM,IAAe,WAAW;AAAA,UACpC,MAAM;AAAA,UACN,OAAO;AAAA;AAAA;AAAA,aAGJ,OAAP;AACA,yBAAY;AACZ,YAAM,UAAU,kBAAkB,SAAS,SAAS;AACpD,UAAI,MAAM,SAAS,sBAAsB,WAAW;AAClD,mBAAW,eAAe,UAAU,OAAO;AACzC,eAAK;AAAA;AAAA,iBAEE,MAAM,SAAS,iBAAiB;AACzC,YAAI,CAAC,UAAU;AACb,eAAK,iBAAiB,cAAc,UAAU;AAAA;AAAA,aAE3C;AACL,aAAK,iBAAiB,aAAa,UAAU;AAAA;AAAA;AAIjD,WAAO;AAAA;AAAA,QAGK,OACZ,UACA,MACuE;AAGvE,UAAM,EAAE,aAAa7B,gCAAY;AACjC,QAAI,qCAAU,MAAM,SAAS;AAC3B,YAAM,UAAU8B,mCAAe;AAC/B,YAAM,WAAW,MAAM,KAAK,QAAQ,OAAO,OAAO,UAAU,EAAE;AAC9D,YAAM,SAAS,SAAS,MAAM,IAAI,OAAM;AAAS,QAC/C,KAAK,KAAK;AAAA,QACV,MAAM,MAAM,QAAQ,KAAK;AAAA;AAE3B,aAAO,EAAE,UAAU,MAAM,QAAQ,IAAI,SAAS,MAAM,SAAS;AAAA;AAI/D,QAAI,KAAK,QAAQ,OAAO,SAAS;AAC/B,YAAM,QAAO,MAAM,KAAK,QAAQ,OAAO,QAAQ,UAAU,EAAE;AAC3D,aAAO;AAAA,QACL,UAAU,CAAC,EAAE,KAAK,UAAU,MAAM,MAAM,MAAK;AAAA,QAC7C,MAAM,MAAK;AAAA;AAAA;AAIf,UAAM,OAAO,MAAM,KAAK,QAAQ,OAAO,KAAK;AAC5C,WAAO,EAAE,UAAU,CAAC,EAAE,KAAK,UAAU;AAAA;AAAA;;0BCjHvC,MACA,UACkC;AA9BpC;AA+BE,MAAI;AACJ,MAAI;AACF,gBAAYD,yBAAK,kBAAkB,KAAK,SAAS,SAAS,OAAO,OAAK;AAAA,WAC/D,GAAP;AACA,UAAM,MAAMtC,kCAAqB;AACjC,UAAM,UAAU,2BAA2B,QAAQ;AACnD,UAAM,iBAAiB,aAAa,UAAU;AAC9C;AAAA;AAGF,aAAW,YAAY,WAAW;AAChC,QAAI,eAAS,WAAT,mBAAiB,QAAQ;AAC3B,YAAM,MAAMA,kCAAqB;AACjC,YAAM,UAAU,iBAAiB,QAAQ,SAAS,OAAO;AACzD,YAAM,iBAAiB,aAAa,UAAU;AAAA,WACzC;AACL,YAAM,OAAO,SAAS;AACtB,UAAIwC,2BAAO,cAAc,OAAO;AAC9B,cAAM,iBAAiB,OAAO,UAAU;AAAA,iBAC/B,SAAS,MAAM,OAGnB;AACL,cAAM,UAAU,gCAAgC,OAAO;AACvD,cAAM,iBAAiB,aAAa,UAAU;AAAA;AAAA;AAAA;AAAA;MAMzC,0BACX,yCAAwC,EAAE,MAAM,YAAY;AAC1D,aAAW,KAAK,gBAAgB,MAAM,WAAW;AAC/C,UAAM;AAAA;AAAA;;oCCfkE;AAAA,EAiBpE,YAAY,SAA+C;AAhBnD,gBAAe;AACf,gCAAuBC;AAgBrC,UAAM;AAAA,MACJ;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,qBACAC;AAAA,MACA;AAAA,QACE;AAEJ,SAAK,mBACH,oBAAoB;AACtB,SAAK,SAAS;AACd,SAAK,YAAY,aAAa;AAC9B,SAAK,gBACHA,mBAAiB,IAAIC,4BAAc,EAAE,cAAc;AACrD,SAAK,eAAe;AAAA;AAAA,SAvBf,WACL,SACA,SACA;AACA,WAAO,IAAI,8BAA8B;AAAA;AAAA,QAsBrC,cAAiC;AACrC,WAAOC,gBAAS,KAAK,KAAK;AAAA;AAAA,EAGpB,kBACN,QACA,MACQ;AACR,QAAI,YAAY;AAChB,eAAW,CAAC,KAAK,UAAU,OAAO,QAAQ,OAAO;AAC/C,kBAAY,UAAU,QAAQ,IAAI,OAAO;AAAA;AAE3C,WAAO,UAAU;AAAA;AAAA,EAGX,aAAa,QAAsC;AACzD,WAAO,OAAO,KAAK,kBAAkB,aAAa;AAAA;AAAA,EAG5C,gBAAgB,QAAwB;AAxGlD;AAyGI,QAAI,eAAe,OAAO,SAAS,eAAe;AAClD,QAAI,KAAK,aAAa,SAAS;AAC7B,UAAI,oBAAO,SAAP,mBAAa,YAAb,mBAAsB,gBAAe,cAAc;AAErD,cAAM,cAAc,mBAAO,SAAP,mBAAa,YAAb,mBAAsB;AAC1C,uBAAe,YAAY,OAAO,OAAO;AAAA,aACpC;AACL,uBAAe,oBAAO,SAAP,mBAAa,YAAb,mBAAsB,gBAAe;AAAA;AAAA;AAGxD,WAAO;AAAA;AAAA,SAGM,UAAiD;AAtHlE;AAuHI,UAAM,EAAE,UAAU,MAAM,KAAK,aAAa;AAC1C,QAAI,oBAAoB;AACxB,QAAI,oBAAoB;AAKxB,WAAO,mBAAmB;AACxB,YAAM,WACJ,OAAM,KAAK,cAAc,YACvB;AAAA,QACE,QAAQ,KAAK;AAAA,QACb,OAAO,KAAK;AAAA,QACZ,QAAQ;AAAA,SAEV,EAAE,UAEJ;AAGF,0BAAoB,SAAS,WAAW,KAAK;AAC7C,2BAAqB,SAAS;AAE9B,iBAAW,UAAU,UAAU;AAC7B,cAAM;AAAA,UACJ,OAAO,aAAO,SAAS,UAAhB,YAAyB,OAAO,SAAS;AAAA,UAChD,UAAU,KAAK,kBAAkB,KAAK,kBAAkB;AAAA,YACtD,WAAW,OAAO,SAAS,aAAa;AAAA,YACxC,MAAM,OAAO;AAAA,YACb,MAAM,OAAO,SAAS;AAAA;AAAA,UAExB,MAAM,KAAK,gBAAgB;AAAA,UAC3B,eAAe,oBAAO,SAAP,mBAAa,SAAb,mBAAmB,eAAc;AAAA,UAChD,MAAM,oBAAO,SAAP,mBAAa,SAAb,mBAAmB,eAAc;AAAA,UACvC,WAAW,OAAO,SAAS,aAAa;AAAA,UACxC,MAAM,OAAO;AAAA,UACb,WAAY,cAAO,SAAP,mBAAa,cAAwB;AAAA,UACjD,OAAQ,cAAO,SAAP,mBAAa,UAAoB;AAAA,UACzC,eAAe;AAAA,YACb,aAAaC,gCAAmB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;6BCrHR;AAAA,EAsBlC,YAAY,SAMT;AAvBa,gBAAe;AACf,gCAAuBJ;AAuBrC,UAAM,EAAE,WAAW,kBAAkB,uBAAQC,iBAAe,iBAC1D;AAEF,SAAK,YAAY;AACjB,SAAK,mBACH,oBAAoB;AACtB,SAAK,SAAS;AACd,SAAK,gBACHA,mBAAiB,IAAIC,4BAAc,EAAE,cAAc;AACrD,SAAK,eAAe;AAAA;AAAA,SA7Bf,WACL,SACA,SAKA;AACA,WAAO,IAAI,uBAAuB;AAAA,SAC7B;AAAA;AAAA;AAAA,EAuBG,kBACR,QACA,MACQ;AACR,QAAI,YAAY;AAChB,eAAW,CAAC,KAAK,UAAU,OAAO,QAAQ,OAAO;AAC/C,kBAAY,UAAU,QAAQ,IAAI,OAAO;AAAA;AAE3C,WAAO,UAAU;AAAA;AAAA,EAGX,aAAa,QAAsC;AACzD,WAAO,OAAO,KAAK,kBAAkB,aAAa;AAAA;AAAA,EAG5C,gBAAgB,QAAwB;AAjGlD;AAkGI,QAAI,eAAe,OAAO,SAAS,eAAe;AAClD,QAAI,KAAK,aAAa,SAAS;AAC7B,UAAI,oBAAO,SAAP,mBAAa,YAAb,mBAAsB,gBAAe,cAAc;AAErD,cAAM,cAAc,mBAAO,SAAP,mBAAa,YAAb,mBAAsB;AAC1C,uBAAe,YAAY,OAAO,OAAO;AAAA,aACpC;AACL,uBAAe,oBAAO,SAAP,mBAAa,YAAb,mBAAsB,gBAAe;AAAA;AAAA;AAGxD,WAAO;AAAA;AAAA,QAGH,UAAU;AACd,UAAM,EAAE,UAAU,MAAM,KAAK,aAAa;AAC1C,UAAM,WAAW,MAAM,KAAK,cAAc,YACxC;AAAA,MACE,QAAQ,KAAK;AAAA,OAEf,EAAE;AAEJ,WAAO,SAAS,MAAM,IAAI,CAAC,WAA0C;AAvHzE;AAwHM,aAAO;AAAA,QACL,OAAO,aAAO,SAAS,UAAhB,YAAyB,OAAO,SAAS;AAAA,QAChD,UAAU,KAAK,kBAAkB,KAAK,kBAAkB;AAAA,UACtD,WAAW,OAAO,SAAS,aAAa;AAAA,UACxC,MAAM,OAAO;AAAA,UACb,MAAM,OAAO,SAAS;AAAA;AAAA,QAExB,MAAM,KAAK,gBAAgB;AAAA,QAC3B,eAAe,oBAAO,SAAP,mBAAa,SAAb,mBAAmB,eAAc;AAAA,QAChD,MAAM,oBAAO,SAAP,mBAAa,SAAb,mBAAmB,eAAc;AAAA,QACvC,WAAW,OAAO,SAAS,aAAa;AAAA,QACxC,MAAM,OAAO;AAAA,QACb,WAAY,cAAO,SAAP,mBAAa,cAAwB;AAAA,QACjD,OAAQ,cAAO,SAAP,mBAAa,UAAoB;AAAA,QACzC,eAAe;AAAA,UACb,aAAaE,gCAAmB;AAAA;AAAA;AAAA;AAAA;AAAA;;oCC5GC,UAAwB;AACjE,QAAM,OAAOC,kBAAW,QACrB,OAAO,GAAG,SAAS,QAAQ,SAAS,UACpC,OAAO;AACV,SAAO,aAAa;AAAA;sCAIpB,UACA,cACwB;AArC1B;AAsCE,MAAI;AACJ,MAAI;AACJ,MAAI,cAAc;AAChB,UAAM,mBACJ,mBAAa,SAAS,gBAAtB,mBAAoC3C;AACtC,QAAI,CAAC,kBAAkB;AACrB,YAAM,IAAI,MACR,kBAAkB0C,gCAChB,+BACiB7C,kCACjB;AAAA;AAIN,kBAAc;AACd,UAAM,sBACJ,mBAAa,SAAS,gBAAtB,mBAAoCI;AACtC,QAAI,CAAC,qBAAqB;AACxB,YAAM,IAAI,MACR,kBAAkByC,gCAChB,+BACiB7C,kCACjB;AAAA;AAIN,qBAAiB;AAAA,SACZ;AACL,kBAAcA,kCAAqB;AACnC,qBAAiB;AAAA;AAGnB,QAAM,SAAiC;AAAA,IACrC,YAAY;AAAA,IACZ,MAAM;AAAA,IACN,UAAU;AAAA,MACR,MAAM,2BAA2B;AAAA,MACjC,aAAa;AAAA,SACVG,mCAAsB;AAAA,SACtBC,0CAA6B;AAAA;AAAA;AAAA,IAGlC,MAAM;AAAA,MACJ,MAAM,SAAS;AAAA,MACf,QAAQ,SAAS;AAAA,MACjB,UAAU,SAAS;AAAA;AAAA;AAIvB,SAAO;AAAA;;0BCxDwB,QAA0C;AACzE,SAAO,OAAO,SAAS;AAAA;8BAGY,QAAwB;AAnC7D;AAoCE,QAAM,MAAM,aAAO,SAAS,gBAAhB,mBAA8BD;AAC1C,MAAI,CAAC,KAAK;AACR,UAAM,YAAY0C,gCAAmB;AACrC,UAAM,IAAItD,kBACR,WAAW,2CAA2CY;AAAA;AAG1D,SAAO;AAAA;oCAGkC,QAAwB;AA9CnE;AA+CE,QAAM,MAAM,aAAO,SAAS,gBAAhB,mBAA8BC;AAC1C,MAAI,CAAC,KAAK;AACR,UAAM,YAAYyC,gCAAmB;AACrC,UAAM,IAAItD,kBACR,WAAW,2CAA2Ca;AAAA;AAG1D,SAAO;AAAA;uBAIP,cACA,MACA,MACA,QACQ;AACR,MAAI,KAAK,SAAS,MAAM;AACtB,WAAO;AAAA;AAET,MAAI;AACF,QAAI,SAAS,QAAQ;AACnB,UAAI,OAAO,WAAW,MAAM;AAC1B,eAAOZ,yBAAK,KAAKA,yBAAK,QAAQ,KAAK,SAAS;AAAA;AAE9C,aAAO;AAAA,eACE,SAAS,OAAO;AACzB,aAAO,aAAa,WAAW,EAAE,KAAK,QAAQ,MAAM,KAAK;AAAA;AAE3D,WAAO;AAAA,WACA,GAAP;AACA,WAAO;AAAA;AAAA;kBAIc,OAAmD;AAC1E,SAAO,OAAO,UAAU,YAAY,UAAU,QAAQ,CAAC,MAAM,QAAQ;AAAA;MAG1D,iBAAiBuD;MAEjB,yBAAyBC;;+BCnDA;AAAA,EAMpC,YACmB,QACA,cACjB;AAFiB;AACA;AAPF,kBAAS,IAAI;AACb,qBAAY,IAAI;AAChB,4BAAmB,IAAI;AAChC,gBAAO;AAAA;AAAA,MAOX,SAA8C;AAChD,WAAO,OAAK,KAAK,QAAQ;AAAA;AAAA,EAG3B,UAAU;AACR,SAAK,OAAO;AACZ,WAAO;AAAA,MACL,QAAQ,KAAK;AAAA,MACb,WAAW,KAAK;AAAA,MAChB,kBAAkB,KAAK;AAAA;AAAA;AAAA,EAInB,QAAQ,GAA2B;AACzC,QAAI,KAAK,MAAM;AACb,WAAK,OAAO,KACV,iBACE,EAAE,kEAEF,IAAI,QAAQ;AAGhB;AAAA;AAGF,QAAI,EAAE,SAAS,UAAU;AACvB,UAAI;AACJ,YAAM,WAAWhD,kCAAqB,EAAE;AAExC,UAAI;AACF,iBAAS,uBAAuB,EAAE;AAAA,eAC3B,GAAP;AACA,2BAAY;AACZ,aAAK,OAAO,MAAM,iCAAiC,aAAa;AAChE,aAAK,OAAO,KAAK;AACjB;AAAA;AAQF,YAAM,cAAc,OAAO,SAAS,eAAe;AACnD,UAAI,OAAO,gBAAgB,YAAY,CAAC,MAAM,QAAQ,cAAc;AAClE,cAAM,iBAAiB,2BAA2B,KAAK;AACvD,iBAAS;AAAA,aACJ;AAAA,UACH,UAAU;AAAA,eACL,OAAO;AAAA,YACV,aAAa;AAAA,iBACR;AAAA,eACFI,0CAA6B;AAAA,eAC7BD,mCAAsB;AAAA;AAAA;AAAA;AAAA;AAM/B,WAAK,iBAAiB,KAAK,EAAE,QAAQ,aAAa;AAAA,eACzC,EAAE,SAAS,YAAY;AAChC,YAAM,SAAS,6BACb,EAAE,UACF,KAAK;AAEP,YAAM,cAAc,qBAAqB;AACzC,WAAK,iBAAiB,KAAK,EAAE,QAAQ;AAAA,eAC5B,EAAE,SAAS,YAAY;AAChC,WAAK,UAAU,KAAK,EAAE;AAAA,eACb,EAAE,SAAS,SAAS;AAC7B,WAAK,OAAO,KAAK,EAAE;AAAA;AAAA;AAAA;;ACjGzB,8BAA+D;AAAA,EAG7D,YAA6B,eAA4B;AAA5B;AAAA;AAAA,QAEvB,IACJ,KAC+B;AA3BnC;AA4BI,WAAO,WAAK,kBAAL,mBAAqB;AAAA;AAAA,QAGxB,IACJ,KACA,OACe;AACf,QAAI,CAAC,KAAK,UAAU;AAClB,WAAK,WAAW;AAAA;AAGlB,SAAK,SAAS,OAAO;AAAA;AAAA,EAGvB,UAAkC;AA1CpC;AA2CI,WAAO,WAAK,aAAL,YAAiB,KAAK;AAAA;AAAA;AAIjC,2BAA4D;AAAA,EAI1D,YAA6B,eAA4B;AAA5B;AAFrB,yCAAsD;AAAA;AAAA,QAIxD,IACJ,KAC+B;AAvDnC;AAwDI,WAAO,WAAK,kBAAL,mBAAqB;AAAA;AAAA,QAGxB,IACJ,KACA,OACe;AACf,QAAI,CAAC,KAAK,UAAU;AAClB,WAAK,WAAW;AAAA;AAGlB,SAAK,SAAS,OAAO;AAAA;AAAA,EAGvB,QAAQ,KAAa;AAtEvB;AAuEI,UAAM,mBAAmB,KAAK,UAAU,IAAI;AAC5C,QAAI,kBAAkB;AACpB,aAAO;AAAA;AAET,UAAM,WAAW,WAAK,kBAAL,mBAAqB;AACtC,UAAM,WAAW,IAAI,wBACnB,SAAS,YAAY,WAAW;AAElC,SAAK,UAAU,IAAI,KAAK;AACxB,WAAO;AAAA;AAAA,EAGT,UAAkC;AAnFpC;AAoFI,QAAI,MAAM,WAAK,aAAL,YAAiB,KAAK;AAChC,eAAW,CAAC,KAAK,aAAa,KAAK,WAAW;AAC5C,YAAM,gBAAgB,SAAS;AAC/B,UAAI,eAAe;AACjB,cAAM,KAAK,MAAM,MAAM;AAAA;AAAA;AAG3B,WAAO;AAAA;AAAA;4BAIwB;AAAA,EAGjC,YAA6B,eAA2B;AAA3B;AAFrB,sCAAa;AAAA;AAAA,EAIrB,aACE,WACA,KACuB;AAEvB,UAAM,OAAO,UAAU;AACvB,UAAM,QAAQ,KAAK,OAAO,IAAI;AAC9B,QAAI,OAAO;AACT,aAAO,MAAM,MAAM,QAAQ,OAAO;AAAA;AAGpC,UAAM,WAAW,KAAK,cAAc;AAEpC,UAAM,WAAW,IAAI,qBACnB,SAAS,YAAY,WAAW;AAElC,SAAK,OAAO,IAAI,MAAM;AACtB,WAAO,MAAM,SAAS,QAAQ,OAAO;AAAA;AAAA,EAGvC,UAAsB;AACpB,UAAM,SAAqB;AAC3B,eAAW,CAAC,KAAK,UAAU,KAAK,OAAO,WAAW;AAChD,aAAO,OAAO,MAAM;AAAA;AAGtB,WAAO;AAAA;AAAA;;2CCzDX;AAAA,EACE,YACmB,SAQjB;AARiB;AAAA;AAAA,QAUb,QACJ,SACiC;AACjC,WAAO,KAAK,oBAAoB,QAAQ,QAAQ,QAAQ;AAAA;AAAA,QAG5C,oBACZ,mBACA,OACiC;AACjC,UAAM,YAAY,IAAI,yBACpB,KAAK,QAAQ,QACb;AAIF,UAAM,QAAQ,IAAI,sBAChB,SAAS,UAAU,SAAS,MAAM,SAAS,MAAM,QAAQ;AAG3D,QAAI;AAEF,UAAI,SAAiB;AAMrB,UAAI;AACF,+BAAuB;AAAA,eAChB,GAAP;AACA,cAAM,IAAIZ,kBACR,uDACA;AAAA;AAMJ,YAAM,UAAmB;AAAA,QACvB,WAAWsD,gCAAmB;AAAA,QAC9B,UAAUI,8BAAiB,qBAAqB;AAAA,QAChD,gBAAgBA,8BAAiB,2BAA2B;AAAA,QAC5D;AAAA,QACA;AAAA;AAIF,eAAS,MAAM,KAAK,kBAAkB,QAAQ;AAC9C,eAAS,MAAM,KAAK,cAAc;AAClC,YAAM,KAAK,gBAAgB,QAAQ;AACnC,UAAI,iBAAiB,SAAS;AAC5B,cAAM,KAAK,uBAAuB,QAAQ;AAAA;AAE5C,eAAS,MAAM,KAAK,mBAAmB,QAAQ;AAI/C,YAAM,mBAAmB,QAAQ,UAAU;AAC3C,iBAAW,kBAAkB,iBAAiB,kBAAkB;AAC9D,YACE,CAAC,KAAK,QAAQ,cAAc,UAC1B,eAAe,QACf,QAAQ,iBAEV;AACA,gBAAM,IAAIC,uBACR,UAAUL,gCACR,eAAe,cACT7C,kCACN,QAAQ,4BACUA,kCAClB,QAAQ;AAAA;AAAA;AAMhB,aAAO;AAAA,WACF;AAAA,QACH,iBAAiB;AAAA,QACjB,OAAO,EAAE,OAAO,MAAM;AAAA,QACtB,IAAI,iBAAiB,OAAO,WAAW;AAAA;AAAA,aAElC,OAAP;AACA,yBAAY;AACZ,aAAO;AAAA,QACL,IAAI;AAAA,QACJ,QAAQ,UAAU,UAAU,OAAO,OAAO;AAAA;AAAA;AAAA;AAAA,QAOlC,kBACZ,QACA,SACiB;AACjB,QAAI,MAAM;AAEV,eAAW,aAAa,KAAK,QAAQ,YAAY;AAC/C,UAAI,UAAU,kBAAkB;AAC9B,YAAI;AACF,gBAAM,MAAM,UAAU,iBACpB,KACA,QAAQ,UACR,QAAQ,UAAU,QAClB,QAAQ,gBACR,QAAQ,MAAM,aAAa;AAAA,iBAEtB,GAAP;AACA,gBAAM,IAAIT,kBACR,aAAa,UAAU,YAAY,2CACnC;AAAA;AAAA;AAAA;AAMR,WAAO;AAAA;AAAA,QAMK,cAAc,QAAiC;AAC3D,QAAI;AAEJ,QAAI;AACF,6BAAuB,MAAM,KAAK,QAAQ,OAAO,QAAQ;AAAA,aAClD,GAAP;AACA,YAAM,IAAIA,kBAAW,uBAAuB;AAAA;AAG9C,QAAI,CAAC,sBAAsB;AACzB,YAAM,IAAI,MAAM;AAAA;AAGlB,WAAO;AAAA;AAAA,QAMK,gBACZ,QACA,SACe;AAGf,QAAIsD,gCAAmB,YAAY,QAAQ,WAAW;AACpD,YAAM,IAAIM,qBACR;AAAA;AAKJ,QAAI;AACF,qBAAe;AAAA,aACR,GAAP;AACA,YAAM,IAAIA,qBACR,yDACA;AAAA;AAIJ,QAAI,YAAY;AAEhB,eAAW,aAAa,KAAK,QAAQ,YAAY;AAC/C,UAAI,UAAU,oBAAoB;AAChC,YAAI;AACF,sBAAY,MAAM,UAAU,mBAAmB;AAC/C,cAAI,WAAW;AAMb;AAAA;AAAA,iBAEK,GAAP;AACA,gBAAM,IAAI5D,kBACR,aAAa,UAAU,YAAY,mDACnC;AAAA;AAAA;AAAA;AAMR,QAAI,CAAC,WAAW;AACd,YAAM,IAAIA,kBACR;AAAA;AAAA;AAAA,QAQQ,uBACZ,QACA,SACe;AACf,UAAM,EAAE,OAAO,QAAQ,SAAS,MAAM,WAAW,eAAe,OAAO;AACvE,UAAM,UAAU,IAAI;AACpB,QAAI,OAAO,KAAK,QAAQ;AACtB,cAAQ,KAAK,OAAO,KAAK;AAAA;AAE3B,QAAI,OAAO,KAAK,SAAS;AACvB,cAAQ,KAAK,GAAG,OAAO,KAAK;AAAA;AAG9B,eAAW,uBAAuB,SAAS;AACzC,UAAI,SAAS,UAAU,oBAAoB,SAASC,yBAAK,MAAM;AAC7D,gBAAQ,UAAU,OAChB,iBAAiB,WACf,QAAQ,UACR,yCAAyC,kCAAkC,QAAQ,SAAS;AAGhG;AAAA;AAEF,YAAM,SAAS,cACb,KAAK,QAAQ,cACb,QAAQ,UACR,MACA;AAGF,UAAI,UAAU;AACd,iBAAW,aAAa,KAAK,QAAQ,YAAY;AAC/C,YAAI,UAAU,cAAc;AAC1B,cAAI;AACF,kBAAM,OAAO,MAAM,UAAU,aAC3B;AAAA,cACE;AAAA,cACA;AAAA,cACA;AAAA,eAEF,aAAa,YACb,QAAQ,UAAU,QAClB,KAAK,QAAQ,QACb,QAAQ,MAAM,aAAa,WAAW;AAExC,gBAAI,MAAM;AACR,wBAAU;AACV;AAAA;AAAA,mBAEK,GAAP;AACA,kBAAM,IAAID,kBACR,aAAa,UAAU,YAAY,qCAAqC,QAAQ,UAChF;AAAA;AAAA;AAAA;AAKR,UAAI,CAAC,SAAS;AACZ,cAAM,IAAIA,kBACR,8CAA8C,QAAQ;AAAA;AAAA;AAAA;AAAA,QAShD,mBACZ,QACA,SACiB;AACjB,QAAI,MAAM;AAEV,eAAW,aAAa,KAAK,QAAQ,YAAY;AAC/C,UAAI,UAAU,mBAAmB;AAC/B,YAAI;AACF,gBAAM,MAAM,UAAU,kBACpB,KACA,QAAQ,UACR,QAAQ,UAAU,QAClB,QAAQ,MAAM,aAAa;AAAA,iBAEtB,GAAP;AACA,gBAAM,IAAIA,kBACR,aAAa,UAAU,YAAY,4CACnC;AAAA;AAAA;AAAA;AAMR,WAAO;AAAA;AAAA;;qCClViC,SAGhB;AAC1B,QAAM,EAAE,YAAY,eAAe;AACnC,SAAO,MAAM;AACX,WAAO,KAAK,yBAAyB,cAAc;AAAA;AAAA;wCASR,SAGhB;AAC7B,QAAM,EAAE,YAAY,eAAe;AACnC,SAAO,MAAM;AACX,WAAO,KAAK,yBAAyB,cAAc;AAAA;AAAA;;2BClCrD,OACc;AACd,QAAM,eAAqD;AAE3D,aAAW,CAAC,KAAK,UAAU,OAAO,QAAQ,QAAQ;AAChD,UAAM,SAAS,CAAC,OAAO;AAEvB,UAAM,IACJ,OAAO,eACH,aAAa,OACZ,aAAa,OAAO,EAAE,KAAK,QAAQ;AAE1C,MAAE,OAAQ,KAAK,GAAG;AAAA;AAGpB,SAAO,EAAE,OAAO,CAAC,EAAE,OAAO,OAAO,OAAO;AAAA;;2BCdxC,OACA,KACoB;AACpB,MAAI,UAAU,QAAW;AACvB,WAAO;AAAA;AAGT,MAAI,OAAO,UAAU,UAAU;AAC7B,UAAM,IAAIA,kBAAW,WAAW;AAAA;AAGlC,QAAM,SAAS,SAAS,OAAO;AAC/B,MAAI,CAAC,OAAO,UAAU,WAAW,OAAO,YAAY,OAAO;AACzD,UAAM,IAAIA,kBAAW,WAAW;AAAA;AAGlC,SAAO;AAAA;0BAOP,OACA,KACoB;AACpB,MAAI,UAAU,QAAW;AACvB,WAAO;AAAA;AAGT,MAAI,OAAO,UAAU,UAAU;AAC7B,UAAM,IAAIA,kBAAW,WAAW;AAAA;AAGlC,SAAO;AAAA;2BAQP,OACA,KACsB;AACtB,MAAI,UAAU,QAAW;AACvB,WAAO;AAAA;AAGT,QAAM,QAAQ,CAAC,OAAO;AACtB,MAAI,MAAM,KAAK,OAAK,OAAO,MAAM,WAAW;AAC1C,UAAM,IAAIA,kBAAW,WAAW;AAAA;AAGlC,SAAO;AAAA;;iCCpDP,QAC0B;AAE1B,QAAM,gBAAgB,kBAAkB,OAAO,QAAQ;AACvD,MAAI,CAAC,eAAe;AAClB,WAAO;AAAA;AAKT,QAAM,UAAU,cAAc,IAAI,yBAAyB,OAAO;AAClE,MAAI,CAAC,QAAQ,QAAQ;AACnB,WAAO;AAAA;AAGT,SAAO,EAAE,OAAO,QAAQ,IAAI,UAAQ,OAAO;AAAA;iCAQ3C,cACoC;AACpC,QAAM,aAAa,aAChB,MAAM,KACN,IAAI,OAAK,EAAE,QACX,OAAO;AAEV,MAAI,CAAC,WAAW,QAAQ;AACtB,WAAO;AAAA;AAGT,QAAM,eAAqD;AAE3D,aAAW,aAAa,YAAY;AAClC,UAAM,cAAc,UAAU,QAAQ;AAEtC,UAAM,MACJ,gBAAgB,KAAK,YAAY,UAAU,OAAO,GAAG,aAAa;AACpE,UAAM,QACJ,gBAAgB,KAAK,SAAY,UAAU,OAAO,cAAc,GAAG;AACrE,QAAI,CAAC,KAAK;AACR,YAAM,IAAIA,kBACR,oBAAoB;AAAA;AAIxB,UAAM,IACJ,OAAO,eAAe,aAAa,OAAQ,aAAa,OAAO,EAAE;AAEnE,QAAI,UAAU,QAAW;AACvB,QAAE,SAAS,EAAE,UAAU;AACvB,QAAE,OAAO,KAAK;AAAA;AAAA;AAIlB,SAAO,OAAO,OAAO;AAAA;;qCC1DrB,QAC8B;AAC9B,QAAM,SAAS,kBAAkB,OAAO,QAAQ;AAChD,QAAM,QAAQ,kBAAkB,OAAO,OAAO;AAC9C,QAAM,QAAQ,iBAAiB,OAAO,OAAO;AAE7C,MAAI,WAAW,UAAa,UAAU,UAAa,UAAU,QAAW;AACtE,WAAO;AAAA;AAGT,MAAI,WAAW,UAAa,SAAS,GAAG;AACtC,UAAM,IAAIA,kBAAW;AAAA;AAEvB,MAAI,UAAU,UAAa,SAAS,GAAG;AACrC,UAAM,IAAIA,kBAAW;AAAA;AAEvB,MAAI,UAAU,UAAa,CAAC,OAAO;AACjC,UAAM,IAAIA,kBAAW;AAAA;AAGvB,SAAO;AAAA,OACD,WAAW,SAAY,EAAE,WAAW;AAAA,OACpC,UAAU,SAAY,EAAE,UAAU;AAAA,OAClC,UAAU,SAAY,EAAE,UAAU;AAAA;AAAA;;oCCzBxC,QAC0C;AAC1C,QAAM,gBAAgB,kBAAkB,OAAO,QAAQ;AACvD,MAAI,CAAC,eAAe;AAClB,WAAO;AAAA;AAGT,QAAM,SAAS,cACZ,IAAI,OAAK,EAAE,MAAM,MACjB,OACA,IAAI,OAAK,EAAE,QACX,OAAO;AAEV,MAAI,CAAC,OAAO,QAAQ;AAClB,WAAO;AAAA;AAGT,MAAI,OAAO,KAAK,OAAK,EAAE,SAAS,OAAO;AACrC,UAAM,IAAIA,kBAAW;AAAA;AAGvB,SAAO,WAAS;AACd,UAAM,SAAmC;AAEzC,eAAW,SAAS,QAAQ;AAC1B,YAAM,QAAQiD,2BAAO,IAAI,OAAO;AAChC,UAAI,UAAU,QAAW;AACvB,mCAAO,IAAI,QAAQ,OAAO;AAAA;AAAA;AAI9B,WAAO;AAAA;AAAA;;kCCjC8B,KAAgC;AACvE,QAAM,cAAc,IAAI,OAAO;AAC/B,MAAI,CAAC,aAAa;AAChB,UAAM,IAAIjD,kBAAW;AAAA,aACZ,CAAC,YAAY,MAAM,4BAA4B;AACxD,UAAM,IAAIA,kBAAW;AAAA;AAGvB,QAAM,OAAO,IAAI;AACjB,MAAI,CAAC,MAAM;AACT,UAAM,IAAIA,kBAAW;AAAA,aACZ,CAACiD,2BAAO,cAAc,OAAO;AACtC,UAAM,IAAIjD,kBAAW;AAAA,aACZ,OAAO,KAAK,MAAM,WAAW,GAAG;AAEzC,UAAM,IAAIA,kBAAW;AAAA;AAGvB,SAAO;AAAA;MAGI,gBAAgB6D,MAC1B,OAAO;AAAA,EACN,MAAMA,MAAE;AAAA,EACR,QAAQA,MAAE;AAAA,EACV,UAAUA,MAAE,QAAQ,YAAY,GAAGA,MAAE,QAAQ,aAAa;AAAA,GAE3D;mCAGD,KACA,QACY;AACZ,QAAM,OAAO,MAAM,mBAAmB;AACtC,MAAI;AACF,WAAO,MAAM,OAAO,MAAM;AAAA,WACnB,GAAP;AACA,UAAM,IAAI7D,kBAAW,sBAAsB;AAAA;AAAA;8BAIV,UAAmB;AACtD,MAAI,UAAU;AACZ,UAAM,IAAI2D,uBAAgB;AAAA;AAAA;;gCCxC5B,QACU;AAEV,QAAM,eAAe,kBAAkB,OAAO,OAAO;AACrD,MAAI,cAAc;AAChB,UAAM,WAAW,aAAa,OAAO;AACrC,QAAI,SAAS,QAAQ;AACnB,aAAO;AAAA;AAAA;AAIX,QAAM,IAAI3D,kBAAW;AAAA;;4BC2BrB,SACyB;AACzB,QAAM;AAAA,IACJ;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,MACE;AAEJ,QAAM,SAAS8D;AACf,SAAO,IAAIC,4BAAQ;AAEnB,QAAM,kBACJ,OAAO,mBAAmB,uBAAuB;AACnD,MAAI,iBAAiB;AACnB,WAAO,KAAK;AAAA;AAGd,MAAI,gBAAgB;AAClB,WAAO,KAAK,YAAY,OAAO,KAAK,QAAQ;AAC1C,YAAM,iBAAiC,IAAI;AAC3C,qBAAe,qBAAqB,eAClC,IAAI,OAAO;AAGb,YAAM,eAAe,QAAQ;AAC7B,UAAI,OAAO,KAAK;AAAA;AAAA;AAIpB,MAAI,6BAA6B;AAC/B,WAAO,IAAI;AAAA;AAGb,MAAI,iBAAiB;AACnB,WACG,IAAI,aAAa,OAAO,KAAK,QAAQ;AACpC,YAAM,EAAE,UAAU,aAAa,MAAM,gBAAgB,SAAS;AAAA,QAC5D,QAAQ,wBAAwB,IAAI;AAAA,QACpC,QAAQ,2BAA2B,IAAI;AAAA,QACvC,YAAY,4BAA4B,IAAI;AAAA,QAC5C,oBAAoB,eAAe,IAAI,OAAO;AAAA;AAIhD,UAAI,SAAS,aAAa;AACxB,cAAM,MAAM,IAAI,IAAI,iBAAiB,IAAI;AACzC,YAAI,aAAa,OAAO;AACxB,YAAI,aAAa,IAAI,SAAS,SAAS;AACvC,YAAI,UAAU,QAAQ,IAAI,IAAI,WAAW,IAAI;AAAA;AAI/C,UAAI,KAAK;AAAA,OAEV,IAAI,yBAAyB,OAAO,KAAK,QAAQ;AAChD,YAAM,EAAE,QAAQ,IAAI;AACpB,YAAM,EAAE,aAAa,MAAM,gBAAgB,SAAS;AAAA,QAClD,QAAQ,kBAAkB,EAAE,gBAAgB;AAAA,QAC5C,oBAAoB,eAAe,IAAI,OAAO;AAAA;AAEhD,UAAI,CAAC,SAAS,QAAQ;AACpB,cAAM,IAAIhE,qBAAc,sBAAsB;AAAA;AAEhD,UAAI,OAAO,KAAK,KAAK,SAAS;AAAA,OAE/B,OAAO,yBAAyB,OAAO,KAAK,QAAQ;AACnD,YAAM,EAAE,QAAQ,IAAI;AACpB,YAAM,gBAAgB,kBAAkB,KAAK;AAAA,QAC3C,oBAAoB,eAAe,IAAI,OAAO;AAAA;AAEhD,UAAI,OAAO,KAAK;AAAA,OAEjB,IAAI,4CAA4C,OAAO,KAAK,QAAQ;AACnE,YAAM,EAAE,MAAM,WAAW,SAAS,IAAI;AACtC,YAAM,EAAE,aAAa,MAAM,gBAAgB,SAAS;AAAA,QAClD,QAAQ,kBAAkB;AAAA,UACxB;AAAA,UACA,sBAAsB;AAAA,UACtB,iBAAiB;AAAA;AAAA,QAEnB,oBAAoB,eAAe,IAAI,OAAO;AAAA;AAEhD,UAAI,CAAC,SAAS,QAAQ;AACpB,cAAM,IAAIA,qBACR,oBAAoB,2BAA2B,uBAAuB;AAAA;AAG1E,UAAI,OAAO,KAAK,KAAK,SAAS;AAAA,OAE/B,IACC,qDACA,OAAO,KAAK,QAAQ;AAClB,YAAM,EAAE,MAAM,WAAW,SAAS,IAAI;AACtC,YAAM,YAAYuD,gCAAmB,EAAE,MAAM,WAAW;AACxD,YAAM,WAAW,MAAM,gBAAgB,eAAe;AACtD,UAAI,OAAO,KAAK,KAAK;AAAA,OAGxB,IAAI,kBAAkB,OAAO,KAAK,QAAQ;AACzC,YAAM,WAAW,MAAM,gBAAgB,OAAO;AAAA,QAC5C,QAAQ,wBAAwB,IAAI;AAAA,QACpC,QAAQ,uBAAuB,IAAI;AAAA,QACnC,oBAAoB,eAAe,IAAI,OAAO;AAAA;AAEhD,UAAI,OAAO,KAAK,KAAK;AAAA;AAAA;AAI3B,MAAI,iBAAiB;AACnB,WACG,KAAK,cAAc,OAAO,KAAK,QAAQ;AACtC,YAAM,WAAW,MAAM,oBAAoB,KAAK;AAChD,YAAM,SAASU,uBAAG,IAAI,MAAM,QAAQ,EAAE,SAAS;AAI/C,UAAI,CAAC,QAAQ;AACX,6BAAqB;AAAA;AAGvB,YAAM,SAAS,MAAM,gBAAgB,eAAe,UAAU,QAAQ;AAAA,QACpE,oBAAoB,eAAe,IAAI,OAAO;AAAA;AAEhD,UAAI,OAAO,KAAK,KAAK;AAAA,OAEtB,IAAI,cAAc,OAAO,KAAK,QAAQ;AACrC,YAAM,YAAY,MAAM,gBAAgB,cAAc;AAAA,QACpD,oBAAoB,eAAe,IAAI,OAAO;AAAA;AAEhD,UAAI,OAAO,KAAK,KAAK,UAAU,IAAI,UAAQ,MAAM;AAAA,OAGlD,IAAI,kBAAkB,OAAO,KAAK,QAAQ;AACzC,YAAM,EAAE,OAAO,IAAI;AACnB,YAAM,SAAS,MAAM,gBAAgB,YAAY,IAAI;AAAA,QACnD,oBAAoB,eAAe,IAAI,OAAO;AAAA;AAEhD,UAAI,OAAO,KAAK,KAAK;AAAA,OAEtB,OAAO,kBAAkB,OAAO,KAAK,QAAQ;AAC5C,2BAAqB;AAErB,YAAM,EAAE,OAAO,IAAI;AACnB,YAAM,gBAAgB,eAAe,IAAI;AAAA,QACvC,oBAAoB,eAAe,IAAI,OAAO;AAAA;AAEhD,UAAI,OAAO,KAAK;AAAA;AAAA;AAItB,MAAI,kBAAkB;AACpB,WAAO,KAAK,qBAAqB,OAAO,KAAK,QAAQ;AACnD,YAAM,OAAO,MAAM,oBACjB,KACAH,MAAE,OAAO,EAAE,UAAU;AAEvB,YAAM,SAASA,MAAE,OAAO,EAAE,UAAU;AACpC,YAAM,SAAS,MAAM,iBAAiB,gBAAgB,OAAO,MAAM;AACnE,UAAI,OAAO,KAAK,KAAK;AAAA;AAAA;AAIzB,SAAO,IAAII;AACX,SAAO;AAAA;AAGT,wBACE,qBACoB;AACpB,MAAI,OAAO,wBAAwB,UAAU;AAC3C,WAAO;AAAA;AAET,QAAM,UAAU,oBAAoB,MAAM;AAC1C,SAAO,mCAAU;AAAA;;mCCzNiD;AAAA,EAClE,YAA6B,QAAgB;AAAhB;AAAA;AAAA,EAE7B,kBAA0B;AACxB,WAAO;AAAA;AAAA,QAGH,QAAQ,YAAqD;AACjE,UAAM,WAAW,KAAK;AACtB,UAAM,WAAW,cAAc;AAAA,MAC7B,MAAM;AAAA,MACN;AAAA;AAGF,QAAI,KAAK,OAAO,WAAW;AACzB,UAAI,aAAa,KAAK,UAAU;AAEhC,WAAK,OAAO,UAAU,MAAM;AAC1B,cAAM,cAAc,KAAK;AACzB,cAAM,SAAS,KAAK,UAAU;AAE9B,YAAI,eAAe,QAAQ;AACzB,uBAAa;AACb,qBAAW,cAAc;AAAA,YACvB,MAAM;AAAA,YACN,UAAU;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOZ,wBAAwB;AAtDlC;AAuDI,UAAM,kBACJ,WAAK,OAAO,uBAAuB,yBAAnC,YAA2D;AAE7D,WAAO,gBAAgB,IAAI,cAAY;AACrC,YAAM,OAAO,SAAS,UAAU;AAChC,YAAM,SAAS,SAAS,UAAU;AAClC,YAAM,SAAS,6BAA6B;AAAA,QAC1C;AAAA,QACA,QAAQ,SAAS,SAAShE,yBAAK,QAAQ,UAAU;AAAA;AAEnD,YAAM,cAAc,qBAAqB;AACzC,aAAO,EAAE,QAAQ;AAAA;AAAA;AAAA;;2BCxCoD;AAAA,EAGzE,YAA6B,IAAU;AAAV;AAAA;AAAA,EAE7B,kBAA0B;AACxB,WAAO;AAAA;AAAA,QAGH,eAAe,OAAyC;AAC5D,UAAM,WAAW,MAAM,KAAK,GAAG,YAAY,OAAM,OAAM;AAErD,YAAM,oBAAoB,MAAM,KAAK,UAAU;AAG/C,YAAM,mBAAmB,kBAAkB,KACzC,OAAK,MAAM,SAAS,EAAE,QAAQ,MAAM,WAAW,EAAE;AAEnD,UAAI,kBAAkB;AACpB,cAAM,IAAI2D,qBACR,YAAY,MAAM,QAAQ,MAAM;AAAA;AAIpC,YAAM,QAAwB;AAAA,QAC5B,IAAIM;AAAA,QACJ,MAAM,MAAM;AAAA,QACZ,QAAQ,MAAM;AAAA;AAGhB,YAAM,GAAmB,aAAa,OAAO;AAE7C,aAAO;AAAA;AAET,UAAM,SAAS,6BAA6B;AAC5C,UAAM,KAAK,WAAW,cAAc;AAAA,MAClC,MAAM;AAAA,MACN,OAAO,CAAC,EAAE,QAAQ,aAAa,qBAAqB;AAAA,MACpD,SAAS;AAAA;AAGX,WAAO;AAAA;AAAA,QAGH,gBAAqC;AACzC,WAAO,MAAM,KAAK;AAAA;AAAA,QAGd,YAAY,IAA+B;AAC/C,UAAM,QAAQ,MAAM,KAAK,GAAmB,aACzC,MAAM,EAAE,MACR;AAEH,QAAI,CAAC,MAAM,QAAQ;AACjB,YAAM,IAAInE,qBAAc,6BAA6B;AAAA;AAEvD,WAAO,MAAM;AAAA;AAAA,QAGT,eAAe,IAA2B;AAC9C,QAAI,CAAC,KAAK,YAAY;AACpB,YAAM,IAAI,MAAM;AAAA;AAGlB,UAAM,UAAU,MAAM,KAAK,GAAG,YAAY,OAAM,OAAM;AACpD,YAAM,CAAC,YAAY,MAAM,GAAmB,aACzC,MAAM,EAAE,MACR;AAEH,UAAI,CAAC,UAAU;AACb,cAAM,IAAIA,qBAAc,6BAA6B;AAAA;AAGvD,YAAM,GAAmB,aAAa,MAAM,EAAE,MAAM;AACpD,aAAO;AAAA;AAET,UAAM,SAAS,6BAA6B;AAC5C,UAAM,KAAK,WAAW,cAAc;AAAA,MAClC,MAAM;AAAA,MACN,OAAO;AAAA,MACP,SAAS,CAAC,EAAE,QAAQ,aAAa,qBAAqB;AAAA;AAAA;AAAA,MAI9C,aAAuC;AACjD,QAAI,CAAC,KAAK,aAAa;AACrB,YAAM,IAAI,MAAM;AAAA;AAGlB,WAAO,KAAK;AAAA;AAAA,QAGR,QAAQ,YAAqD;AACjE,SAAK,cAAc;AAEnB,UAAM,YAAY,MAAM,KAAK;AAE7B,UAAM,WAAW,UAAU,IAAI,cAAY;AACzC,YAAM,SAAS,6BAA6B;AAC5C,aAAO,EAAE,QAAQ,aAAa,qBAAqB;AAAA;AAGrD,UAAM,KAAK,WAAW,cAAc;AAAA,MAClC,MAAM;AAAA,MACN;AAAA;AAAA;AAAA,QAIU,UAAU,SAAkC,KAAK,IAAI;AACjE,UAAM,YAAY,MAAM,OAAuB,aAAa;AAC5D,WACE,UAGG,OAAO,CAAC,EAAE,WAAW,SAAS,aAC9B,IAAI;AAAS,MACZ,IAAI,KAAK;AAAA,MACT,QAAQ,KAAK;AAAA,MACb,MAAM,KAAK;AAAA;AAAA;AAAA;;2BCtHyC;AAAA,EAI5D,YAAY,QAAgB,iBAAyC;AACnE,SAAK,SAAS;AACd,SAAK,kBAAkB;AAAA;AAAA,QAEnB,gBACJ,SACkC;AAClC,UAAM,EAAE,OAAO,SAASmB,gCAAY,QAAQ,SAAS;AACrD,UAAM,SAAiB;AAAA,MACrB,YAAY;AAAA,MACZ,MAAM;AAAA,MACN,UAAU;AAAA,QACR;AAAA;AAAA,MAEF,MAAM,EAAE,MAAM,SAAS,WAAW;AAAA;AAGpC,UAAM,cAAc,KAAK,gBAAgB,MAAM,QAAQ,SAAS;AAChE,QAAI;AACJ,YAAQ,2CAAa;AAAA,WACd;AACH,2BAAmB;AACnB;AAAA,WACG;AACH,2BAAmB;AACnB;AAAA,WACG;AACH,2BAAmB;AACnB;AAAA,WACG;AACH,2BAAmB;AACnB;AAEA;AAGJ,QAAI,kBAAkB;AACpB,aAAO,SAAS,cAAc;AAAA,SAC3B,GAAG,kCAAkC,GAAG,SAAS;AAAA;AAAA;AAItD,SAAK,OAAO,MAAM,sBAAsB,QAAQ,SAAS;AACzD,WAAO;AAAA,MACL,qBAAqB;AAAA,MACrB,kBAAkB,CAAC,EAAE,QAAQ,QAAQ;AAAA;AAAA;AAAA;;6BCjDP,OAAgC;AAClE,MAAI;AACF,QAAI,OAAO,UAAU,UAAU;AAC7B,aAAOiD,eAAS,WAAW,OAAO;AAAA;AAGpC,UAAM,SAAS,MAAM,SAAS,OAC1BA,eAAS,QAAQ,OAAO,EAAE,MAAM,WAChCA,eAAS,QAAQ,OAAO,EAAE,MAAM;AACpC,QAAI,CAAC,OAAO,SAAS;AACnB,YAAM,IAAI,UAAU;AAAA;AAGtB,WAAO;AAAA,WACA,GAAP;AACA,UAAM,IAAInE,kBAAW,sCAAsC,SAAS;AAAA;AAAA;sBAO3C,GAAe;AAC1C,MACE,4BAA4B,KAAK,EAAE,YACnC,oBAAoB,KAAK,EAAE,UAC3B;AACA,UAAM,IAAI4D,qBAAc,wCAAwC;AAAA;AAGlE,QAAM;AAAA;;6BC3BN,QACY;AACZ,QAAM,WAAWQ,oBAAS,gBAAgB,OAAO;AACjD,SAAO,YAAY,IAAIC,mBAAW;AAAA;2BAIlC,QACU;AACV,QAAM,WAAWD,oBAAS,gBAAgB,OAAO;AACjD,SAAO,YAAY,IAAIE,iBAAS;AAAA;6BAIhC,QACY;AACZ,QAAM,WAAWF,oBAAS,gBAAgB,OAAO;AACjD,SAAO,YAAY,IAAIG,mBAAW;AAAA;;6BC1BA,MAAY;AAC9C,QAAM,2BAAW;AACjB,SAAO;AAAA,IACL,gBAAgB,kBAAkB;AAAA,MAChC,MAAM;AAAA,MACN,MAAM;AAAA,MACN,YAAY,CAAC;AAAA,YACP,UAAU;AACd,cAAM,SAAS,MAAM,KAAwB,iBAAiB,OAC5D;AAEF,cAAM,UAAU,OACb,IAAI,SAAO,IAAI,WAAW,MAAM,KAAK,IACrC,OAAO,CAAC,KAAK,MAAM,IAAI,IAAI,GAAI,KAAI,IAAI,MAAM,KAAK,wBAAQ;AAE7D,gBAAQ,QAAQ,CAAC,OAAO,QAAQ;AAC9B,eAAK,IAAI;AACT,eAAK,IAAI,EAAE,MAAM,OAAO;AAAA;AAI1B,aAAK,QAAQ,SAAO;AAClB,cAAI,CAAC,QAAQ,IAAI,MAAM;AACrB,iBAAK,IAAI,EAAE,MAAM,OAAO;AACxB,iBAAK,OAAO;AAAA;AAAA;AAAA;AAAA;AAAA,IAKpB,sBAAsB,kBAAkB;AAAA,MACtC,MAAM;AAAA,MACN,MAAM;AAAA,YACA,UAAU;AACd,cAAM,QAAQ,MAAM,KAAqB,aAAa,MAAM;AAAA,UAC1D,OAAO;AAAA;AAET,aAAK,IAAI,OAAO,MAAM,GAAG;AAAA;AAAA;AAAA,IAG7B,WAAW,kBAAkB;AAAA,MAC3B,MAAM;AAAA,MACN,MAAM;AAAA,YACA,UAAU;AACd,cAAM,QAAQ,MAAM,KAAqB,aAAa,MAAM;AAAA,UAC1D,OAAO;AAAA;AAET,aAAK,IAAI,OAAO,MAAM,GAAG;AAAA;AAAA;AAAA;AAAA;;8BC9CE,QAAgB;AACjD,SAAOhB,kBAAW,QACf,OAAOiB,oCAAgB,KAAK,WAC5B,OAAO;AAAA;;AC8BZ,MAAMC,eAAa;AACnB,MAAM,qBAAqB;gCAE0C;AAAA,EACnE,YACmB,SAKjB;AALiB;AAMjB,wBAAoB,QAAQ;AAAA;AAAA,QAGxB,sBACJ,UACA,SACe;AACf,UAAM,KAAK;AACX,UAAM;AAAA,MACJ;AAAA,MACA;AAAA,MACA;AAAA,cACAC;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,QACE;AACJ,UAAM,gBAAgB,MAAM,GAAsB,iBAC/C,OAAO;AAAA,MACN,kBAAkB,KAAK,UAAU;AAAA,MACjC,aAAa;AAAA,cACbA;AAAA,MACA,cAAc;AAAA,OAEf,MAAM,aAAa,IACnB,SAAS,WAAS;AACjB,UAAI,CAAC,aAAa;AAChB,eAAO,MAAM,UAAU;AAAA;AAEzB,aAAO,MACJ,MAAM,gBAAgB,aACtB,YAAY;AAAA;AAEnB,QAAI,kBAAkB,GAAG;AACvB,YAAM,IAAId,qBACR,8CAA8C,yBAAyB;AAAA;AAK3E,UAAM,KAAK,uBAAuB,IAAI;AAAA,MACpC,UAAU;AAAA,MACV,iBAAiBN,gCAAmB;AAAA;AAItC,UAAM,GAAmB,aACtB,MAAM,EAAE,uBAAuB,MAC/B;AAGH,UAAM,eAAiC,UAAU,IAC/C,CAAC,EAAE,QAAQ,QAAQ;AAAY,MAC7B,uBAAuB;AAAA,MACvB,mBAAmBA,gCAAmB;AAAA,MACtC,mBAAmBA,gCAAmB;AAAA,MACtC;AAAA;AAGJ,UAAM,GAAG,YACP,aACA,KAAK,qBAAqB,eAC1BmB;AAAA;AAAA,QAIE,4BACJ,UACA,SACe;AACf,UAAM,KAAK;AACX,UAAM,EAAE,IAAI,QAAQ,eAAe;AAEnC,UAAM,GAAsB,iBACzB,OAAO;AAAA,MACN;AAAA,MACA,aAAa;AAAA,OAEd,MAAM,aAAa;AAAA;AAAA,QAGlB,kBACJ,UACA,SACe;AACf,UAAM,KAAK;AACX,UAAM,EAAE,IAAI,UAAU;AAEtB,UAAM,GAAsB,iBACzB,OAAO,EAAE,OAAO,KAAK,UAAU,wBAAS,OACxC,MAAM,aAAa;AAAA;AAAA,QAGlB,2BACJ,UACA,SACe;AACf,UAAM,KAAK;AAEX,UAAM,EAAE,OAAO,UAAU,aAAa,MAAM,KAAK,YAAY,IAAI;AAEjE,QAAI,SAAS,QAAQ;AAqCnB,YAAM,eAAe,MAAM,GAAsB,iBAC9C,QAAQ,cAAc,4BAA4B,SAAS;AAC1D,eACE,QAEG,cAAc,eAAe,qBAAqB,OAAO;AACxD,iBAAO,MACJ,OAAO,EAAE,SAAS,MAAM,YAAY,uBACpC,KAAK,4BACL,MAAM,cAAc,QAAQ,WAC5B,QAAQ,qBAAqB,UAC7B,MAAM,mBAAmB,OAAO;AAC/B,mBAAO,MACJ,OAAO;AAAA,cACN,SAAS;AAAA,cACT,YACE;AAAA,eAEH,KAAK,eACL,KAAK,4BAA4B;AAAA,cAChC,0BACE;AAAA;AAAA;AAAA,WAKX,cAAc,aAAa,mBAAmB,OAAO;AACpD,iBAAO,MACJ,OAAO;AAAA,YACN,SAAS,GAAG,IAAI,qBAAqB;AAAA,YACrC,gBAAgB;AAAA,YAChB,eAAe;AAAA,aAEhB,KAAK,eACL,MAAM,mBAAmB,OAAO;AAC/B,mBAAO,MACJ,OAAO;AAAA,cACN,SAAS,GAAG,IACV,0DACA;AAAA,cAEF,gBAAgB;AAAA,cAChB,eAAe;AAAA,eAEhB,KAAK,aACL,KAAK,4BAA4B;AAAA,cAChC,mBAAmB;AAAA;AAAA;AAAA,WAK5B,OAAO,0BACP,KAAK,eAEL,cAAc,aAAa,0BAA0B;AACpD,eAAK,GACH,2BACA,KACA;AAEF,eAAK,aAAa;AAClB,eAAK,MAAM,qBAAqB,MAAM;AAAA,WAEvC,UAAU;AAAA,SAGhB;AAEH,YAAM,GAAgC,4BACnC,MAAM,cAAc,KAAK,QAAQ,WACjC,QAAQ,qBAAqB,UAC7B;AAEH,WAAK,QAAQ,OAAO,MAClB,YAAY,0BAA0B,KAAK,UAAU;AAAA;AAIzD,QAAI,MAAM,QAAQ;AAUhB,iBAAW,SAASxB,2BAAO,MAAM,OAAO,KAAK;AAC3C,YAAI;AACF,gBAAM,GAAG,YACP,iBACA,MAAM,IAAI;AAAS,YACjB,WAAWiB;AAAA,YACX,YAAYZ,gCAAmB,KAAK,SAAS;AAAA,YAC7C,oBAAoB,KAAK,UAAU,KAAK,SAAS;AAAA,YACjD,kBAAkB,KAAK;AAAA,YACvB,QAAQ;AAAA,YACR,cAAc,KAAK,SAAS;AAAA,YAC5B,gBAAgB,GAAG,GAAG;AAAA,YACtB,mBAAmB,GAAG,GAAG;AAAA,eAE3BmB;AAEF,gBAAM,GAAG,YACP,4BACA,MAAM,IAAI;AAAS,YACjB,YAAY,QAAQ;AAAA,YACpB,mBAAmBnB,gCAAmB,KAAK,SAAS;AAAA,eAEtDmB;AAAA,iBAEK,OAAP;AACA,cAAI,CAACE,sCAAwB,QAAQ;AACnC,kBAAM;AAAA,iBACD;AACL,iBAAK,QAAQ,OAAO,MAClB,uDAAuD;AAEzD,qBAAS,KAAK,GAAG;AAAA;AAAA;AAAA;AAAA;AAMzB,QAAI,SAAS,QAAQ;AACnB,iBAAW;AAAA,QACT,UAAU,EAAE,QAAQ;AAAA,QACpB;AAAA,WACG,UAAU;AACb,cAAM,YAAYrB,gCAAmB;AAErC,YAAI;AACF,cAAI,KAAK,MAAM,KAAK,wBAClB,IACA,QACA,MACA;AAEF,cAAI,CAAC,IAAI;AACP,iBAAK,MAAM,KAAK,wBACd,IACA,QACA,MACA;AAAA;AAIJ,cAAI,IAAI;AACN,kBAAM,GACJ,4BACA,OAAO;AAAA,cACP,YAAY,QAAQ;AAAA,cACpB,mBAAmB;AAAA;AAAA,iBAEhB;AACL,kBAAM,iBAAiB,MAAM,KAAK,yBAChC,IACA,WACA;AAEF,gBAAI,gBAAgB;AAClB,mBAAK,QAAQ,OAAO,KAClB,UAAU,QAAQ,4CAA4C,mCAAmC,+BAA+B;AAAA;AAAA;AAAA,iBAI/H,OAAP;AACA,eAAK,QAAQ,OAAO,MAClB,kBAAkB,2BAA2B,QAAQ,eAAe;AAAA;AAAA;AAAA;AAAA;AAAA,QAOxE,uBACJ,UACA,SACuC;AACvC,UAAM,KAAK;AAEX,QAAI,aAAa,GAAsB,iBAAiB;AAKxD,QAAI,CAAC,SAAS,UAAU,MAAM,SAAS,GAAG,OAAO,OAAO,SAAS;AAC/D,mBAAa,WAAW,YAAY;AAAA;AAGtC,UAAM,QAAQ,MAAM,WACjB,MAAM,kBAAkB,MAAM,GAAG,GAAG,OACpC,MAAM,QAAQ,kBACd,QAAQ,kBAAkB;AAE7B,UAAM,WAAW,KAAK,QAAQ;AAC9B,UAAM,GAAsB,iBACzB,QACC,cACA,MAAM,IAAI,OAAK,EAAE,aAElB,OAAO;AAAA,MACN,gBAAgB,GAAG,OAAO,OAAO,OAAO,SAAS,aAC7C,GAAG,IAAI,sBAAsB,CAAC,GAAG,uBACjC,GAAG,IAAI,qBAAqB;AAAA;AAGpC,WAAO;AAAA,MACL,OAAO,MAAM,IACX;AACG,QACC,IAAI,EAAE;AAAA,QACN,WAAW,EAAE;AAAA,QACb,mBAAmB,KAAK,MAAM,EAAE;AAAA,QAChC,iBAAiB,EAAE,mBACd,KAAK,MAAM,EAAE,oBACd;AAAA,QACJ,YAAY,EAAE,eAAe;AAAA,QAC7B,cAAc,oBAAoB,EAAE;AAAA,QACpC,iBAAiB,oBAAoB,EAAE;AAAA,QACvC,OAAO,EAAE,QAAQ,KAAK,MAAM,EAAE,SAAS;AAAA,QACvC,QAAQ,EAAE;AAAA,QACV,aAAa,EAAE;AAAA;AAAA;AAAA;AAAA,QAMnB,cACJ,UACA,SAC8B;AAlblC;AAmbI,UAAM,KAAK;AACX,UAAM,EAAE,cAAc;AACtB,UAAM,aAAa,IAAI;AAEvB,QAAI,aAAa,UAAU,kBAAkB;AAC7C,aAAS,QAAQ,GAAG,SAAS,oBAAoB,SAAS,GAAG;AAC3D,YAAM,OAAO,MAAM,GACjB,4BAEC,MAAM,EAAE,mBAAmB,cAC3B;AAEH,UAAI,KAAK,WAAW,GAAG;AACrB,YAAI,UAAU,GAAG;AACf,gBAAM,IAAIvD,qBAAc,UAAU;AAAA;AAEpC,cAAM,IAAIA,qBACR,UAAU,oDAAoD;AAAA;AAIlE,YAAM,YAAY,WAAK,KAAK,OAAK,EAAE,uBAAjB,mBAAqC;AACvD,UAAI,CAAC,WAAW;AAGd,eAAO,EAAE;AAAA;AAEX,iBAAW,KAAK;AAChB,mBAAa;AAAA;AAEf,UAAM,IAAI,MACR,gCAAgC,uCAAuC;AAAA;AAAA,QAIrE,YACJ,UACA,SAC4B;AAC5B,UAAM,KAAK;AAEX,UAAM,OAAO,MAAM,GACjB,4BAEC,MAAM,EAAE,mBAAmB,QAAQ,aACnC;AAEH,UAAM,aAAa,KAAK,IAAI,OAAK,EAAE,mBAAoB,OAAO;AAE9D,WAAO,EAAE;AAAA;AAAA,QAGL,QAAQ,UAAuB,SAAwC;AAC3E,UAAM,KAAK;AACX,UAAM,EAAE,cAAc;AAEtB,UAAM,eAAe,MAAM,GAAsB,iBAC9C,MAAM,EAAE,YAAY,UAAU,kBAAkB,YAChD,OAAO,EAAE,gBAAgB,GAAG,GAAG;AAClC,QAAI,iBAAiB,GAAG;AACtB,YAAM,IAAIA,qBAAc,sBAAsB;AAAA;AAAA;AAAA,QAI5C,YAAe,IAAiD;AACpE,QAAI;AACF,UAAI,SAAwB;AAE5B,YAAM,KAAK,QAAQ,SAAS,YAC1B,OAAM,OAAM;AAGV,iBAAS,MAAM,GAAG;AAAA,SAEpB;AAAA,QAEE,uBAAuB;AAAA;AAI3B,aAAO;AAAA,aACA,GAAP;AACA,WAAK,QAAQ,OAAO,MAAM,6BAA6B;AACvD,YAAM,aAAa;AAAA;AAAA;AAAA,QAUT,wBACZ,IACA,QACA,MACA,aACkB;AAClB,UAAM,YAAYuD,gCAAmB;AACrC,UAAM,mBAAmB,KAAK,UAAU;AAExC,UAAM,gBAAgB,MAAM,GAAsB,iBAC/C,OAAO;AAAA,MACN,oBAAoB;AAAA,MACpB,kBAAkB;AAAA,MAClB,cAAc;AAAA,MACd,mBAAmB,GAAG,GAAG;AAAA,MAIzB,gBAAgB,GAAG,GAAG;AAAA,OAEvB,MAAM,cAAc,WACpB,SAAS,WAAS;AACjB,UAAI,CAAC,aAAa;AAChB,eAAO,MAAM,UAAU;AAAA;AAEzB,aAAO,MACJ,MAAM,gBAAgB,aACtB,YAAY;AAAA;AAGnB,WAAO,kBAAkB;AAAA;AAAA,QAOb,wBACZ,IACA,QACA,MACA,aACkB;AAClB,UAAM,YAAYA,gCAAmB;AACrC,UAAM,mBAAmB,KAAK,UAAU;AAExC,QAAI;AACF,UAAI,QAAQ,GAAsB,iBAAiB,OAAO;AAAA,QACxD,WAAWY;AAAA,QACX,YAAY;AAAA,QACZ,oBAAoB;AAAA,QACpB,kBAAkB;AAAA,QAClB,QAAQ;AAAA,QACR,cAAc;AAAA,QACd,gBAAgB,GAAG,GAAG;AAAA,QACtB,mBAAmB,GAAG,GAAG;AAAA;AAO3B,UAAI,CAAC,GAAG,OAAO,OAAO,OAAO,SAAS,YAAY;AAChD,gBAAQ,MAAM,WAAW,cAAc;AAAA;AAIzC,YAAM,SAAiD,MAAM;AAC7D,aAAO,OAAO,aAAa,KAAK,OAAO,WAAW;AAAA,aAC3C,OAAP;AAEA,UACEU,eAAQ,UACR,MAAM,QAAQ,SAAS,6BACvB;AACA,eAAO;AAAA;AAET,YAAM;AAAA;AAAA;AAAA,QAUI,yBACZ,IACA,WACA,aAC6B;AAC7B,UAAM,MAAM,MAAM,GAAsB,iBACrC,OAAO,gBACP,MAAM,cAAc,WACpB;AAEH,UAAM,iBAAiB,2BAAK;AAG5B,QAAI,CAAC,gBAAgB;AACnB,aAAO;AAAA;AAGT,QAAI,mBAAmB,aAAa;AAClC,aAAO;AAAA;AAET,WAAO;AAAA;AAAA,EAGD,qBAAqB,MAA0C;AACrE,WAAO3B,2BAAO,OACZ,MACA,OAAK,GAAG,EAAE,qBAAqB,EAAE,qBAAqB,EAAE;AAAA;AAAA,QAI9C,YACZ,IACA,SAKC;AACD,QAAI,QAAQ,SAAS,SAAS;AAC5B,aAAO;AAAA,QACL,OAAO;AAAA,QACP,UAAU,QAAQ,MAAM,IAAI;AAAM,UAChC,UAAU;AAAA,UACV,MAAM4B,qBAAmB,EAAE;AAAA;AAAA,QAE7B,UAAU,QAAQ,QAAQ,IAAI,OAAKvB,gCAAmB,EAAE;AAAA;AAAA;AAK5D,UAAM,UAAU,MAAM,GACpB,4BAEC,SAA4B,iBAAiB;AAAA,MAC5C,mBAAmB;AAAA,OAEpB,MAAM,EAAE,YAAY,QAAQ,aAC5B,OAAO;AAAA,MACN,mBAAmB;AAAA,MACnB,cAAc;AAAA,MACd,kBAAkB;AAAA;AAGtB,UAAM,QAAQ,QAAQ,MAAM,IAAI;AAAa,MAC3C;AAAA,MACA,KAAKA,gCAAmB,SAAS;AAAA,MACjC,MAAMuB,qBAAmB,SAAS;AAAA;AAGpC,UAAM,aAAa,IAAI,IACrB,QAAQ,IAAI,OAAK;AAAA,MACf,EAAE;AAAA,MACF;AAAA,QACE,aAAa,EAAE;AAAA,QACf,eAAe,EAAE;AAAA;AAAA;AAIvB,UAAM,aAAa,IAAI,IAAI,MAAM,IAAI,UAAQ,KAAK;AAElD,UAAM,QAAQ,IAAI;AAClB,UAAM,WAAW,IAAI;AACrB,UAAM,WAAW,QACd,IAAI,SAAO,IAAI,mBACf,OAAO,SAAO,CAAC,WAAW,IAAI;AAEjC,eAAW,QAAQ,OAAO;AACxB,YAAM,SAAS,WAAW,IAAI,KAAK;AACnC,YAAM,aAAa,EAAE,UAAU,KAAK,UAAU,MAAM,KAAK;AACzD,UAAI,CAAC,QAAQ;AAEX,cAAM,KAAK;AAAA,iBACF,OAAO,gBAAgB,KAAK,SAAS,aAAa;AAE3D,iBAAS,KAAK,KAAK;AACnB,cAAM,KAAK;AAAA,iBACF,OAAO,kBAAkB,KAAK,MAAM;AAE7C,iBAAS,KAAK;AAAA;AAAA;AAIlB,WAAO,EAAE,OAAO,UAAU;AAAA;AAAA,QAOd,uBACZ,UACA,SAIe;AACf,UAAM,KAAK;AAGX,UAAM,kBAAkB,IAAI;AAC5B,UAAM,6BAA6B,IAAI;AAIvC,eAAW,EAAE,QAAQ,iBAAiB,QAAQ,UAAU;AACtD,YAAM,YAAYvB,gCAAmB;AACrC,YAAM,OAAOuB,qBAAmB;AAEhC,YAAM,UAAU,MAAM,KAAK,wBACzB,IACA,QACA,MACA;AAEF,UAAI,SAAS;AACX,wBAAgB,KAAK;AACrB;AAAA;AAGF,YAAM,WAAW,MAAM,KAAK,wBAC1B,IACA,QACA,MACA;AAEF,UAAI,UAAU;AACZ,wBAAgB,KAAK;AACrB;AAAA;AAMF,YAAM,iBAAiB,MAAM,KAAK,yBAChC,IACA,WACA;AAEF,UAAI,gBAAgB;AAClB,aAAK,QAAQ,OAAO,KAClB,kCAAkC,mCAAmC,+BAA+B;AAEtG,mCAA2B,KAAK;AAAA;AAAA;AAKpC,UAAM,GAAgC,4BACnC,WAAW,qBAAqB,4BAChC,SAAS,EAAE,mBAAmB,QAAQ,mBACtC;AACH,UAAM,GAAG,YACP,4BACA,gBAAgB,IAAI;AAAc,MAChC,mBAAmB,QAAQ;AAAA,MAC3B,mBAAmB;AAAA,SAErBJ;AAAA;AAAA;;uCCrwBwC,MAA2B;AACvE,QAAM,gBAAgBK,iCACpB,qCACA;AAGF,QAAM,KAAK,QAAQ,OAAO;AAAA,IACxB,WAAW;AAAA;AAAA;;ACVf,MAAM,8BAA8B;2BA6CC,SAAqB;AACxD,QAAM;AAAA,IACJ;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA,oBAAoB;AAAA,MAClB;AAEJ,MAAI,gBAAgB,eAAe;AACjC,UAAM,IAAI,MAAM;AAAA;AAGlB,MAAI,UAAU;AACd,MAAI,UAAU;AACd,MAAI,gBAAgB;AAEpB,iCAA+B;AAC7B,QAAI,WAAW,WAAW,gBAAgB,cAAc;AACtD;AAAA;AAIF,cAAU;AACV,UAAM,YAAY,gBAAgB;AAClC,UAAM,cAAc,MAAM,UAAU;AACpC,cAAU;AAGV,qBAAiB,YAAY;AAC7B,gBAAY,QAAQ,UAAQ;AAC1B,kBAAY,MAAM,QAAQ,MAAM;AAC9B,YAAI,SAAS;AACX;AAAA;AAIF,yBAAiB;AACjB;AAAA;AAAA;AAKJ,QAAI,YAAY,SAAS,GAAG;AAC1B;AAAA;AAAA;AAOJ,QAAM,aAAa,YAAY,MAAM;AACnC;AAAA,KACC;AAEH,SAAO,MAAM;AACX,cAAU;AACV,kBAAc;AAAA;AAAA;;ACvFlB,MAAM,YAAY;qCAE6D;AAAA,EAI7E,YACmB,QACA,oBACA,cACA,UACA,YACA,oBAA4B,KAC7C;AANiB;AACA;AACA;AACA;AACA;AACA;AATF,mBAAU;AAAA;AAAA,QAYrB,QAAQ;AACZ,QAAI,KAAK,UAAU;AACjB,YAAM,IAAI,MAAM;AAAA;AAGlB,SAAK,WAAW,kBAAoC;AAAA,MAClD,cAAc;AAAA,MACd,eAAe;AAAA,MACf,mBAAmB,KAAK;AAAA,MACxB,WAAW,OAAM,UAAS;AACxB,YAAI;AACF,gBAAM,EAAE,UAAU,MAAM,KAAK,mBAAmB,YAC9C,OAAM,OAAM;AACV,mBAAO,KAAK,mBAAmB,uBAAuB,IAAI;AAAA,cACxD,kBAAkB;AAAA;AAAA;AAIxB,iBAAO;AAAA,iBACA,OAAP;AACA,eAAK,OAAO,KAAK,mCAAmC;AACpD,iBAAO;AAAA;AAAA;AAAA,MAGX,aAAa,OAAM,SAAQ;AACzB,cAAM,QAAQ,KAAK,QAAQ,aAAa,MAAM,KAAK;AAEnD,YAAI;AACF,gBAAM;AAAA,YACJ;AAAA,YACA;AAAA,YACA;AAAA,YACA;AAAA,YACA;AAAA,YACA,YAAY;AAAA,cACV;AACJ,gBAAM,SAAS,MAAM,KAAK,aAAa,QAAQ;AAAA,YAC7C,QAAQ;AAAA,YACR;AAAA;AAGF,gBAAM,wBAAwB;AAE9B,cAAI,OAAO,IAAI;AACb,gBAAIN,oCAAgB,WAAWA,oCAAgB,OAAO,QAAQ;AAC5D,oBAAM,KAAK,mBAAmB,YAAY,OAAM,OAAM;AACpD,sBAAM,KAAK,mBAAmB,kBAAkB,IAAI;AAAA,kBAClD;AAAA,kBACA,OAAO;AAAA,oBACL,KAAK;AAAA,uBACF,OAAO;AAAA;AAAA;AAAA;AAAA;AAAA,iBAKb;AACL,kBAAM,WAAW,+BAAO;AACxB,kBAAM,MAAM,OAAO,UAAU,YAAa,WAAsB;AAChE,kBAAM,KAAK,mBAAmB,YAAY,OAAM,OAAM;AACpD,oBAAM,KAAK,mBAAmB,kBAAkB,IAAI;AAAA,gBAClD;AAAA,gBACA,OAAO,MAAM,IAAI,KAAK,OAAO,KAAK,MAAM,MAAM;AAAA;AAAA;AAAA;AAKpD,qBAAW,SAAS,OAAO,QAAQ;AAGjC,iBAAK,OAAO,KAAK,MAAM,SAAS;AAAA,cAC9B,QAAQ;AAAA;AAAA;AAGZ,gBAAM,eAAe,KAAK,UACxB,OAAO,OAAO,IAAI,OAAKO,sBAAe;AAGxC,cAAI,cAAc,KAAK,aAAa,OAAO;AAC3C,cAAI,OAAO,IAAI;AACb,kBAAM,EAAE,YAAY,YAClB,MAAM,KAAK,mBAAmB,YAAY,QACxC,KAAK,mBAAmB,YAAY,IAAI;AAAA,cACtC;AAAA;AAIN,0BAAc,YACX,OAAOP,oCAAgB,KAAK,OAAO,oBACnC,OAAOA,oCAAgB,CAAC,GAAG,OAAO,oBAClC,OAAOA,oCAAgB,CAAC,GAAG,OAAO,aAClC,OAAOA,oCAAgB,CAAC,GAAG;AAAA;AAGhC,gBAAM,aAAa,YAAY,OAAO;AACtC,cAAI,eAAe,oBAAoB;AAIrC,kBAAM;AACN;AAAA;AAUF,cAAI,CAAC,OAAO,IAAI;AACd,kBAAM,KAAK,mBAAmB,YAAY,OAAM,OAAM;AACpD,oBAAM,KAAK,mBAAmB,4BAA4B,IAAI;AAAA,gBAC5D;AAAA,gBACA,QAAQ;AAAA,gBACR;AAAA;AAAA;AAGJ,kBAAM,KAAK,SAAS,2BACd,IAAI,CAAClB,gCAAmB;AAE9B,kBAAM;AACN;AAAA;AAGF,iBAAO,gBAAgB,SAAS,MAAM;AACtC,gBAAM,KAAK,mBAAmB,YAAY,OAAM,OAAM;AACpD,kBAAM,KAAK,mBAAmB,sBAAsB,IAAI;AAAA,cACtD;AAAA,cACA,iBAAiB,OAAO;AAAA,cACxB;AAAA,cACA,QAAQ;AAAA,cACR,WAAW,OAAO;AAAA,cAClB,kBAAkB,OAAO;AAAA,cACzB;AAAA;AAAA;AAIJ,gBAAM,0CAA0B,IAAY;AAAA,YAC1CA,gCAAmB,OAAO;AAAA,YAC1B,GAAG,OAAO,UAAU,IAAI,cACtBA,gCAAmB,SAAS;AAAA;AAGhC,gBAAM,KAAK,SAAS,OAAO;AAE3B,gBAAM,0BAA0B,oBAAoB;AAAA,iBAC7C,OAAP;AACA,6BAAY;AACZ,gBAAM,WAAW;AAAA;AAAA;AAAA;AAAA;AAAA,QAMnB,OAAO;AACX,QAAI,KAAK,UAAU;AACjB,WAAK;AACL,WAAK,WAAW;AAAA;AAAA;AAAA;AAMtB,2BAA2B;AACzB,QAAM,mBAAmB,oBAAoB;AAAA,IAC3C,MAAM;AAAA,IACN,MAAM;AAAA;AAER,QAAM,oBAAoB,oBAAoB;AAAA,IAC5C,MAAM;AAAA,IACN,MAAM;AAAA,IACN,YAAY,CAAC;AAAA;AAEf,QAAM,qBAAqB,oBAAoB;AAAA,IAC7C,MAAM;AAAA,IACN,MAAM;AAAA,IACN,YAAY,CAAC;AAAA;AAEf,QAAM,qBAAqB,oBAAoB;AAAA,IAC7C,MAAM;AAAA,IACN,MAAM;AAAA,IACN,YAAY,CAAC;AAAA;AAEf,QAAM,uBAAuB,oBAAoB;AAAA,IAC/C,MAAM;AAAA,IACN,MAAM;AAAA;AAGR,wBAAsB,MAAwB,QAAgB;AAC5D,WAAO,MAAM,cAAc,KAAK;AAEhC,QAAI,KAAK,cAAc;AACrB,2BAAqB,QAAQ,CAAC,KAAK,aAAa,UAAU,GAAG;AAAA;AAG/D,UAAM,kBAAkB,mBAAmB;AAC3C,UAAM,qBAAqB,mBAAmB;AAE9C,qCAAiC,QAAgC;AAC/D,yBAAmB,EAAE,QAAQ,OAAO,KAAK,OAAO;AAAA;AAGlD,2CAAuC;AACrC,sBAAgB,EAAE,QAAQ;AAC1B,wBAAkB,IAAI,EAAE,QAAQ,eAAe;AAAA;AAGjD,wCAAoC;AAClC,sBAAgB,EAAE,QAAQ;AAC1B,wBAAkB,IAAI,EAAE,QAAQ,YAAY;AAAA;AAG9C,uCAAmC,eAAuB;AACxD,sBAAgB,EAAE,QAAQ;AAC1B,uBAAiB,IAAI;AACrB,wBAAkB,IAAI,EAAE,QAAQ,aAAa;AAAA;AAG/C,wBAAoB,OAAc;AAChC,wBAAkB,IAAI,EAAE,QAAQ,YAAY;AAC5C,aAAO,KAAK,iBAAiB,KAAK,oBAAoB;AAAA;AAGxD,WAAO;AAAA,MACL;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA;AAAA;AAIJ,SAAO,EAAE;AAAA;;6BCxPoD;AAAA,EAC7D,YACmB,OACA,cACjB;AAFiB;AACA;AAAA;AAAA,QAGb,eACJ,OACA,QACuE;AACvE,QAAI,QAAQ;AACV,aAAO,KAAK,qBAAqB;AAAA;AAEnC,UAAM,WAAW,MAAM,KAAK,MAAM,eAAe;AACjD,WAAO,EAAE,UAAU,UAAU;AAAA;AAAA,EAG/B,gBAAqC;AACnC,WAAO,KAAK,MAAM;AAAA;AAAA,EAEpB,YAAY,IAA+B;AACzC,WAAO,KAAK,MAAM,YAAY;AAAA;AAAA,EAEhC,eAAe,IAA2B;AACxC,WAAO,KAAK,MAAM,eAAe;AAAA;AAAA,QAGrB,gBACZ,qBACmB;AACnB,UAAM,WAAqB;AAC3B,WAAO,oBAAoB,QAAQ;AACjC,YAAM,gBAAgB,oBAAoB;AAC1C,UAAI,CAAC,eAAe;AAClB;AAAA;AAEF,YAAM,YAAY,MAAM,KAAK,aAAa,QAAQ;AAAA,QAChD,QAAQ,cAAc;AAAA,QACtB,OAAO;AAAA;AAGT,UAAI,UAAU,IAAI;AAChB,YACE,SAAS,KACP,OACEA,gCAAmB,OACnBA,gCAAmB,UAAU,mBAEjC;AACA,gBAAM,IAAI,MACR,4BAA4BA,gCAC1B,UAAU;AAAA;AAIhB,4BAAoB,KAAK,GAAG,UAAU;AACtC,iBAAS,KAAK,UAAU;AAAA,aACnB;AACL,cAAM,MAAM,UAAU,OAAO,IAAI,QAAQ,KAAK;AAAA;AAAA;AAGlD,WAAO;AAAA;AAAA,QAGK,qBACZ,MACuE;AAEvE,UAAM,gBAAgB,KAAK,MACxB,gBACA,KAAK,eACJ,UAAU,KAAK,OAAK,EAAE,SAAS,KAAK,QAAQ,EAAE,WAAW,KAAK;AAGlE,UAAM,SAAS;AAAA,MACb,YAAY;AAAA,MACZ,MAAM;AAAA,MACN,UAAU;AAAA,QACR,MAAM,2BAA2B;AAAA,UAC/B,MAAM,KAAK;AAAA,UACX,QAAQ,KAAK;AAAA;AAAA,QAEf,WAAW;AAAA,QACX,aAAa;AAAA,WACV1C,mCAAsB,GAAG,KAAK,QAAQ,KAAK;AAAA,WAC3CC,0CAA6B,GAAG,KAAK,QAAQ,KAAK;AAAA;AAAA;AAAA,MAGvD,MAAM;AAAA,QACJ,MAAM,KAAK;AAAA,QACX,QAAQ,KAAK;AAAA;AAAA;AAGjB,UAAM,sBAAwC;AAAA,MAC5C,EAAE,QAAQ,aAAa,GAAG,KAAK,QAAQ,KAAK;AAAA;AAE9C,UAAM,WAAqB,MAAM,KAAK,gBAAgB;AAEtD,WAAO;AAAA,MACL,QAAQ,MAAM;AAAA,MACd,UAAU,KAAK,MAAM,IAAI,GAAG,KAAK,QAAQ,KAAK;AAAA,MAC9C;AAAA;AAAA;AAAA;;ACxFN,yBAAyB,OAGvB;AACA,MAAI,CAAC,OAAO;AACV,WAAO;AAAA;AAGT,MAAI,EAAE,OAAO,WAAW;AAExB,MAAI,MAAM,UAAU,QAAW;AAC7B,QAAI;AACJ,QAAI;AACF,YAAM,OAAO,OAAO,KAAK,MAAM,OAAO,UAAU,SAAS;AACzD,eAAS,KAAK,MAAM;AAAA,YACpB;AACA,YAAM,IAAIb,kBAAW;AAAA;AAEvB,QAAI,OAAO,UAAU,QAAW;AAC9B,UAAI,CAAC,OAAO,UAAU,OAAO,QAAQ;AACnC,cAAM,IAAIA,kBAAW;AAAA;AAEvB,cAAQ,OAAO;AAAA;AAEjB,QAAI,OAAO,WAAW,QAAW;AAC/B,UAAI,CAAC,OAAO,UAAU,OAAO,SAAS;AACpC,cAAM,IAAIA,kBAAW;AAAA;AAEvB,eAAS,OAAO;AAAA;AAAA;AAIpB,SAAO,EAAE,OAAO;AAAA;AAGlB,6BAA6B,OAA0C;AACrE,QAAM,OAAO,KAAK,UAAU,EAAE,OAAO,MAAM,OAAO,QAAQ,MAAM;AAChE,QAAM,SAAS,OAAO,KAAK,MAAM,QAAQ,SAAS;AAClD,SAAO;AAAA;AAGT,sBACE,cACA,IACA,QACA,SAAkB,OAClB;AAIA,QAAM,aAAa,GAAgB,UAChC,OAAO,aACP,MAAM,EAAE,KAAK,OAAO,IAAI,iBACxB,SAAS,qBAAqB;AAC7B,QAAI,OAAO,QAAQ;AACjB,UAAI,OAAO,OAAO,WAAW,GAAG;AAC9B,aAAK,MAAM,EAAE,OAAO,OAAO,OAAO,GAAG;AAAA,aAChC;AACL,aAAK,SACH,SACA,MACA,OAAO,OAAO,IAAI,OAAK,EAAE;AAAA;AAAA;AAAA;AAKnC,eAAa,SAAS,aAAa,SAAS,WAAW,MAAM;AAAA;AAG/D,gCACE,QACgC;AAChC,SAAO,OAAO,eAAe;AAAA;AAG/B,0BACE,QACqC;AACrC,SAAO,OAAO,eAAe;AAAA;AAG/B,gCACE,QACiC;AACjC,SAAO,OAAO,eAAe;AAAA;AAG/B,qBACE,QACA,OACA,IACA,SAAkB,OACC;AACnB,MAAI,uBAAuB,SAAS;AAClC,WAAO,MAAM,SAAS,0BAA0B;AAC9C,mBAAa,MAAM,IAAI,QAAQ;AAAA;AAAA;AAInC,MAAI,uBAAuB,SAAS;AAClC,WAAO,YAAY,OAAO,KAAK,OAAO,IAAI,CAAC;AAAA;AAG7C,SAAO,MAAM,SAAS,gBAAgB,YAAY,0BAA0B;AAlJ9E;AAmJI,QAAI,iBAAiB,SAAS;AAC5B,iBAAW,aAAa,aAAO,UAAP,YAAgB,IAAI;AAC1C,aAAK,QAAQ,cAAY,YAAY,WAAW,UAAU;AAAA;AAAA,WAEvD;AACL,iBAAW,aAAa,aAAO,UAAP,YAAgB,IAAI;AAC1C,aAAK,SAAS,cAAY,YAAY,WAAW,UAAU;AAAA;AAAA;AAAA;AAAA;6BAMJ;AAAA,EAC7D,YAA6B,UAAgB;AAAhB;AAAA;AAAA,QAEvB,SAAS,SAAsD;AACnE,UAAM,KAAK,KAAK;AAEhB,QAAI,gBAAgB,GAAuB;AAC3C,QAAI,mCAAS,QAAQ;AACnB,sBAAgB,YAAY,QAAQ,QAAQ,eAAe;AAAA;AAI7D,oBAAgB,cACb,OAAO,oBACP,aAAa,+BACb,QAAQ,aAAa;AAExB,UAAM,EAAE,OAAO,WAAW,gBAAgB,mCAAS;AACnD,QAAI,UAAU,QAAW;AACvB,sBAAgB,cAAc,MAAM,QAAQ;AAAA;AAE9C,QAAI,WAAW,QAAW;AACxB,sBAAgB,cAAc,OAAO;AAAA;AAGvC,QAAI,OAAO,MAAM;AAEjB,QAAI;AACJ,QAAI,UAAU,UAAa,KAAK,UAAU,OAAO;AAC/C,iBAAW,EAAE,aAAa;AAAA,WACrB;AACL,aAAO,KAAK,MAAM,GAAG;AACrB,iBAAW;AAAA,QACT,aAAa;AAAA,QACb,WAAW,oBAAoB;AAAA,UAC7B;AAAA,UACA,QAAS,2BAAU,KAAK;AAAA;AAAA;AAAA;AAK9B,QAAI,WAAqB,KAAK,IAAI,OAAK,KAAK,MAAM,EAAE;AAEpD,QAAI,mCAAS,QAAQ;AACnB,iBAAW,SAAS,IAAI,OAAK,QAAQ,OAAQ;AAAA;AAO/C,eAAW,UAAU,UAAU;AAC7B,UAAI,OAAO,WAAW;AACpB,mBAAW,YAAY,OAAO,WAAW;AACvC,cAAI,CAAC,SAAS,aAAa,SAAS,QAAQ;AAG1C,qBAAS,YAAYsD,gCAAmB,SAAS;AAAA,qBACxC,CAAC,SAAS,UAAU,SAAS,WAAW;AAIjD,qBAAS,SAAS1B,4BAAe,SAAS;AAAA;AAAA;AAAA;AAAA;AAMlD,WAAO;AAAA,MACL;AAAA,MACA;AAAA;AAAA;AAAA,QAIE,kBAAkB,KAA4B;AASlD,UAAM,KAAK,SAA4B,iBACpC,OAAO;AAAA,MACN,aAAa;AAAA,OAEd,QAAQ,cAAc,iBAAiB,SAAS;AAC/C,aAAO,QACJ,KAAwB,iBACxB,UAAuC,4BAA4B;AAAA,QAClE,8CACE;AAAA,SAEH,MAAM,2BAA2B,KAAK,KACtC,OAAO;AAAA;AAGd,UAAM,KAAK,SAA4B,iBACpC,MAAM,aAAa,KACnB;AAAA;AAAA,QAGC,eAAe,SAAkD;AACrE,UAAM,CAAC,WAAW,MAAM,KAAK,SAA4B,iBACtD,SAA6B,kBAAkB;AAAA,MAC9C,2BAA2B;AAAA,OAE5B,MAAM,4BAA4B,KAAK,SACvC,OAAO;AAAA,MACN,YAAY;AAAA;AAGhB,QAAI,CAAC,SAAS;AACZ,YAAM,IAAI7B,qBAAc,kBAAkB;AAAA;AAG5C,UAAM,aAAa,KAAK,MAAM,QAAQ;AACtC,UAAM,qCAAqB;AAC3B,UAAM,OAAO,IAAI;AACjB,UAAM,QAAQ,IAAI;AAElB,aACM,UAA8B,YAClC,SACA,UAAU,KAAK,OACf;AACA,YAAM,aAAauD,gCAAmB;AACtC,qBAAe,IAAI;AAEnB,YAAM,aAAa,MAAM,KAAK,SAC5B,4BAEC,UAA6B,iBAAiB;AAAA,QAC7C,8CACE;AAAA,SAEH,UAA8B,kBAAkB;AAAA,QAC/C,2BAA2B;AAAA,SAE5B,MAAM,8CAA8C,KAAK,YACzD,OAAO;AAAA,QACN,iBAAiB;AAAA,QACjB,kBAAkB;AAAA;AAGtB,YAAM,aAAuB;AAC7B,iBAAW,EAAE,iBAAiB,sBAAsB,YAAY;AAC9D,mBAAW,KAAK;AAChB,YAAI,CAAC,eAAe,IAAI,kBAAkB;AACxC,yBAAe,IAAI;AACnB,eAAK,KAAK,KAAK,MAAM;AAAA;AAAA;AAIzB,YAAM,KAAK;AAAA,QACT,QAAQ;AAAA,QACR,kBAAkB;AAAA;AAAA;AAItB,WAAO;AAAA,MACL,eAAeA,gCAAmB;AAAA,MAClC;AAAA;AAAA;AAAA,QAIE,OAAO,SAA6D;AACxE,UAAM,EAAE,aAAa,MAAM,KAAK,SAAS;AAAA,MACvC,QAAQ,QAAQ;AAAA,MAChB,oBAAoB,QAAQ;AAAA;AAG9B,UAAM,SAAyC;AAE/C,eAAW,SAAS,QAAQ,QAAQ;AAClC,YAAM,SAAS,SACZ,IAAI,YAAU;AAhVvB;AAmVU,YAAI,MAAM,WAAW,0BAA0B;AAC7C,iBAAO,aAAO,SAAS,gBAAhB,mBACL,MAAM,UAAU,wBAAwB;AAAA,mBAEjC,MAAM,WAAW,qBAAqB;AAC/C,iBAAO,aAAO,SAAS,WAAhB,mBACL,MAAM,UAAU,mBAAmB;AAAA;AAGvC,eAAOL,2BAAO,IAAI,QAAQ;AAAA,SAE3B,QAAQ,WAAS;AAChB,YAAI,OAAO,UAAU,UAAU;AAC7B,iBAAO,CAAC;AAAA,mBACC,MAAM,QAAQ,QAAQ;AAC/B,iBAAO,MAAM,OAAO,OAAK,OAAO,MAAM;AAAA;AAExC,eAAO;AAAA,SAER;AAEH,YAAM,SAASA,2BAAO,QAAQ,QAAQA,2BAAO;AAE7C,aAAO,SAAS,OAAO,QAAQ,QAAQ,IAAI,CAAC,CAAC,OAAO;AAAY,QAC9D;AAAA,QACA;AAAA;AAAA;AAIJ,WAAO,EAAE;AAAA;AAAA;;ACzVb,MAAM,eAAe;AAAA,EACnB;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA;AAMF,MAAM,iBAAiB;AACvB,MAAM,mBAAmB;kBAkCA,MAAqB;AAC5C,QAAM,SAAe;AAErB,iBAAe,MAAc,SAAkB;AAC7C,QAAI,aAAa,SAAS,OAAO;AAC/B;AAAA;AAIF,QACE,YAAY,UACZ,YAAY,QACZ,CAAC,UAAU,UAAU,WAAW,SAAS,OAAO,UAChD;AACA,aAAO,KAAK,EAAE,KAAK,MAAM,OAAO;AAChC;AAAA;AAIF,QAAI,OAAO,YAAY,UAAU;AAC/B;AAAA;AAIF,QAAI,MAAM,QAAQ,UAAU;AAC1B,iBAAW,QAAQ,SAAS;AAc1B,cAAM,MAAM;AACZ,YAAI,OAAO,SAAS,UAAU;AAC5B,iBAAO,KAAK,EAAE,KAAK,GAAG,QAAQ,QAAQ,OAAO;AAAA;AAAA;AAGjD;AAAA;AAIF,eAAW,CAAC,KAAK,UAAU,OAAO,QAAQ,UAAW;AACnD,YAAM,OAAO,GAAG,QAAQ,QAAQ,KAAK;AAAA;AAAA;AAIzC,QAAM,IAAI;AAEV,SAAO;AAAA;mBAIiB,OAAa,UAAiC;AACtE,QAAM,SAAwB;AAE9B,aAAW,EAAE,KAAK,QAAQ,OAAO,cAAc,OAAO;AACpD,UAAM,MAAM,OAAO,kBAAkB;AACrC,QAAI,aAAa,UAAa,aAAa,MAAM;AAC/C,aAAO,KAAK,EAAE,WAAW,UAAU,KAAK,OAAO;AAAA,WAC1C;AACL,YAAM,QAAQ,OAAO,UAAU,kBAAkB;AACjD,UAAI,IAAI,UAAU,kBAAkB,MAAM,UAAU,kBAAkB;AACpE,eAAO,KAAK,EAAE,WAAW,UAAU,KAAK;AAAA;AAAA;AAAA;AAK9C,SAAO;AAAA;2BAWP,UACA,QACe;AA/JjB;AAiKE,QAAM,MAAM,SAAS;AAIrB,MAAI,KAAK,EAAE,KAAK,iBAAiB,OAAO,OAAO,SAAS;AACxD,MAAI,KAAK,EAAE,KAAK,sBAAsB,OAAO,OAAO,SAAS;AAC7D,MAAI,KAAK,EAAE,KAAK,gBAAgB,OAAO,OAAO,SAAS;AAIvD,MAAI,CAAC,OAAO,SAAS,WAAW;AAC9B,QAAI,KAAK,EAAE,KAAK,sBAAsB,OAAO+B;AAAA;AAI/C,aAAW,YAAY,aAAO,cAAP,YAAoB,IAAI;AAC7C,QAAI,KAAK;AAAA,MACP,KAAK,aAAa,SAAS;AAAA,MAC3B,OAAO,SAAS;AAAA;AAAA;AAMpB,QAAM,OAAO,IAAI,IAAI,IAAI,IAAI,OAAK,EAAE;AACpC,QAAM,YAAY,IAAI,IAAI,IAAI,IAAI,OAAK,EAAE,IAAI,kBAAkB;AAC/D,MAAI,KAAK,SAAS,UAAU,MAAM;AAChC,UAAM,aAAa;AACnB,eAAW,OAAO,MAAM;AACtB,YAAM,QAAQ,IAAI,kBAAkB;AACpC,UAAI,CAAC,UAAU,OAAO,QAAQ;AAC5B,mBAAW,KAAK;AAAA;AAAA;AAGpB,UAAM,UAAU,IAAI,WAAW,KAAK;AACpC,UAAM,IAAIhF,kBACR,uDAAuD;AAAA;AAI3D,SAAO,UAAU,KAAK;AAAA;;MCjLX,aAAa;4BAES,QAAgB;AACjD,SAAOuD,kBAAW,QACf,OAAOiB,oCAAgB,KAAK,WAC5B,OAAO;AAAA;;eCYU;AAAA,EACpB,YACmB,UACA,QACjB;AAFiB;AACA;AAAA;AAAA,QAGb,OAAO,YAAyB;AACpC,eAAW,aAAa,YAAY;AAClC,UAAI;AACF,cAAM,KAAK,UAAU;AAAA,eACd,OAAP;AACA,aAAK,OAAO,MACV,oBAAoB,cAAcS,sBAAe;AAAA;AAAA;AAAA;AAAA,QAM3C,UAAU,WAAkC;AA3D5D;AA4DI,UAAM,eAAe,MAAM,KAAK,SAA4B,iBACzD,MAAM,EAAE,YAAY,aACpB,MAAM,GACN,OAAO;AACV,QAAI,CAAC,aAAa,QAAQ;AAExB;AAAA;AAIF,UAAM,SAASf;AACf,UAAM,KAAK,SAA6B,kBACrC,OAAO;AAAA,MACN,WAAW,aAAa,GAAG;AAAA,MAC3B,MAAM;AAAA,MACN,eAAe;AAAA,OAEhB,WAAW,aACX,MAAM,CAAC;AASV,UAAM,SAQD,MAAM,KAAK,SACb,KAAK,uBAAuB,4BAA4B,SAAS;AAChE,aAAO,QACJ,KAAK,4BACL,MAAM,EAAE,mBAAmB,aAC3B,MAAM,EAAE,OAAO;AAAA,OAEnB,OAAO;AAAA,MACN,UAAU;AAAA,MACV,iBAAiB;AAAA,MACjB,QAAQ;AAAA,MACR,wBAAwB;AAAA,MACxB,cAAc;AAAA,MACd,cAAc;AAAA,MACd,gBAAgB;AAAA,OAEjB,KAAK,iBACL,MAAM,EAAE,4BAA4B,aACpC,UAAU,KAAK,SAAS,IAAI,wBAC5B,cAAc,kBAAkB;AAAA,MAC/B,4BAA4B;AAAA,OAE7B,cAAc,aAAa;AAAA,MAC1B,+BAA+B;AAAA,OAEhC,QAAQ,gBAAgB,OACxB,QAAQ,kBAAkB;AAM7B,QAAI,CAAC,OAAO,QAAQ;AAClB,WAAK,OAAO,MACV,oBAAoB;AAEtB;AAAA;AAGF,UAAM;AAAA,MACJ;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,QACE,OAAO;AAMX,QAAI,CAAC,iBAAiB;AACpB,WAAK,OAAO,MACV,oBAAoB;AAEtB;AAAA;AAKF,UAAM,SAAS,KAAK,MAAM;AAC1B,UAAM,WAAW,OAAO,4BAA4B;AACpD,QAAI,cAAkC;AAEtC,QAAI,UAAU;AACZ,WAAK,OAAO,MAAM,GAAG;AACrB,aAAO,SAAS,cAAc;AAAA,WACzB,OAAO,SAAS;AAAA,SAClB,wBAAwB;AAAA;AAAA;AAG7B,QAAI,QAAQ;AACV,YAAM,eAAe,KAAK,MAAM;AAChC,UAAI,MAAM,QAAQ,iBAAiB,aAAa,QAAQ;AACtD,sBAAc,aAAa,IAAI;AAAM,UACnC,MAAMgB;AAAA,UACN,OAAO;AAAA,UACP,SAAS,GAAG,EAAE,SAAS,EAAE;AAAA,UACzB,OAAO;AAAA;AAAA;AAAA;AAOb,UAAM,qBAAqBC,cACzB,QACA,OAAK,GAAG,EAAE,gBAAgB,EAAE;AAE9B,WAAO,YAAY,mBAChB,OAAO,SAAO,IAAI,cAClB,IAAoB;AAAQ,MAC3B,MAAM,IAAI;AAAA,MAEV,QAAQvD,4BAAe,IAAI;AAAA,MAC3B,WAAW,IAAI;AAAA;AAEnB,QAAI,YAAY,QAAQ;AACtB,aAAO,SAAS;AAAA,WACX,OAAO;AAAA,QACV,OAAO,CAAC,GAAI,mBAAO,WAAP,mBAAe,UAAf,YAAwB,IAAK,GAAG;AAAA;AAAA;AAKhD,UAAM,OAAO,mBAAmB;AAChC,QAAI,SAAS,cAAc;AACzB,WAAK,OAAO,MAAM,wBAAwB;AAC1C;AAAA;AAGF,WAAO,SAAS,MAAM;AACtB,WAAO,SAAS,aAAa;AAC7B,QAAI,CAAC,OAAO,SAAS,MAAM;AAGzB,aAAO,SAAS,OAAO;AAAA;AAMzB,UAAM,gBAAgB,kBAAkB,UAAU;AAElD,UAAM,cAAc,MAAM,KAAK,SAC7B,kBAEC,OAAO;AAAA,MACN,cAAc,KAAK,UAAU;AAAA,MAC7B;AAAA,OAED,MAAM,aAAa,UACnB,MAAM,iBAAiB,QACvB,WAAW,aACX,MAAM,CAAC,gBAAgB;AAE1B,QAAI,YAAY,WAAW,GAAG;AAC5B,WAAK,OAAO,MACV,UAAU;AAEZ;AAAA;AAUF,UAAM,KAAK,SAAsB,UAC9B,MAAM,EAAE,WAAW,YACnB;AACH,UAAM,KAAK,SAAS,YAAY,UAAU,eAAe;AAAA;AAAA;;4BCrOA;AAAA,EAG3D,YAAY,SAAkD;AAC5D,SAAK,WAAW,QAAQ;AAAA;AAAA,QAGpB,QAAQ,SAAyB;AACrC,UAAM,KAAK,SAAS,YAAY,OAAM,OAAM;AAC1C,YAAM,EAAE,eAAe,MAAM,KAAK,SAAS,cAAc,IAAI;AAAA,QAC3D,WAAW,QAAQ;AAAA;AAErB,YAAM,mBAAmB,WAAW,KAAK,SACvC,IAAI,WAAW;AAKjB,UAAI,kBAAkB;AACpB,cAAM,KAAK,SAAS,QAAQ,IAAI;AAAA,UAC9B,WAAW;AAAA;AAAA;AAGf,YAAM,KAAK,SAAS,QAAQ,IAAI;AAAA,QAC9B,WAAW,QAAQ;AAAA;AAAA;AAAA;AAAA;;+BCnBqC;AAAA,EAC9D,YACmB,SACA,eACjB;AAFiB;AACA;AAAA;AAAA,QAGb,QAAQ,SAAyB;AACrC,UAAM,oBACJ,OAAM,KAAK,cAAc,UACvB;AAAA,MACE;AAAA,QACE,YAAYwD;AAAA,QACZ,aAAa,QAAQ;AAAA;AAAA,OAGzB,EAAE,OAAO,QAAQ,uBAEnB;AACF,QAAI,kBAAkB,WAAWC,uCAAgB,OAAO;AACtD,YAAM,IAAI1B;AAAA;AAEZ,UAAM,KAAK,QAAQ,QAAQ;AAAA;AAAA;;AClB/B,iBAAqD;AAAA,EAGnD,YACmB,QAIjB;AAJiB;AAHV,kCAAyBF;AAAA;AAAA,QAS5B,cAAc,UAAiD;AACnE,UAAM,KAAK,KAAK,OAAO;AAEvB,QAAI,SAAS,SAAS,QAAQ;AAC5B,WAAK,MAAM,SAAS,SAAS,IAAI,OAAK,EAAE;AACxC,YAAM,GAAG,YAAY,OAAM,OAAM;AAC/B,cAAM,GAAG,2BAA2B,IAAI;AAAA,UACtC,WAAW,KAAK,OAAO;AAAA,UACvB,MAAM;AAAA,UACN,OAAO,SAAS;AAAA;AAAA;AAAA,eAGX,SAAS,SAAS,SAAS;AACpC,WAAK,MAAM,SAAS,MAAM,IAAI,OAAK,EAAE;AACrC,WAAK,MAAM,SAAS,QAAQ,IAAI,OAAK,EAAE;AACvC,YAAM,GAAG,YAAY,OAAM,OAAM;AAC/B,cAAM,GAAG,2BAA2B,IAAI;AAAA,UACtC,WAAW,KAAK,OAAO;AAAA,UACvB,MAAM;AAAA,UACN,OAAO,SAAS;AAAA,UAChB,SAAS,SAAS;AAAA;AAAA;AAAA;AAAA;AAAA,EAMlB,MAAM,UAAoB;AAChC,eAAW,UAAU,UAAU;AAC7B,UAAI;AACF,aAAK,uBAAuB;AAAA,eACrB,GAAP;AACA,cAAM,IAAI,UAAU,8BAA8B;AAAA;AAAA;AAAA;AAAA;sCAOxD,IACA,WACA;AACA,QAAM,QAAQ,IACZ,UAAU,IAAI,OAAM,aAAY;AAC9B,UAAM,aAAa,IAAI,WAAW;AAAA,MAChC,IAAI,SAAS;AAAA,MACb,oBAAoB;AAAA;AAEtB,WAAO,SAAS,QAAQ;AAAA;AAAA;;MCzDjB,8BAA8B6B;;MCF9B,gBAAgB,4BAA4B;AAAA,EACvD,MAAM;AAAA,EACN,aACE;AAAA,EACF,OAAO,CAAC,UAAkB,eAAoB;AA7BhD;AA8BI,YAAC,iBAAU,SAAS,gBAAlB,mBAA+B,eAAe;AAAA;AAAA,EAClD,SAAS,CAAC;AAAwB,IAChC,KAAK,wBAAwB;AAAA;AAAA;;MCRpB,eAAe,4BAA4B;AAAA,EACtD,MAAM;AAAA,EACN,aAAa;AAAA,EACb,MAAM,UAAkB,OAAiB;AACvC,UAAM,eAAe,SAAS,KAAK,kBAAkB;AACrD,WAAO,MAAM,KAAK,UAAQ,KAAK,kBAAkB,aAAa;AAAA;AAAA,EAEhE,QAAQ,OAAuC;AAC7C,WAAO;AAAA,MACL,KAAK;AAAA,MACL,QAAQ,MAAM,IAAI,UAAQ,KAAK,kBAAkB;AAAA;AAAA;AAAA;;MCT1C,gBAAgB,4BAA4B;AAAA,EACvD,MAAM;AAAA,EACN,aAAa;AAAA,EACb,OAAO,CAAC,UAAkB,WAAqB;AAC7C,QAAI,CAAC,SAAS,WAAW;AACvB,aAAO;AAAA;AAGT,WAAO,SAAS,UACb,OAAO,cAAY,SAAS,SAASzD,gCACrC,KAAK,cAAY,OAAO,SAAS,SAAS;AAAA;AAAA,EAE/C,SAAS,CAAC;AAAsB,IAC9B,KAAK;AAAA,IACL,QAAQ;AAAA;AAAA;;MCfC,WAAW,4BAA4B;AAAA,EAClD,MAAM;AAAA,EACN,aAAa;AAAA,EACb,OAAO,CAAC,UAAkB,UAAe;AA3B3C;AA4BI,YAAC,iBAAU,SAAS,WAAlB,mBAA0B,eAAe;AAAA;AAAA,EAC7C,SAAS,CAAC;AAAmB,IAC3B,KAAK,mBAAmB;AAAA;AAAA;;MCVf,qBAAqB,CAAC,iBACjC,4BAA4B;AAAA,EAC1B,MAAM,OAAO,aAAa;AAAA,EAC1B,aAAa,2CAA2C;AAAA,EACxD,OAAO,CAAC,UAAkB,KAAa,UAAmB;AACxD,UAAM,aAAatB,WAAI,SAAS,eAAe;AAC/C,QAAI,UAAU,QAAW;AACvB,aAAO,UAAU;AAAA;AAEnB,WAAO,CAAC,CAAC;AAAA;AAAA,EAEX,SAAS,CAAC,KAAa;AAAoB,IACzC,KAAK,GAAG,gBAAgB;AAAA,OACpB,UAAU,UAAa,EAAE,QAAQ,CAAC;AAAA;AAAA;;MCN/B,cAAc,mBAAmB;;MCAjC,UAAU,mBAAmB;;MCE7B,kBAAkB;AAAA,EAC7B;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA;;gCCGgE;AAAA,EAChE,YACmB,iBACA,eACA,qBACjB;AAHiB;AACA;AACA;AAAA;AAAA,QAGb,SAAS,SAAsD;AACnE,UAAM,oBACJ,OAAM,KAAK,cAAc,UACvB,CAAC,EAAE,YAAY2C,oDACf,EAAE,OAAO,mCAAS,uBAEpB;AAEF,QAAI,kBAAkB,WAAWmC,uCAAgB,MAAM;AACrD,aAAO;AAAA,QACL,UAAU;AAAA,QACV,UAAU,EAAE,aAAa;AAAA;AAAA;AAI7B,QAAI,kBAAkB,WAAWA,uCAAgB,aAAa;AAC5D,YAAM,mBAAiC,KAAK,oBAC1C,kBAAkB;AAEpB,aAAO,KAAK,gBAAgB,SAAS;AAAA,WAChC;AAAA,QACH,QAAQ,oCAAS,UACb,EAAE,OAAO,CAAC,kBAAkB,QAAQ,YACpC;AAAA;AAAA;AAIR,WAAO,KAAK,gBAAgB,SAAS;AAAA;AAAA,QAGjC,kBACJ,KACA,SACe;AACf,UAAM,oBACJ,OAAM,KAAK,cAAc,UACvB,CAAC,EAAE,YAAYE,sDACf,EAAE,OAAO,mCAAS,uBAEpB;AACF,QAAI,kBAAkB,WAAWF,uCAAgB,MAAM;AACrD,YAAM,IAAI1B;AAAA;AAEZ,QAAI,kBAAkB,WAAW0B,uCAAgB,aAAa;AAC5D,YAAM,mBAAiC,KAAK,oBAC1C,kBAAkB;AAEpB,YAAM,EAAE,aAAa,MAAM,KAAK,gBAAgB,SAAS;AAAA,QACvD,QAAQ;AAAA,UACN,OAAO,CAAC,kBAAkB,kBAAkB,EAAE,gBAAgB;AAAA;AAAA;AAGlE,UAAI,SAAS,WAAW,GAAG;AACzB,cAAM,IAAI1B;AAAA;AAAA;AAGd,WAAO,KAAK,gBAAgB,kBAAkB;AAAA;AAAA,QAG1C,eACJ,WACA,SACiC;AACjC,UAAM,8BACJ,OAAM,KAAK,cAAc,UACvB,CAAC,EAAE,YAAYT,iDAA6B,aAAa,cACzD,EAAE,OAAO,mCAAS,uBAEpB;AACF,QAAI,4BAA4B,WAAWmC,uCAAgB,MAAM;AAC/D,YAAM,IAAI1B;AAAA;AAGZ,UAAM,iBAAiB,MAAM,KAAK,gBAAgB,eAAe;AACjE,UAAM,oBAAoB,MAAM,KAAK,cAAc,UACjD,eAAe,MAAM,IAAI;AAAS,MAChC,YAAYT;AAAA,MACZ,aAAaI,gCAAmB,KAAK;AAAA,SAEvC,EAAE,OAAO,mCAAS;AAEpB,UAAM,4BAA4B,eAAe,MAAM,OACrD,CAAC,GAAG,UAAU,kBAAkB,OAAO,WAAW+B,uCAAgB;AAEpE,QAAI,0BAA0B,WAAW,GAAG;AAC1C,aAAO;AAAA;AAET,UAAM,6BAA6B,0BAA0B,IAC3D,kBAAgB/B,gCAAmB,aAAa;AAElD,UAAM,4BAA4B,IAAI,IACpC,2BAA2B,QAAQ,mBACjC,KAAK,YACH,eACA,eAAe,OACf,IAAI,IAAI;AAId,WAAO;AAAA,MACL,eAAe,eAAe;AAAA,MAC9B,OAAO,eAAe,MAAM,OAC1B,kBACE,CAAC,0BAA0B,IACzBA,gCAAmB,aAAa;AAAA;AAAA;AAAA,QAMpC,OAAO,SAA6D;AACxE,UAAM,oBACJ,OAAM,KAAK,cAAc,UACvB,CAAC,EAAE,YAAYJ,oDACf,EAAE,OAAO,mCAAS,uBAEpB;AAEF,QAAI,kBAAkB,WAAWmC,uCAAgB,MAAM;AACrD,aAAO;AAAA,QACL,QAAQ,OAAO,YAAY,QAAQ,OAAO,IAAI,OAAK,CAAC,GAAG;AAAA;AAAA;AAI3D,QAAI,kBAAkB,WAAWA,uCAAgB,aAAa;AAC5D,YAAM,mBAAiC,KAAK,oBAC1C,kBAAkB;AAEpB,aAAO,KAAK,gBAAgB,OAAO;AAAA,WAC9B;AAAA,QACH,QAAQ,oCAAS,UACb,EAAE,OAAO,CAAC,kBAAkB,QAAQ,YACpC;AAAA;AAAA;AAIR,WAAO,KAAK,gBAAgB,OAAO;AAAA;AAAA,EAG7B,YACN,WACA,kBACA,gBACU;AACV,UAAM,SAAS,iBAAiB,KAC9B,kBAAgB/B,gCAAmB,aAAa,YAAY;AAE9D,QAAI,CAAC;AAAQ,aAAO;AAEpB,UAAM,oBAAoB,IAAI,IAAI;AAClC,WAAO,iBAAiB,QAAQ,eAC9B,kBAAkB,IAAI;AAGxB,WAAO;AAAA,MACL;AAAA,MACA,GAAG,OAAO,iBAAiB,QAAQ,eACjC,eAAe,IAAI,aACf,KACA,KAAK,YAAY,WAAW,kBAAkB;AAAA;AAAA;AAAA;;gCC9KQ;AAAA,EAChE,YACmB,iBACA,eACjB;AAFiB;AACA;AAAA;AAAA,QAGb,eACJ,MACA,QACA,SAOC;AACD,UAAM,wBACJ,OAAM,KAAK,cAAc,UACvB,CAAC,EAAE,YAAYkC,wDACf,EAAE,OAAO,mCAAS,uBAEpB;AAEF,QAAI,sBAAsB,WAAWH,uCAAgB,MAAM;AACzD,YAAM,IAAI1B;AAAA;AAGZ,WAAO,KAAK,gBAAgB,eAAe,MAAM;AAAA;AAAA,QAG7C,cAAc,SAEI;AACtB,UAAM,wBACJ,OAAM,KAAK,cAAc,UACvB,CAAC,EAAE,YAAY8B,sDACf,EAAE,OAAO,mCAAS,uBAEpB;AAEF,QAAI,sBAAsB,WAAWJ,uCAAgB,MAAM;AACzD,aAAO;AAAA;AAGT,WAAO,KAAK,gBAAgB;AAAA;AAAA,QAGxB,YACJ,IACA,SACmB;AACnB,UAAM,wBACJ,OAAM,KAAK,cAAc,UACvB,CAAC,EAAE,YAAYI,sDACf,EAAE,OAAO,mCAAS,uBAEpB;AAEF,QAAI,sBAAsB,WAAWJ,uCAAgB,MAAM;AACzD,YAAM,IAAItF,qBAAc,6BAA6B;AAAA;AAGvD,WAAO,KAAK,gBAAgB,YAAY;AAAA;AAAA,QAGpC,eACJ,IACA,SACe;AACf,UAAM,wBACJ,OAAM,KAAK,cAAc,UACvB,CAAC,EAAE,YAAY2F,wDACf,EAAE,OAAO,mCAAS,uBAEpB;AAEF,QAAI,sBAAsB,WAAWL,uCAAgB,MAAM;AACzD,YAAM,IAAI1B;AAAA;AAGZ,WAAO,KAAK,gBAAgB,eAAe;AAAA;AAAA;;qBCYnB;AAAA,EA6BlB,YAAY,KAAyB;AAnBrC,8BACN,+BAA+B;AAAA,MAC7B,YAAY;AAAA,MACZ,YAAY;AAAA;AAER,4BAAiD;AAevD,SAAK,MAAM;AACX,SAAK,iBAAiB;AACtB,SAAK,wBAAwB;AAC7B,SAAK,uBAAuB;AAC5B,SAAK,wBAAwB;AAC7B,SAAK,kBAAkB;AACvB,SAAK,aAAa;AAClB,SAAK,oBAAoB;AACzB,SAAK,SAAS;AACd,SAAK,kBAAkB,OAAO,OAAOgC;AAAA;AAAA,SAdhC,OAAO,KAAyC;AACrD,WAAO,IAAI,eAAe;AAAA;AAAA,EA2B5B,mBAAmB,UAA0C;AAC3D,SAAK,eAAe,KAAK,GAAG;AAC5B,WAAO;AAAA;AAAA,EAWT,0BAA0B,SAAiC;AACzD,SAAK,IAAI,OAAO,KACd;AAEF,SAAK,qBAAqB,+BAA+B;AAAA,MACvD,YAAY;AAAA,MACZ,YAAY,UAAU;AAAA;AAExB,WAAO;AAAA;AAAA,EAST,6BAA6B,SAAiC;AAC5D,SAAK,qBAAqB,+BAA+B;AAAA,MACvD,YAAY;AAAA,MACZ,YAAY,UAAU;AAAA;AAExB,WAAO;AAAA;AAAA,EAST,mBAAmB,iBAA0D;AAC3E,SAAK,IAAI,OAAO,KACd;AAEF,SAAK,qBAAqB;AAC1B,WAAO;AAAA;AAAA,EAOT,sBACE,oBACgB;AAChB,SAAK,qBAAqB;AAC1B,WAAO;AAAA;AAAA,EAMT,oBAAoB,kBAAoD;AACtE,SAAK,mBAAmB;AACxB,WAAO;AAAA;AAAA,EAgBT,sBAAsB,UAA0C;AAC9D,SAAK,iBAAiB,CAAC,GAAG;AAC1B,SAAK,wBAAwB;AAC7B,WAAO;AAAA;AAAA,EAUT,uBACE,KACA,UACgB;AAChB,SAAK,qBAAqB,OAAO;AACjC,WAAO;AAAA;AAAA,EAaT,yBAAyB,YAAiD;AACxE,+BAAO,MAAM,KAAK,uBAAuB;AACzC,WAAO;AAAA;AAAA,EAYT,qBAAqB,WAA6C;AAChE,SAAK,gBAAgB,KAAK,GAAG;AAC7B,WAAO;AAAA;AAAA,EAST,gBAAgB,YAAgD;AAC9D,SAAK,WAAW,KAAK,GAAG;AACxB,WAAO;AAAA;AAAA,EAYT,kBAAkB,YAAgD;AAChE,SAAK,aAAa,CAAC,GAAG;AACtB,SAAK,oBAAoB;AACzB,WAAO;AAAA;AAAA,EAWT,uBAA2C;AACzC,UAAM,EAAE,QAAQ,QAAQ,WAAW,KAAK;AACxC,UAAM,eAAenF,4BAAgB,WAAW;AAEhD,WAAO;AAAA,MACL,IAAI;AAAA,MACJ,IAAI,mBAAmB,EAAE,QAAQ;AAAA,MACjC,oBAAoB,WAAW,QAAQ,EAAE,QAAQ;AAAA,MACjD,IAAI,gCAAgC,EAAE;AAAA;AAAA;AAAA,EAa1C,oBAAoB,QAAgD;AAClE,SAAK,SAAS;AACd,WAAO;AAAA;AAAA,EAUT,sBACK,iBAKH;AACA,SAAK,gBAAgB,KAAK,GAAG;AAAA;AAAA,QAMzB,QAMH;AA5YL;AA6YI,UAAM,EAAE,QAAQ,UAAU,QAAQ,gBAAgB,KAAK;AAEvD,UAAM,SAAS,KAAK;AACpB,UAAM,aAAa,KAAK;AACxB,UAAM,SAAS,KAAK,UAAU;AAE9B,UAAM,WAAW,MAAM,SAAS;AAChC,QAAI,iBAAU,eAAT,mBAAqB,OAAM;AAC9B,aAAO,KAAK;AACZ,YAAM,wBAAwB;AAAA;AAGhC,UAAM,qBAAqB,IAAI,0BAA0B;AAAA,MACvD,UAAU;AAAA,MACV;AAAA,MACA,iBAAiB,KAAK;AAAA;AAExB,UAAM,eAAeA,4BAAgB,WAAW;AAChD,UAAM,gBAAgB,4BAA4B,WAAW;AAC7D,UAAM,eAAe,IAAI,qCAAqC;AAAA,MAC5D;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA;AAEF,UAAM,8BAA8B,IAAI,uBAAuB;AAC/D,UAAM,kBAAkB,IAAI,0BAC1B,6BACA,aACAoF,gDAA2B,KAAK;AAElC,UAAM,8BAA8BC,uDAAkC;AAAA,MACpE,cAAcC;AAAA,MACd,cAAc,OAAO,iBAA2B;AAC9C,cAAM,EAAE,aAAa,MAAM,4BAA4B,SAAS;AAAA,UAC9D,QAAQ;AAAA,YACN,OAAO,aAAa,IAAI,iBAAe;AACrC,oBAAM,EAAE,MAAM,WAAW,SAASlE,4BAAe;AAEjD,qBAAO,kBAAkB;AAAA,gBACvB;AAAA,gBACA,sBAAsB;AAAA,gBACtB,iBAAiB;AAAA;AAAA;AAAA;AAAA;AAMzB,cAAM,gBAAgBmE,aAAM,UAAUzC;AAEtC,eAAO,aAAa,IAClB,iBACE,cAAcA,gCAAmB1B,4BAAe;AAAA;AAAA,MAGtD,OAAO,KAAK;AAAA;AAEd,UAAM,WAAW,IAAI,SAAS,UAAU;AAExC,UAAM,gBAAgB,IAAI,qBAAqB;AAC/C,UAAM,yBAAyB,IAAI,6BAA6B;AAChE,UAAM,kBAAkBqB,2BAAO,OAC7B,CAAC,GAAG,KAAK,iBAAiB,eAAe,yBACzC,cAAY,SAAS;AAGvB,UAAM,mBAAmB,IAAI,+BAC3B,QACA,oBACA,cACA,UACA,MAAMM,kBAAW;AAGnB,UAAM,mBACJ,WAAK,qBAAL,YAAyB,IAAI,qBAAqB,QAAQ;AAC5D,UAAM,kBAAkB,IAAI,0BAC1B,IAAI,uBAAuB,eAAe,eAC1C;AAEF,UAAM,iBAAiB,IAAI,yBACzB,IAAI,sBAAsB,EAAE,UAAU,uBACtC;AAEF,UAAM,SAAS,MAAM,aAAa;AAAA,MAChC;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA;AAGF,UAAM,uBAAuB,oBAAoB;AAEjD,WAAO;AAAA,MACL;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA;AAAA;AAAA,EAII,oBAAkC;AACxC,UAAM,iBAAiC,KAAK,wBACxC,CAAC,IAAIyC,wCAA2B,GAAG,KAAK,kBACxC;AAAA,MACE,IAAIA;AAAA,MACJ,IAAIC;AAAA,MACJ,IAAIC;AAAA,MACJ,IAAIC,qCACFC,2BAAc,KAAK;AAAA,MAErB,GAAG,KAAK;AAAA;AAGd,WAAOC,4BAAe,MAAM;AAAA;AAAA,EAGtB,kBAAsC;AAC5C,UAAM,EAAE,QAAQ,WAAW,KAAK;AAChC,UAAM,eAAe7F,4BAAgB,WAAW;AAEhD,SAAK;AAEL,UAAM,uBAA4D;AAAA,MAChE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,MAAM;AAAA,SACH,KAAK;AAAA;AAIV,UAAM,aAAiC;AAAA,MACrC,IAAI,qBAAqB;AAAA,QACvB,WAAW;AAAA,QACX;AAAA,QACA;AAAA;AAAA,MAEF,IAAI;AAAA;AAIN,QAAI,CAAC,KAAK,mBAAmB;AAC3B,iBAAW,KAAK,GAAG,KAAK;AAAA;AAI1B,eAAW,KAAK,GAAG,KAAK;AAExB,SAAK,+BAA+B;AAEpC,WAAO;AAAA;AAAA,EAKD,kCAAkC;AACxC,UAAM,KAAK,KAAK,IAAI,OAAO,kBAAkB;AAC7C,QAAI,yBAAI,IAAI,WAAW;AACrB,YAAM,IAAI,MACR;AAAA;AAGJ,QAAI,yBAAI,IAAI,cAAc;AACxB,YAAM,IAAI,MACR;AAAA;AAGJ,QAAI,yBAAI,IAAI,iBAAiB;AAC3B,YAAM,IAAI,MACR;AAAA;AAGJ,QAAI,yBAAI,IAAI,aAAa;AACvB,YAAM,IAAI,MACR;AAAA;AAAA;AAAA,EAME,+BAA+B,YAAgC;AAvkBzE;AAwkBI,UAAM,mBAAmB;AACzB,QAAI,QAAQ,IAAI,mBAAmB;AACjC;AAAA;AAGF,UAAM,gBAAgB,IAAI,IACxB,iBAAK,IAAI,OACN,uBAAuB,yBAD1B,mBAEI,IAAI,OAAK,EAAE,UAAU,aAFzB,YAEqC;AAEvC,UAAM,iBAAiB,IAAI,IAAI,WAAW,IAAI,OAAK,EAAE;AAErD,mBACE,cACA,eACA,iBACA;AACA,UACE,cAAc,IAAI,iBAClB,CAAC,eAAe,IAAI,gBACpB;AACA,cAAM,IAAI,MACR;AAAA,UACE,4DAA4D;AAAA,UAC5D,yDAAyD;AAAA,UACzD;AAAA,UACA;AAAA,UACA,mBAAmB;AAAA,UACnB;AAAA,UACA,uCAAuC;AAAA,UACvC,KAAK;AAAA;AAAA;AAKb,UACE,sBACA,wCACA;AAEF,UACE,gBACA,2BACA;AAEF,UACE,mBACA,iCACA;AAEF,UACE,uBACA,+BACA;AAEF,UACE,oBACA,4BACA;AAEF,UACE,cACA,4BACA;AAEF,UACE,oBACA,4BACA;AAEF,UACE,YACA,0BACA;AAEF,UACE,uBACA,oCACA;AAAA;AAAA;;ACloBN,MAAM,mBAAmB8F,4CAAuB;AAAA,EAC9C,UAAU;AAAA,EACV,cAAcR;AAAA,EACd,OAAO;AAAA;MASI,oBAAoB,iBAAiB;MAwBrC,8BACX,iBAAiB;;;;;;;;;;;;;;;;;;;;;;;;;;"}